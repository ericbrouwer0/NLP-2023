{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23506,"status":"ok","timestamp":1681131421877,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"},"user_tz":-120},"id":"m4DDQzFp_Knv","outputId":"e593eef0-aa80-4e57-e290-2c5793c4f733"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentence-transformers\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (0.15.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers) (3.8.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (3.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (1.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=1fedbec70394d63d1b2f190863efb623e2138ff48b5d441964b2532e60d84de4\n","  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sentencepiece, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, sentence-transformers\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.4 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.3 transformers-4.27.4 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["pip install sentence-transformers datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MXNNpPn_RD5"},"outputs":[],"source":["import heapq\n","from sentence_transformers import SentenceTransformer\n","import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics.pairwise import cosine_similarity\n","from transformers import BertForQuestionAnswering, BertTokenizer, AutoTokenizer, pipeline, AutoModel\n","from datasets import load_dataset"]},{"cell_type":"code","source":["# for getting the parameters of each pretrained model\n","from transformers import AutoModel\n","\n","model_name = \"sentence-transformers/msmarco-distilbert-base-v3\"\n","model = AutoModel.from_pretrained(model_name)\n","\n","print(model.config.num_hidden_layers)\n","print(model.config.hidden_size)\n","print(model.config.num_attention_heads)\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["59aa5514b1554bceb859b3096c75ce4e","c01935542b1941a5838966ad6c3ad7d0","e94b6e6c4e5345fc8b0f58e5a709edc3","8d067cc153f44005882161bb7099452a","eb0ecb1291504631b9cc894fd84d2014","4e7bc012ea6743d790e521735fc3c164","28889ca26de44e8a8b1dd08de9ac7901","785ace4ce7ed45c5b887bd4f02229f14","1c5409a74f3e49948d2c0dee232e0ba6","2e1ac5bc7a8245ce9a2b3c923ba0e50b","a8dbde65f2f24eb4a48a5dfed420a577","41043b3ad8844cc1b76085690da205e5","0a113a2b03cd40dfb955e060775baf29","c6955f503c844f7faebbc7eba191d3bf","e8793dbe76de4ac2a2e63e9ef3dcb4f7","8c814d523a7c42729931696a2dae002c","0656ee2bc6dc4405b86b0c568e688542","53bc4b1ccf0e4e748429298a2df2fcf6","826b01232b274e66b87163af3a259461","11b8bf6d9f0d4c9190ea01092cab96cc","36f805e9c60049499e752195791d03a6","4411284d626541f280f7786154576f8a"]},"id":"oDhwqTmdOGw_","executionInfo":{"status":"ok","timestamp":1681076933492,"user_tz":-120,"elapsed":22639,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"01763586-6d7f-47f7-e0fc-d64514726ecd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59aa5514b1554bceb859b3096c75ce4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41043b3ad8844cc1b76085690da205e5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["6\n","768\n","12\n","66362880\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216,"referenced_widgets":["0fc94fd6b4a049dc8e179f0f23f9885c","61520ae541974c4d9d606ee65efd884a","6d9fb932015b4a2e947cbda0bc4ee45a","3237d2ffb53a4bfa9098969821c7ede8","073d7c4f112e43ffaeff914ad86b44ed","8601fc67337f441c9a4dd3305f55c0fa","8a62d55cb6c84a158d46d15e1ccce19e","71c44c19dc6d49b8a923129494554611","f28afce0ce2a497d86baeec6aa570492","e833c645dd4343039ce8f99e633d856c","b56387a85db544fdb8d80968cf949946","07296998180f4dc6a077112617c53e72","8fe69bb06283444386e09ab5da26143c","794e9182a47c4f60a70a1dc272419652","00977cfbefce4af1881bf90f1a12b9bd","8a859a77915745a78f303c60016778d1","c5287a7c25fc4311927d7fa3399567eb","b353b570b3834b89a43daf73a430da97","3ee672c122ec45c09e2363de4cd34ca0","95724b8899914346b882d8017021a410","7240cce7c9c940ca9c73765249a1019b","64636fe30eb84da9977be097ce7300a7","fa21476a360a41ebb513bc764849c4d4","82ebb781e3df4ee0bd2fcd7ebf66dba6","c72e12144d474c419d1541401333ea83","605d5739aaee411e9dae5e7246cfbbbf","f40175aaaad14f679a5e6fc4dec3b0d6","95bda14616a54fbf9c11385c7b3f54e8","8373446b3a274241ad7735e1b4414445","ff2f999f8c85485eb11e6ca812466b7f","f73d3fbe404c47aba4f758e38e3ed4f0","17d86de4adc64bbaa23a7903302f615d","0280949d703f4e7d8790d212969c6565","beca19f7eee34aadbbcee5c05c944943","e88c858047244ff2afb010951df88a5f","9e5ee027b7644e909bf2022cd910aee1","588a66120e364c94867f73127d7cc2f9","be231b68a0ea43be9d7fbb063fa10c6c","f5e46e979407484599450c7943624ed1","1e8639a9279a4b7d9a43e8c62fd0845b","52fe5839c93e4d75bd87745f33264451","7a731ccdebfc478a9486ba18d61e8f12","320ff484422a46f3839a6f45f6ab1a39","597537e66cac4dcaa820e4dee5b55c31","91611badadf742f6982644d7876d5ac3","f848bb27595246b9ae2542e8c5a52d62","f525f668af9549a6961cc2afc778d237","e41fcde1b44b4c95b37991f8cf9452dd","bc3ccbaf13db4bf98e2934671ea9daed","ccafe35fe9544af28fa7c11a8a910c6c","7cb9b59a67014df69509c1d87e8cbce9","71b34d2804da461c94c73e97e556ac83","4cec436c36e9470aa2a06442d1d4cfd7","6034d2a920de4e10b0fbe193668c209d","333cb4d908e843e38739d2cf3229bdf9"]},"executionInfo":{"elapsed":6049,"status":"ok","timestamp":1681077004352,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"},"user_tz":-120},"id":"xvve8nlK--3u","outputId":"3b90477c-0256-4eb9-b8c6-2b7a65537c31"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/3.45k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc94fd6b4a049dc8e179f0f23f9885c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/6.97k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07296998180f4dc6a077112617c53e72"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: ik-nlp-22_slp/paragraphs\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset ik-nlp-22_slp/paragraphs to /root/.cache/huggingface/datasets/GroNLP___ik-nlp-22_slp/paragraphs/1.0.0/6c89281b2028a8a126102dda2c3fb94b1a5ccea59943d26857ae138c7aa782f8...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/741k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa21476a360a41ebb513bc764849c4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beca19f7eee34aadbbcee5c05c944943"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset ik-nlp-22_slp downloaded and prepared to /root/.cache/huggingface/datasets/GroNLP___ik-nlp-22_slp/paragraphs/1.0.0/6c89281b2028a8a126102dda2c3fb94b1a5ccea59943d26857ae138c7aa782f8. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91611badadf742f6982644d7876d5ac3"}},"metadata":{}}],"source":["dataset = load_dataset(\"GroNLP/ik-nlp-22_slp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHPFE9WXXR89"},"outputs":[],"source":["url = \"https://huggingface.co/datasets/GroNLP/ik-nlp-22_slp/raw/main/slp_questions.csv\"\n","test_data = pd.read_csv(url)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1681077012014,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"},"user_tz":-120},"id":"LC5zOl8O_jBS","outputId":"b9c8f703-f6bc-4ef2-f5e1-6155248545fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['n_chapter', 'chapter', 'n_section', 'section', 'n_subsection', 'subsection', 'text'],\n","        num_rows: 1697\n","    })\n","})\n"]}],"source":["print(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6jp9rMu_lsV"},"outputs":[],"source":["train_data = dataset[\"train\"]\n","\n","book_content = []\n","\n","for row in train_data:\n","    entry = {\n","        \"chapter\": row[\"n_chapter\"],\n","        \"section\": row[\"n_section\"],\n","        \"subsection\": row[\"n_subsection\"],\n","        \"paragraph\": row[\"text\"],\n","    }\n","    book_content.append(entry)\n"]},{"cell_type":"code","source":["## Knowledge graph\n","\n","import networkx as nx\n","\n","def build_kg(book_content, model):\n","    G = nx.Graph()\n","\n","    # Precompute and store embeddings\n","    paragraphs = [entry[\"paragraph\"] for entry in book_content]\n","    paragraph_embeddings = model.encode(paragraphs, convert_to_tensor=True)\n","    \n","    for i, entry in enumerate(book_content):\n","        G.add_node(i, text=entry[\"paragraph\"], embedding=paragraph_embeddings[i])\n","\n","    # Normalize embeddings\n","    paragraph_embeddings_norm = paragraph_embeddings / paragraph_embeddings.norm(dim=-1, keepdim=True)\n","\n","    # Compute pairwise similarity matrix\n","    similarity_matrix = torch.mm(paragraph_embeddings_norm, paragraph_embeddings_norm.T).cpu().numpy()\n","\n","    # Remove self-similarities (diagonal elements)\n","    np.fill_diagonal(similarity_matrix, 0)\n","\n","    # Find indices where similarity is greater than 0.8\n","    i_indices, j_indices = np.where(similarity_matrix > 0.8)\n","\n","    # Add edges with similarity > 0.8\n","    for i, j in zip(i_indices, j_indices):\n","        similarity = similarity_matrix[i, j]\n","        G.add_edge(i, j, weight=similarity)\n","\n","    return G\n","\n","def retrieve_relevant_paragraphs(query, book_content, model, top_k=5, threshold=0.3):\n","    G = build_kg(book_content, model)\n","    query_embedding = model.encode(query, convert_to_tensor=True)\n","\n","    similarities = {}\n","    for node in G.nodes:\n","        node_embedding = G.nodes[node][\"embedding\"]\n","        node_embedding_norm = node_embedding / node_embedding.norm(dim=-1)\n","        query_embedding_norm = query_embedding / query_embedding.norm(dim=-1)\n","        similarity = torch.nn.functional.cosine_similarity(query_embedding_norm, node_embedding_norm, dim=-1).cpu().numpy()\n","        similarities[node] = similarity\n","\n","    top_k_nodes = sorted(similarities.keys(), key=lambda x: similarities[x], reverse=True)[:top_k]\n","\n","    if similarities[top_k_nodes[0]] < threshold:\n","        return None\n","\n","    top_k_paragraphs = [book_content[node][\"paragraph\"] for node in top_k_nodes]\n","    return top_k_paragraphs\n","\n","\n","# Retrieve relevant paragraphs\n","query = \"How can we estimate the probability of a word?\"\n","model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n","relevant_paragraphs = retrieve_relevant_paragraphs(query, book_content, model)\n","\n","if relevant_paragraphs is None:\n","    print(\"Query is irrelevant.\")\n","else:\n","    print(relevant_paragraphs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438,"referenced_widgets":["3533b91d1d7c4e1a89efc56f5c29ec1c","2483bac646ba4e18b9a5358018e2d209","5cc707cbec854ced9d8639067723081f","399b46afe4fc477aa1e6869a0c30250f","60786abb5b894f00b40971d620f3c097","329c077df1a04fed92a33980db49e39a","a485e45daa6548b18188766ba9ba9c02","687115eaf5f04e6391a86641cb7367cf","748604d6fc8a4d0c9ca0461d47796f82","54d866aa497f4e29b2d7590eb4fc6c1c","6d371e59d4214433960eae92f1feafc9","daea622a7e824d8b9d62ab68628031c2","6408fcb1864345279ca61ac9efabb26f","80eface5421244a8bf93e814c8d43722","ccc9fa1f7714424880c17e6d981739f4","3c6a922f338b4c49b774ce3afce28605","e880fc1aafec4de3aeb1aa3082e4b159","cf02caa0f01644fdbd42efc892daac29","4c8e8f9b4d204a739a4069527718fc34","bbe67671bd63406ea676b75d96119f4c","6d51deb7c7c341cea2e3b692d2afd7e6","eae042e195584b3792c2a37e82d82e2d","767af6ed427e42afb4b12512d64bd452","55fedab7bbef470a81474d3180fc7b9f","7c5a7153d1c84c178f73a34a301e8d66","1a724673bba941d0b9026848bbf2207e","b9ae46a521924caabbe7b157bab1fabc","784a06ee3fda41d5a0f9d1cafd9e3ba2","97cce910749f4a7ca0fc11bcacae0a19","cf56808fa8b948769419f31548059b5e","f445af40516c4d7aa34d34bbc9a0daef","90183f8d01d941d49036a3237843fcd5","02d816954f21435185c4d3d9712c82d8","22ddca84aa4e43a180e9cc945a3a61c3","388a148566b34b6c906c8c557f5f1a12","202fbeb821cb40e79c73b780efa88442","eb1de45aa7cc4e20afc79d0fe2d6663f","5b696266d03c4e78b54fdbb5a2840e70","cc201c523e934f939d2019d3af83d5bf","e31c24820c184241979a67f0ea6d3d8a","3479c78403bf4c5f9843a8b6dc4baf26","a3d59cd0aff346bc9718ca9569b1beaa","3feeaa7172f14fe28b563a1acd76ecad","a922bc3c959449c6b20c40f93455bd14","6aba4f6e144a42f6aca272bc04ce6108","97d234aff1ea4efa89d2021455e8f5f7","90fb3ed6b45848368e4ddd0730fd7eb0","e9687234508e473885fd4f8dd3481048","d5dd0f9e202147db85b77f4c456d241e","841078076b0a4ee4b0134fca40e435d0","5a34f40b32254ac89686909c9f14a79f","5a7152fb01cf4cd0934c18268c9e8bd1","ec001f213a574defb84991a8b71625c2","fe2541878e3740238c1838c369477a7c","beb2dfda22264c5b9fcd1ebe1078f660","34fae80772534398a0f47f50a983e0f5","b2933294f0804203bf0ae90fb4b4ce45","615fbca8878941dfb119d097ee502ddd","03b1fedfe0334bbfaffb2fec9e11c5e5","f327812f60b94a2dbcdf9133b60549ff","dcff5243346344f39455295ac053b2eb","fb69315335b54c8ba147e567753a1f39","ed3a4cf3926c401a9c3c9b93bfddf852","2b769c2e6a2d476281d1b70fceacf4ec","05c28b29d5af49f08ed22087c4904064","773ef3037ad64aa0b452e2e632460913","82f74f9568c04574a4808dfd464ca691","7069429b683341b39c34fdb5b84c0669","d254c7dd745d4cdcb3644a9955748476","0f58f05a1db14567960b632e94369dfb","ece83e8406c84ddda8baae2b045771e7","1732b6708c924e949ad0e6f54e9db380","59c6e075f662445b8508a7d935948d4f","dad1e98be6d348dd902782a33d4fbfa8","055cb6baa5fa4edc96d59b07c59cc2f2","5fda530753be47a4aa444e50b7339840","48ef537cc7d74475abd690c7ceabb277","c34b6dfb5de34b0cbd8ffd346151e60f","a32accb02747441c89a981dc622b4af2","e2489cb018784cf799247bffea93ffcb","d96cca4878fc4398bba47038a531ba7f","8f22a1bf68334b41853e616f50b25a7b","d119288b931a43b093d62b9fa46248cf","2fac0c1ee901458db21f4c4a3a8ab273","f30d04d933d54ad093b6009198cbcb48","f8e12c5126c04f21a1ea1f7f34ad398a","1cebed3333cb4fe3953bb53a6ce5937f","0b39ef015ac946fa8110dcea2bd2cfdb","db63b3aef3ed49079d17abd981f4f777","10f4b7d8f50a4673a36b64affedbfd53","3f229d4711d54cbeb87208728f4779ac","4b8cf1a8b3cb4b679d85aea0f2eb22d7","834c27f6a5734e0eb8fa3a3494ae6ebb","509c31f2cebb45f6bb65e33892efdc92","0efdabe7850d4441b98143e4af185d6a","0044126db9a2442d98525ff0b1261ee4","73ac199984684f9aace5217ed98e2e6b","0d07877dd16e4018b611ab7f6a8bc246","83161e30eea44eb28b58a8fac9dfe362","4b239ba5c0f743218a42a54e6bb691f9","7b4453b371a0430682206e01fb07ffe6","1b44062c01cb4201a5d9b424a47c9db9","69361d20ecac4b5dbce1a7eff4ba8ea8","216a804cc2934c8a9ba3bb4e72abc59e","48cdb4b943cc4bb0a4c5e1e9ab78b9f6","7ef8ed4dbacd4aad9581af70e71221f4","f97904701e7b4a508de7215198efbcbb","25ef9d715a3046bbaccd647ecd1694ab","f4dd2a0f5f6d450f9d21995fe38010f0","0ac14a677f0b48fd867110f56997649b","394b19b93d6648009030723fea0b5765","18519fcf6c1e42a6b18849eaad8346c7","0a8cf7cea0b9493fa2f0bc97d5660689","e1b5341d229b4567843c7942c80f32fa","501d86ff0dec470cbcd59ec908ecdb20","f82b9da5e61044fc9c3589be59282870","4bb65b37aa634e139ff76206c97c5f20","bbb8105f2160497aac370dd7b3fc0330","9c884b9008ac4e31931dccc516403fc5","e48b6b3c0ab84a879a641880db088a70","251dd039ba354930b9a7186b8f6f40b7","cc9765314c8c423cb879eb9c5cbc570b","fcb92750ffcf44369d943419a918488d","53340f4062ee4178b6362b08a7ccde0f","816222e6b8ff415ebe84f9244e4aa661","7a0404158eb245c99d8fb562d2074ca2","e7fddbb9b31943b2ad3f3880ce2a881d","6f57e93eeb644efbb78a8140b3cd19f8","72f114843b3e4c45b13c9258fccc7084","7ee54a7a21ce4e5e9b542226342b0c24","5e9b39d2bc3d49e7a45a5e48c5ea816e","a984ca239d10456c8e5036898bdfd80e"]},"id":"Uu6lplu-Pg94","executionInfo":{"status":"ok","timestamp":1681077282663,"user_tz":-120,"elapsed":24693,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"4e60a68c-4424-4c36-9bf4-0f905002ae82"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)da7dc/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3533b91d1d7c4e1a89efc56f5c29ec1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daea622a7e824d8b9d62ab68628031c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)3fc4bda7dc/README.md:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767af6ed427e42afb4b12512d64bd452"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)c4bda7dc/config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ddca84aa4e43a180e9cc945a3a61c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aba4f6e144a42f6aca272bc04ce6108"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34fae80772534398a0f47f50a983e0f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f74f9568c04574a4808dfd464ca691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c34b6dfb5de34b0cbd8ffd346151e60f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)da7dc/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db63b3aef3ed49079d17abd981f4f777"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/499 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b239ba5c0f743218a42a54e6bb691f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)3fc4bda7dc/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394b19b93d6648009030723fea0b5765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)4bda7dc/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc9765314c8c423cb879eb9c5cbc570b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[\"The chain rule shows the link between computing the joint probability of a sequence and computing the conditional probability of a word given previous words. Equation 3.4 suggests that we could estimate the joint probability of an entire sequence of words by multiplying together a number of conditional probabilities. But using the chain rule doesn't really seem to help us! We don't know any way to compute the exact probability of a word given a long sequence of preceding words, P(w n |w n−1 1 ). As we said above, we can't just estimate by counting the number of times every word occurs following every long string, because language is creative and any particular context might have never occurred before!\", 'Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the. In the following sections we will formalize this intuition by introducing models that assign a probability to each possible next word. The same models will also serve to assign a probability to an entire sentence. Such a model, for example, could predict that the following sequence has a much higher probability of appearing in a text:', 'Let\\'s begin with the task of computing P(w|h), the probability of a word w given some history h. Suppose the history h is \"its water is so transparent that\" and we want to know the probability that the next word is the:', 'The bigram model, for example, approximates the probability of a word given all the previous words P(w n |w 1:n−1 ) by using only the conditional probability of the preceding word P(w n |w n−1 ). In other words, instead of computing the probability', 'Equation 3.12 (like Eq. 3.11) estimates the n-gram probability by dividing the observed frequency of a particular sequence by the observed frequency of a prefix. This ratio is called a relative frequency. We said above that this use of relative frequencies as a way to estimate probabilities is an example of maximum likelihood estimation or MLE. In MLE, the resulting parameter set maximizes the likelihood of the training set T given the model M (i.e., P(T |M)). For example, suppose the word Chinese occurs 400 times in a corpus of a million words like the Brown corpus. What is the probability that a random word selected from some other text of, say, a million words will be the word Chinese? The MLE of its probability is 400 1000000 or .0004. Now .0004 is not the best possible estimate of the probability of Chinese occurring in all situations; it might turn out that in some other corpus or context Chinese is a very unlikely word. But it is the probability that makes it most likely that Chinese will occur 400 times in a million-word corpus. We present ways to modify the MLE estimates slightly to get better probability estimates in Section 3.5.']\n"]}]},{"cell_type":"code","source":["print(np.asarray(relevant_paragraphs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWnmj3GsXveE","executionInfo":{"status":"ok","timestamp":1681077918899,"user_tz":-120,"elapsed":1155,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"d4c56eb0-2bd6-4f43-9953-6e19a9711888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"The chain rule shows the link between computing the joint probability of a sequence and computing the conditional probability of a word given previous words. Equation 3.4 suggests that we could estimate the joint probability of an entire sequence of words by multiplying together a number of conditional probabilities. But using the chain rule doesn't really seem to help us! We don't know any way to compute the exact probability of a word given a long sequence of preceding words, P(w n |w n−1 1 ). As we said above, we can't just estimate by counting the number of times every word occurs following every long string, because language is creative and any particular context might have never occurred before!\"\n"," 'Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the. In the following sections we will formalize this intuition by introducing models that assign a probability to each possible next word. The same models will also serve to assign a probability to an entire sentence. Such a model, for example, could predict that the following sequence has a much higher probability of appearing in a text:'\n"," 'Let\\'s begin with the task of computing P(w|h), the probability of a word w given some history h. Suppose the history h is \"its water is so transparent that\" and we want to know the probability that the next word is the:'\n"," 'The bigram model, for example, approximates the probability of a word given all the previous words P(w n |w 1:n−1 ) by using only the conditional probability of the preceding word P(w n |w n−1 ). In other words, instead of computing the probability'\n"," 'Equation 3.12 (like Eq. 3.11) estimates the n-gram probability by dividing the observed frequency of a particular sequence by the observed frequency of a prefix. This ratio is called a relative frequency. We said above that this use of relative frequencies as a way to estimate probabilities is an example of maximum likelihood estimation or MLE. In MLE, the resulting parameter set maximizes the likelihood of the training set T given the model M (i.e., P(T |M)). For example, suppose the word Chinese occurs 400 times in a corpus of a million words like the Brown corpus. What is the probability that a random word selected from some other text of, say, a million words will be the word Chinese? The MLE of its probability is 400 1000000 or .0004. Now .0004 is not the best possible estimate of the probability of Chinese occurring in all situations; it might turn out that in some other corpus or context Chinese is a very unlikely word. But it is the probability that makes it most likely that Chinese will occur 400 times in a million-word corpus. We present ways to modify the MLE estimates slightly to get better probability estimates in Section 3.5.']\n"]}]},{"cell_type":"code","source":["def build_kg(book_content, model):\n","    G = nx.Graph()\n","\n","    # Precompute and store embeddings\n","    paragraphs = [entry[\"paragraph\"] for entry in book_content]\n","    paragraph_embeddings = model.encode(paragraphs, convert_to_tensor=True)\n","    \n","    for i, entry in enumerate(book_content):\n","        G.add_node(i, text=entry[\"paragraph\"], embedding=paragraph_embeddings[i])\n","\n","    # Normalize embeddings\n","    paragraph_embeddings_norm = paragraph_embeddings / paragraph_embeddings.norm(dim=-1, keepdim=True)\n","\n","    # Compute pairwise similarity matrix\n","    similarity_matrix = torch.mm(paragraph_embeddings_norm, paragraph_embeddings_norm.T).cpu().numpy()\n","\n","    # Remove self-similarities (diagonal elements)\n","    np.fill_diagonal(similarity_matrix, 0)\n","\n","    # Find indices where similarity is greater than 0.8\n","    i_indices, j_indices = np.where(similarity_matrix > 0.8)\n","\n","    # Add edges with similarity > 0.8\n","    for i, j in zip(i_indices, j_indices):\n","        similarity = similarity_matrix[i, j]\n","        G.add_edge(i, j, weight=similarity)\n","\n","    return G\n","\n","def retrieve_relevant_paragraphs(query, G, model, top_k=5, threshold=0.3):\n","    query_embedding = model.encode(query, convert_to_tensor=True)\n","\n","    similarities = {}\n","    for node in G.nodes:\n","        node_embedding = G.nodes[node][\"embedding\"]\n","        node_embedding_norm = node_embedding / node_embedding.norm(dim=-1)\n","        query_embedding_norm = query_embedding / query_embedding.norm(dim=-1)\n","        similarity = torch.nn.functional.cosine_similarity(query_embedding_norm, node_embedding_norm, dim=-1).cpu().numpy()\n","        similarities[node] = similarity\n","\n","    top_k_nodes = sorted(similarities.keys(), key=lambda x: similarities[x], reverse=True)[:top_k]\n","\n","    if similarities[top_k_nodes[0]] < threshold:\n","        return None\n","\n","    top_k_paragraphs = [{\"paragraph\": book_content[node][\"paragraph\"]} for node in top_k_nodes]\n","    return top_k_paragraphs\n","\n","\n","def create_prompt(query, relevant_paragraphs):\n","    prompt = f\"{query} \\n\"\n","    for i, paragraph in enumerate(relevant_paragraphs):\n","        para_text = f\". {paragraph['paragraph']}\"\n","        prompt += para_text\n","    return prompt\n","\n","\n","def generate_answer(prompt):\n","    generator = pipeline(\"text2text-generation\", model=\"allenai/unifiedqa-t5-base\")\n","    answer = generator(prompt)[0].get('generated_text')\n","\n","    return answer\n","\n","\n","def kg_retrieval_pipeline(model, questions):\n","    correct_paragraphs = test_data[\"paragraph\"].tolist()\n","\n","    if(questions == None):\n","      queries = test_data[\"question\"].tolist()\n","    else:\n","      queries = questions\n","\n","    #queries = test_data[\"question\"].tolist()\n","    count = 0\n","\n","    # Build the knowledge graph once\n","    G = build_kg(book_content, model)\n","\n","    no_answers = []\n","    answers = []\n","\n","    for idx, query in enumerate(queries):\n","        relevant_paragraphs = retrieve_relevant_paragraphs(query, G, model, top_k=5)\n","        gt = correct_paragraphs[idx]\n","\n","        if relevant_paragraphs is None:\n","            print(\"Query is irrelevant.\")\n","            no_answers.append(query)\n","            answers.append(\"QUERY IRRELEVANT\")\n","\n","        elif gt in [p[\"paragraph\"] for p in relevant_paragraphs]:\n","            count += 1\n","            prompt = create_prompt(query, relevant_paragraphs)\n","            answer = generate_answer(prompt)\n","            answers.append(answer)\n","\n","        else:\n","            no_answers.append(query)\n","            prompt = create_prompt(query, relevant_paragraphs)\n","            answer = generate_answer(prompt)\n","            answers.append(answer)\n","\n","    performance = count / len(correct_paragraphs)\n","    return performance, no_answers, answers\n","\n","\n","model = SentenceTransformer(\"sentence-transformers/msmarco-roberta-base-v2\")\n","performance, no_answers, answers = kg_retrieval_pipeline(model, None)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":943,"referenced_widgets":["606011312509457eb0fdece7c4d18d77","d4e523ee180a464d8081323a4d280b69","59f01a54eaed48a1a4304e6d593336dc","e9ceacaec5f34017b61aa4d530c02eb2","f2af735e02a54271a9761552c1e0690e","7f1169dd8f3f449eb199f202236dec8e","e1278e906bf5422ab2a03b884bdaa1c2","ba5e056c7c154c359561ed26e12466f2","b99f6feae37e4f9898777874b6e0e109","27a20dfebf6443ee9b26837ee36ccf63","8a749f32ec9349f4b1ff99b8758c85f9","8fdcafae93c04932879f8d7afbe7c239","340e829ff8e0443a85e0b2bcb2d12e73","892d8f036bfb405d94fc4ce7926cb24c","1d298db1df974f5b9a73d097a4281609","537c9d5671744ddf89178a4002be3f43","0c3b19a29f69430590cc9df7f6e4a9c8","b3a176fe5b024bc6a1bc751115cf7daf","52453c417ab646558d9677650454f687","6139ad5fc0b341b38f937f9febf15dd6","830a59420faf401aa9f9a01419790d7b","b96a91ca1d1e46a983f0109ea0af0a3e","800d3d85d33b47fd93ba3391a03a4ad0","cabd4b3930fa46b1bc627b5f63967d9a","dda8aa1da86849ce9800a8d687b5b481","65980751c87e40268c8d872244de7d5c","f24725d472984213acb179e6ac9a6aef","2e0dc34679d640219c3ac72edadcc32a","3ca6f172b148449b843f7faa69105280","62d7dc1ec54b449d9cd2bdea3384b83d","e4a2bd4e500740e7b4567382bda9f4d2","02bf613806c441fab241105f2e9002a7","2947a5678c8a4e4492769fe6c7ade019","b98a32698b654f5fac156dec47d4385c","cb44d00842bf4465a6080c39bc84ef02","302ee0991bbc453eaa7fe83d88f4ae32","d64052601a914a85a9b7dc97479be734","14921323156941a092a2e05c89ecde26","0f6c152c8d5246d0b1f06d58f9410002","358809e3b90842ce9f0de606a17e3622","2b2bb7224f7647f8b1af598117cecaf9","a28cf58ed84a45e880eca7cd63ce9aaa","c9acb41eb3e24a8a8d3d4e9e592ca4ad","1f07f009840b46d8889c7ac32725d837","fb3a84b6ec374960b3554adb96d12210","0a51a3d9f235445395cf7a961fb38139","8c4af0c188804a7291e14ce959c004ea","954602fbf9934bd9854e872109ffcd7e","e56210d4de174445892ae664e5ba2ec4","1c2ea9c6cddd42dc905efe870877a6d6","1da5f7b8e84046b8b7f471ccf82784cb","a386560b67dc4f2fb03e51722d7da36f","8578090d7f3147dbbd9852e23bb49fc6","42752549cabb48b08d549f0192be8d95","1bfcf57062634e1db9286e486292702b","b6b3f554107f4b7590abd1d233b03cdf","ac3835bf4d10474e94cb494954d53855","bf5634a06005453188ec0107f8f0b263","6743bb63b58648c9bad1bc5214fc929b","0893deee9df14a22bd393a0063fd4bc3","abe3d47e1de54a2399f2780fd9da2396","b06b818dd9fa423288beba83c2662e55","4d0f55530b824008a484b1d32ca31669","4e73866eefa0438894c6d2fbfd22eb97","711e9b8ececd49b99f8fcb003be4c961","c85b78107cdc48e393dae33208c8aae2"]},"id":"0S2liN67VAke","executionInfo":{"status":"ok","timestamp":1681078397398,"user_tz":-120,"elapsed":475632,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"8120630f-3238-4ce0-ec3a-24831f4ad307"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606011312509457eb0fdece7c4d18d77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fdcafae93c04932879f8d7afbe7c239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800d3d85d33b47fd93ba3391a03a4ad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98a32698b654f5fac156dec47d4385c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb3a84b6ec374960b3554adb96d12210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6b3f554107f4b7590abd1d233b03cdf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (922 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["print(performance)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6dbR8PvZEOs","executionInfo":{"status":"ok","timestamp":1681078659233,"user_tz":-120,"elapsed":881,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"5e680fc4-27b7-42ff-c1cb-26441f64f3c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8305084745762712\n"]}]},{"cell_type":"code","source":["print(np.asarray(answers))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6nT7TU8l9yj","executionInfo":{"status":"ok","timestamp":1681068952776,"user_tz":-120,"elapsed":207,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"}},"outputId":"14d2a495-b397-4b78-a244-727c953ded28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['zero or more occurrences of the immediately previous character or regular expression'\n"," 'pattern' 'tokenizing (segmenting) words'\n"," 'token learner, and token segmenter'\n"," 'token segmenter is a tool used to tokenize test sentences.'\n"," 'learning a vocabulary'\n"," 'the task of putting words/tokens in a standard format'\n"," 'lemmatization is performed by removing suffixes from the end of the word'\n"," 'the task of determining that two words have the same root, despite their surface differences.'\n"," 'the minimum number of operations it takes to edit one into the other.'\n"," 'a neural network' 'by multiplying the conditional probabilities.'\n"," 'a model Markov chain' 'counting in a corpus and normalizing'\n"," 'bigram models are discounted, while trigram models are unipolated.'\n"," 'how well they fit' 'the inverse probability of the test set'\n"," 'by shaven off a bit of probability mass from more frequent events and give it'\n"," 'pruning'\n"," 'if the probabilities assigned to a Stationary sequence are invariant with respect to'\n"," 'it would take huge numbers of parameters and impossibly large training sets to compute directly'\n"," '.' 'features can express any property of the input text we want.'\n"," \"accuracy doesn't work well when the classes are unbalanced\"\n"," 'a x-ray image of the beam is generated.'\n"," 'to classify an observation into two classes'\n"," 'an online algorithm that minimizes the loss function'\n"," 'an online algorithm that minimizes the loss function'\n"," 'L2 regularization' 'softmax regression' 'affective meanings'\n"," 'to represent a word as a point in a multidimensional semantic space that is '\n"," 'each word type in the vocabulary' 'documents'\n"," 'because it will tend to be high just when the two vectors have large values in the same'\n"," 'best way to weigh the association between two words is to ask how much more the two words co'\n"," 'a single vector with the minimum sum of squared distances'\n"," 'input units, hidden units, and output units'\n"," 'a probability distribution over words'\n"," 'a representation of the process of computing a mathematical expression'\n"," 'assigning a part-of-speech label to each of a sequence of'\n"," 'a person, a location, an organization'\n"," 'a hidden Markov model allows us to talk about both observed events hidden Markov model ('\n"," 'because it does not affect the decision being made.'\n"," 'any network that contains a cycle within its network connections'\n"," 'Train an n-gram language model on the training corpus, using the current set of'\n"," 'removing information no longer needed from the context and adding information likely to be needed for later decision'\n"," 'to delete information from the context that is no longer needed'\n"," 'relevance in the current context'\n"," 'to avoid numerical issues and effective loss of gradients during training'\n"," 'self-attention layer, feedforward layer, norm, and layer normalization'\n"," 'no word or phrase, short of an explanatory footnote, can express the exact meaning'\n"," 'languages that can omit pronouns' 'it is a beam search'\n"," 'cross-attention allows the decoder to attend to each of the source language words as projected'\n"," 'chrF is computed by using the chrF algorithm.' '80%'\n"," 'to predict the original inputs for each of the masked tokens'\n"," 'sentence embedding']\n"]}]},{"cell_type":"code","source":["np.savetxt(f\"answers_msmarco-roberta-base-v2_top_5.csv\", np.asarray(answers), delimiter=\",\", fmt=\"%s\")"],"metadata":{"id":"aorxy3RylR-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6547,"status":"ok","timestamp":1681045982087,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"},"user_tz":-120},"id":"ZAw1UZj1Otsg","outputId":"6d6fbbdf-1410-4256-8632-333555c8bec6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'chapter': '3', 'section': '3.1', 'subsection': 'nan', 'paragraph': \"The chain rule shows the link between computing the joint probability of a sequence and computing the conditional probability of a word given previous words. Equation 3.4 suggests that we could estimate the joint probability of an entire sequence of words by multiplying together a number of conditional probabilities. But using the chain rule doesn't really seem to help us! We don't know any way to compute the exact probability of a word given a long sequence of preceding words, P(w n |w n−1 1 ). As we said above, we can't just estimate by counting the number of times every word occurs following every long string, because language is creative and any particular context might have never occurred before!\"}, {'chapter': '3', 'section': 'nan', 'subsection': 'nan', 'paragraph': 'Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the. In the following sections we will formalize this intuition by introducing models that assign a probability to each possible next word. The same models will also serve to assign a probability to an entire sentence. Such a model, for example, could predict that the following sequence has a much higher probability of appearing in a text:'}, {'chapter': '3', 'section': '3.1', 'subsection': 'nan', 'paragraph': 'Let\\'s begin with the task of computing P(w|h), the probability of a word w given some history h. Suppose the history h is \"its water is so transparent that\" and we want to know the probability that the next word is the:'}, {'chapter': '3', 'section': '3.1', 'subsection': 'nan', 'paragraph': 'The bigram model, for example, approximates the probability of a word given all the previous words P(w n |w 1:n−1 ) by using only the conditional probability of the preceding word P(w n |w n−1 ). In other words, instead of computing the probability'}, {'chapter': '3', 'section': '3.1', 'subsection': 'nan', 'paragraph': 'Equation 3.12 (like Eq. 3.11) estimates the n-gram probability by dividing the observed frequency of a particular sequence by the observed frequency of a prefix. This ratio is called a relative frequency. We said above that this use of relative frequencies as a way to estimate probabilities is an example of maximum likelihood estimation or MLE. In MLE, the resulting parameter set maximizes the likelihood of the training set T given the model M (i.e., P(T |M)). For example, suppose the word Chinese occurs 400 times in a corpus of a million words like the Brown corpus. What is the probability that a random word selected from some other text of, say, a million words will be the word Chinese? The MLE of its probability is 400 1000000 or .0004. Now .0004 is not the best possible estimate of the probability of Chinese occurring in all situations; it might turn out that in some other corpus or context Chinese is a very unlikely word. But it is the probability that makes it most likely that Chinese will occur 400 times in a million-word corpus. We present ways to modify the MLE estimates slightly to get better probability estimates in Section 3.5.'}]\n"]}],"source":["def retrieve_relevant_paragraphs(query, book_content, model, top_k=5, threshold=0.3):\n","    query_embedding = model.encode(query, convert_to_tensor=True)\n","\n","    paragraphs = [entry[\"paragraph\"] for entry in book_content]\n","    paragraph_embeddings = model.encode(paragraphs, convert_to_tensor=True)\n","\n","    # Compute cosine similarity using PyTorch\n","    query_embedding_norm = query_embedding / query_embedding.norm(dim=-1)\n","    paragraph_embeddings_norm = paragraph_embeddings / paragraph_embeddings.norm(dim=-1, keepdim=True)\n","    similarities = torch.nn.functional.cosine_similarity(query_embedding_norm, paragraph_embeddings_norm, dim=-1).cpu().numpy().flatten()\n","\n","    # Check if the highest similarity score is below the threshold\n","    if similarities.max() < threshold:\n","        return None\n","\n","    top_k_indices = similarities.argsort()[-top_k:][::-1]\n","    top_k_paragraphs = [book_content[i] for i in top_k_indices]\n","\n","    return top_k_paragraphs\n","\n","# Retrieve relevant paragraphs\n","query = \"How can we estimate the probability of a word?\"\n","model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n","relevant_paragraphs = retrieve_relevant_paragraphs(query, book_content, model)\n","\n","if relevant_paragraphs is None:\n","    print(\"Query is irrelevant.\")\n","else:\n","    print(relevant_paragraphs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589,"referenced_widgets":["2a3bab006f27495e940f69d789ceed62","8619779699bd4d8c86f6ad30c28ded0c","acd945fe45b4472ba5118404c4bb4134","09d6e6e10e9a4aabb038bceb632dcadf","8d1e271d905c43a3ba5c46648483bedc","10d633203a054563a334bac4999dae03","b98a667da5f84667a0b09fc36df4f2f0","ecc7fda7f8b74c20a0a9f277fa7da5c6","9fdf76b6bcdf4c12b6409ca9ed5e80a6","167ccb692bf047f6b84f78eba2a85b49","21bd0f606ac04e73be3340d77e42e8f5","0c37fb5237254c3a858a9fadbdaafa1d","1f7c36bb1d2b4d81a6d677972d03b52e","49892775520e46c6aceb309f370f7ec6","84d60330641c4e22874b01a0cf25ea1c","52f1faca49ef4f508a4393953e2ea599","734b93d89fb7452cba3dba554285c3c1","e481be4cdfce4c1cbaf0ccab1d8e6d45","e9ed341a31f043858530ecc180a3a6bb","d5649de593e34688a8e053cf27462cea","6a3523b4031a4082940843e258b3dcc7","0eb0a11d7c1b455ca6984240ac741f48","8e8490e43e494608bfbb368934d58791","ceb8a71617134f2492941858a75efc2f","2707dc89b4d04606a3d89448aee56dba","8496eb8f590248e196c0b2a0eab0dba1","3ffac43531c3447097491993bb87db39","0b03cae2890c40098463a020311c1a07","56af9eaae8ea47079a64f810350c3dc4","618568ad6c6640d78f1041d9064838d4","1cec44f5d23841e2aca99938c4cdebd9","b1acec211ee9409d8b879c04c0a44972","4d8abdbd63614bfe8f1763c4e7275e7d","1bf5e635715e41fc99306de21de85e7c","5633f91282054436837c8fc7f277714f","6cec0e3a6f834995a54e95be087d1f02","b31ff19cdce84a6996ed7fc8d2d7d590","1513a2f724874698971909904a5e4fe3","cb25da54d63a4f79b149491a59453229","181b0c6ab1244c0ba6889776f8971976","5abefdba23bb4ce3a52a904b0fed7bbd","486f2fbe37f745b0a3b3d62173bc1908","8ee41752250f466dadd9cf21f95b6492","2c3c81cf671145dba62bf582bd614427","1294dd153d0244b0836d885f8a9693a3","e21e62d2f3d44bb5af88cb7cdcf7680e","21eddaeb30e9429c815deb39ef089f0d","eedb2298866c45cd81440320b939915f","7147034b3f0b44b2902b32c1414e93be","2b3c86ca10d6475b9edec1bb841202d7","b5a5a29f8bbf40c687314e0ad70b5d1b","d88b5de3bff949559e836254733d72d2","1f5f3127de9a4bccbe924fddee58c609","b19fcdfefbb546da993990e77595444e","e4342d0f3a944f8f80913a436561cd3e"]},"executionInfo":{"elapsed":44566,"status":"error","timestamp":1681046030736,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"},"user_tz":-120},"id":"Yuut_byuqj41","outputId":"5ecc9828-fe22-46ee-d2e2-c7ea4e781a08"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a3bab006f27495e940f69d789ceed62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c37fb5237254c3a858a9fadbdaafa1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e8490e43e494608bfbb368934d58791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf5e635715e41fc99306de21de85e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1294dd153d0244b0836d885f8a9693a3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at twmkn9/bert-base-uncased-squad2 were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7d8165926555>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"twmkn9/bert-base-uncased-squad2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mrelevant_paragraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_k_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-7d8165926555>\u001b[0m in \u001b[0;36mget_top_k_paragraphs\u001b[0;34m(query, book_content, tokenizer, model, top_k)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mparagraph_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mparagraph_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparagraph_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mparagraph_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def get_top_k_paragraphs(query, book_content, tokenizer, model, top_k=5):\n","    # Tokenize the query\n","    query_tokens = tokenizer(query, return_tensors=\"pt\")\n","    \n","    # Get the query embedding by passing the tokens through the model and taking the mean of the last hidden state\n","    with torch.no_grad():\n","        query_embedding = model(**query_tokens)[0].mean(dim=1)\n","\n","    # Calculate the embeddings for each paragraph in the book\n","    paragraph_embeddings = []\n","    for paragraph in book_content:\n","        paragraph_tokens = tokenizer(paragraph[\"paragraph\"], return_tensors=\"pt\")\n","        with torch.no_grad():\n","            paragraph_embedding = model(**paragraph_tokens)[0].mean(dim=1)\n","        paragraph_embeddings.append(paragraph_embedding)\n","    \n","    # Compute the cosine similarity between the query and each paragraph embedding\n","    similarities = cosine_similarity(query_embedding, torch.cat(paragraph_embeddings, dim=0))\n","    \n","    # Get the indices of the top_k paragraphs\n","    top_k_indices = similarities.argsort()[0][-top_k:][::-1]\n","\n","    # Return the top_k most relevant paragraphs\n","    return [book_content[i] for i in top_k_indices]\n","\n","query = \"How can we estimate the probability of a word?\"\n","tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/bert-base-uncased-squad2\")\n","model = AutoModel.from_pretrained(\"twmkn9/bert-base-uncased-squad2\")\n","\n","relevant_paragraphs = get_top_k_paragraphs(query, book_content, tokenizer, model)\n","print(np.asarray(relevant_paragraphs))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":220,"status":"error","timestamp":1680880916080,"user":{"displayName":"E.B. Brouwer","userId":"17872242925014382799"},"user_tz":-120},"id":"iccMMDOjameW","outputId":"83727c61-8a9a-4529-8b97-44b9ca296610"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-56f29f0cbd62>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0meval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-56f29f0cbd62>\u001b[0m in \u001b[0;36mconvert_to_string\u001b[0;34m(relevant_paragraphs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}],"source":["def convert_to_string(relevant_paragraphs):\n","    output = []\n","\n","    for rel in relevant_paragraphs:\n","        output.append(rel['paragraph'])\n","\n","    return output\n","\n","eval_list = np.asarray(convert_to_string(relevant_paragraphs))\n","print(eval_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":276,"status":"error","timestamp":1680884979573,"user":{"displayName":"E.B. Brouwer","userId":"17872242925014382799"},"user_tz":-120},"id":"TelBL0EKRilc","outputId":"2b6198f0-4656-4841-e264-7629fa0abd3d"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-3e5743da8677>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create the prompt for T5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-57-3e5743da8677>\u001b[0m in \u001b[0;36mcreate_prompt\u001b[0;34m(query, relevant_paragraphs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{query} \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\". {paragraph['paragraph']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: string indices must be integers"]}],"source":["def generate_answer(prompt):\n","    generator = pipeline(\"text2text-generation\", model=\"allenai/unifiedqa-t5-base\")\n","    answer = generator(prompt)[0].get('generated_text')\n","\n","    return answer\n","\n","\n","def create_prompt(query, relevant_paragraphs):\n","    prompt = f\"{query} \\n\"\n","    for paragraph in relevant_paragraphs:\n","        prompt += f\". {paragraph['paragraph']}\"\n","    return prompt\n","\n","\n","# Create the prompt for T5\n","prompt = create_prompt(query, relevant_paragraphs)\n","\n","print(prompt)\n","# Generate an answer using T5\n","answer = generate_answer(prompt)\n","print(answer)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":186,"status":"ok","timestamp":1681046045151,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"},"user_tz":-120},"id":"Kean0__bJRg8","outputId":"c97e32db-ebdd-4980-e19a-e1b435076da3"},"outputs":[{"output_type":"stream","name":"stdout","text":["How can we estimate the probability of a word?</s>. The chain rule shows the link between computing the joint probability of a sequence and computing the conditional probability of a word given previous words. Equation 3.4 suggests that we could estimate the joint probability of an entire sequence of words by multiplying together a number of conditional probabilities. But using the chain rule doesn't really seem to help us! We don't know any way to compute the exact probability of a word given a long sequence of preceding words, P(w n |w n<unk> 1 1 ). As we said above, we can't just estimate by counting the number of times every word occurs following every long string, because language is creative and any particular context might have never occurred before!</s>. Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the. In the following sections we will formalize this intuition by introducing models that assign a probability to each possible next word. The same models will also serve to assign a probability to an entire sentence. Such a model, for example, could predict that the following sequence has a much higher probability of appearing in a text:</s>. Let's begin with the task of computing P(w|h), the probability of a word w given some history h. Suppose the history h is \"its water is so transparent that\" and we want to know the probability that the next word is the:</s>. The bigram model, for example, approximates the probability of a word given all the previous words P(w n |w 1:n<unk> 1 ) by using only the conditional probability of the preceding word P(w n |w n<unk> 1 ). In other words, instead of computing the probability</s>. Equation 3.12 (like Eq. 3.11) estimates the n-gram probability by dividing the observed frequency of a particular sequence by the observed frequency of a prefix. This ratio is called a relative frequency. We said above that this use of relative frequencies as a way to estimate probabilities is an example of maximum likelihood estimation or MLE. In MLE, the resulting parameter set maximizes the likelihood of the training set T given the model M (i.e., P(T |M)). For example, suppose the word Chinese occurs 400 times in a corpus of a million words like the Brown corpus. What is the probability that a random word selected from some other text of, say, a million words will be the word Chinese? The MLE of its probability is 400 1000000 or.0004. Now.0004 is not the best possible estimate of the probability of Chinese occurring in all situations; it might turn out that in some other corpus or context Chinese is a very unlikely word. But it is the probability that makes it most likely that Chinese will occur 400 times in a million-word corpus. We present ways to modify the MLE estimates slightly to get better probability estimates in Section 3.5.</s>\n"]}],"source":["from transformers import T5Tokenizer\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"allenai/unifiedqa-t5-base\")\n","\n","def create_prompt(query, relevant_paragraphs, max_length=512):\n","    prompt = f\"{query} \\n\"\n","    prompt_tokens = tokenizer.encode(prompt, return_tensors=\"pt\")\n","\n","    for i, paragraph in enumerate(relevant_paragraphs):\n","        para_text = f\". {paragraph['paragraph']}\"\n","\n","        # Tokenize the paragraph text and check the total token length\n","        para_tokens = tokenizer.encode(para_text, return_tensors=\"pt\")\n","        total_length = prompt_tokens.shape[1] + para_tokens.shape[1]\n","\n","        if total_length <= max_length:\n","            # Add the paragraph if the total token length is within the limit\n","            prompt_tokens = torch.cat([prompt_tokens, para_tokens], dim=-1)\n","        else:\n","            # Stop adding paragraphs if the limit is exceeded\n","            break\n","\n","    # Decode the tokens back to text\n","    prompt_text = tokenizer.decode(prompt_tokens[0])\n","    return prompt_text\n","\n","# Create the prompt for T5\n","prompt = create_prompt(query, relevant_paragraphs, max_length=512)\n","\n","print(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470,"referenced_widgets":["e22ecf124e2545e4b931f58fda243242","08eb70b750424599a0312a81c92b704b","9d3fb8b9688b49ee9fb5e9f0235a6a50","93b26a7d8f2647d5b4a8c9e5cf4ba493","8e002ed1dc0544fda1257b22e2b3d759","762cc44b89354e3989d5c10949b0d53b","0b864ae086fc4edcac68f1aee361e44a","addc7246c7e6482b922915f7aebed3b0","485f36fdddf5403287f76fbb0205842f","50459bbbcc8f459583e059110ca8a5a5","a84e374baf1b4c5d9563165de4524c9c","eebf5064e77d40eaa960457d86e76a5b","38dac4b1fe0c4c69b629e4df743f51dc","7f12647a925b4c4cb0a43f4471f9cb55","530c45454a6f492cbfcf7056cebf2d06","4417d3dbbc3d4333804a9fa08b5c821a","13a39e8bb23c41c79737a5f0c3c3be35","e6d8993d676a4790bb6bccdc90558cc8","af69613b2ceb46dc9d959b73154d9a61","bde0c56a60b34c72b60c8e92ae83592c","7cc8ff632a5a4510a9cfea0abfab9524","5964bfdc804d45c0acbd41a310fd02ca","19e849364e164250a88917caacbc3b6e","e7647707e5cd490b92433c3db44a96e5","25312b89f58b4c42ac4b84d99d66da28","d89f2b46004a4ea78254117c9f20647d","d02fd260b3cc4ebebc2009109e214ac5","5105e1e440d64a72931fd87213bd6c39","0582c630550446ddb281cd63e914dad8","370523f402234011a559be11389bdbcb","8cfd7897c2764afcbb9e2ac6b2e2cc5a","0b440ef0aa884c899c604153ef885c85","45fccbf46d8f4b61bc1f6b55802b50f8","c9dfb4d58a3c427caa607d0a97f562c0","00b47e006d874fa3b6c997bd56006547","d98eca76321e4a188dfbd5f8bcfcb48c","55994ac10c7d4fcaaf51bc269197a493","8975ef622be946c2abd708e1852d190d","0e0c7e2782a14460b3853ab8deab4d07","ef251ede424544c2ab044df62119ab77","38e8cc4aa7344acc922dc127d67472e6","816030fb79eb40058dae4517f95eecf5","bb0c1b34c22543c5a80151fc14d4c8f1","162e2bb118bf48cbb0a635a37512ee2c","13688f65eebd4935a7cfdecc58840ad6","91025bd1da3c4cb79b6a96b27232eafc","387a051eb06c4a4f975eab4c324db718","28e4d03c6a874c9789e6f7b9fc3875e5","efe9d7ccb1eb4d1dba64cafe43d01e4a","625d37cb5d114afdbf9571ce07ed43e8","529f05ffd16d462f9b92dd542421e0ea","3a25cb071ccb42a890129746d53c3505","77965214fc1248eba84e7b66ee8ff2b8","ebb3355217ce4675b2c19a7b125f86ca","748a161fa9eb467195545071487c4489","20de1fd7d0d141b4ac25a787e6953432","56322b48de2847bc9171b3fdf1797689","37d6144b01d44b31a8de6ae58ede20c2","1f15daba850e41db9b78c3f9e243cfdf","3e3f76c6156e4dc7aaf78dead73a95d6","236f2c7623b3495d98628d262238746c","e826e74b9c3e4086bd38eda4c57b190b","dc5e85136f0b477ea5862c6e1388fbd6","3b574558023745a980f92c8386dd1caf","0ed03e9d0106484892585711e1c9fb22","926ce28199f2445aa59bb81c9b3b9ac4","c0f1cf2a68b0403c9b880c99029aa6a4","33d50d5d63eb492a807ed96c9d519639","0e58e3c9edb042cc85818e4cbfa7e9c6","acd745b3deac4dd8ace5b7616a7e56bd","d159afe80246413796d9bec5cfa64c54","5f3fee1706ac4015aae69735f28f48e3","cdef964a39cb4fb5b292f5fc05d90fc2","a08d8e9fbb3c495cba1eda25bda56433","99f62bc1034f4cd4a61a058311e455bb","f4ce38b151e94a76ad2d2e02a33fc5d3","47df19ec1e67493b982a3c9129e12de3","be86f8f5382c4202bb226d8b3c06b518","99c9b769fe1540749ccd3bc94c667b67","13fe1876764b4acbb52c210b00f5d766","8784e2a05ef64da193c361ddf9efd662","813590552a4a4064bab0ee229679aac1","6f1cecfb69c74479a7ad49f9fd8e5773","e8194e09b72b4c5b8669ac65a0c6e2c2","9e8b96edd8d74729bded82aa522b5dbb","0b48fd675fc746349e0fad7ffd6440a0","7f2b2790dc984486952dc35b16e8c56e","50b74077ec674d6f978149c9bf8308f0","759a28d94ff94280ba8dba47ee323850","57b008177b154b2eb236e47b0e20c653","d81c468e1ef349d690ee8c98279a9456","04bbd2f594a444ff87cca6629e2126c6","f63a51b2034a45f58093793ee759ce65","34755868accb408f80df03f12dd8c09a","1895df10227a492d8feebdd04defdaac","0353fcb826fa4fc989a9d317ce08a245","2a1ea502d864401fb4354326494c4169","b2c8902938834713a644292a5681af91","c72091b33e3244d191c76275e7478f0d","685a85ac1c2c46aca7c40947f5bed5ea","8f2c0e6244e84008a2ebff0c6bbd6582","67052362b31e4def92e08801ed682e1f","5b65aa41db384fb6b2811415bb142f12","d3c6e52ccb164fd9b9572b7f9293463a","9b70b621d6154d84828919f4b7495520","4cd2bbab9f8a439b84be960a8f683acb","04d040c7b1b64c9bb9694e1d8f394760","16d01f7f4ee14d13a47cc9e164e3e86b","f9e07ca763b44ad8b4c6dfb26c08c399","f8bfb06ae97345849468c1c6938a88e8","cc9a6d40dc8448f3ac1301b7b8aee3af","564ab30bf6cf4bd0b0036dcac70d9c96","c8cc02ee922a47138d8e7e771dc97340","550f027303bb477a94a2aaf49c36c500","9d62590bb57f4542856e742f2877d067","7188c1ac04934827ad6b16ce7556af40","3a641abf33d44bd7978b9d1c6ddf9d90","1eb698256ab249f1b6c92c67b82a9464","ed66b06211474fcd97f39cbcb03bcc69","3ba30ae08c814a52977b32d6018d863b","7910526e062240368cca81311406335f","2209efb0d5c94f3091a05acaf36b21bb","8caf5c76ae3a43689eb21d082d959a25","d2561a7e3b9d4eb6a726a0d68ecfd867","954ddbb51dac41af9554dd4faf16816a","a3e693042d4c4fd6a606f2b61feeba62","6277ef7fceb2488686992291dc7eaa1d","4ccab469a532443eb52f95f14248a3ac","7a10a411d3934282a8a34b82081669c9","9e76b61dab6a48598e1db09f111c7a69","90633305502b4eae9a2636708c2763d1","503498dc5ae94b4fb6188ac06e48b879","71d8ed1f9a6342dcb3ca03668b9cfd63","e8aab362fc4a4ec38247766ce26c25e0","a9fc9124e6864383818ceca27dc09c47","f280bc14db264adea07e3c453196bd48","ed6bd57012c94f1f881bbe9f77c58615","4331ba2fa20b49cab1ca4e217af25917","09c5f544f7bd470483a74e734ee826b6","d6c0780b278d4cfaba5e885f1f13d71d","b0c47ff4dc934e14b0566dd1086cf2e5","16bfafe4cc1241d9bfcaab255d3ee3d9","7ac43ac71bca445987bd0211bdd8cd9f"]},"executionInfo":{"elapsed":24513,"status":"ok","timestamp":1680852392440,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"},"user_tz":-120},"id":"JI5APnPRBFCM","outputId":"0b87ac82-91b3-4277-ed0c-9203063178f4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)2b9e5/.gitattributes:   0%|          | 0.00/736 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e22ecf124e2545e4b931f58fda243242"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eebf5064e77d40eaa960457d86e76a5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)3c1ed2b9e5/README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e849364e164250a88917caacbc3b6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)1ed2b9e5/config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9dfb4d58a3c427caa607d0a97f562c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13688f65eebd4935a7cfdecc58840ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)c1ed2b9e5/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20de1fd7d0d141b4ac25a787e6953432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f1cf2a68b0403c9b880c99029aa6a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be86f8f5382c4202bb226d8b3c06b518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"759a28d94ff94280ba8dba47ee323850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)2b9e5/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685a85ac1c2c46aca7c40947f5bed5ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc9a6d40dc8448f3ac1301b7b8aee3af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)c1ed2b9e5/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2209efb0d5c94f3091a05acaf36b21bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ed2b9e5/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71d8ed1f9a6342dcb3ca03668b9cfd63"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Equation 3.4 suggests that we could estimate the joint probability of an entire sequence of words by multiplying together a number of conditional probabilities. But using the chain rule doesn't really seem to help us! We don't know any way to compute the exact probability of a word given a long sequence of preceding words, P(w n |w n−1 1 ). As we said above, we can't just estimate by counting the number of times every word occurs following every long string, because language is creative and any particular context might have never occurred before! Hopefully, most of you concluded that a very likely word is in, or possibly over, but probably not refrigerator or the.\n"]}],"source":["## Paraphraser tool to generate answer - Not good\n","import spacy\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def extract_detailed_answer(question, paragraph, model, n_sentences=2):\n","    nlp = spacy.load(\"en_core_web_sm\")\n","    \n","    question_embedding = model.encode(question)\n","    sentences = [sent.text for sent in nlp(paragraph).sents]\n","    sentence_embeddings = model.encode(sentences)\n","\n","    similarities = cosine_similarity(question_embedding.reshape(1, -1), sentence_embeddings)\n","    most_similar_index = np.argmax(similarities)\n","\n","    # Get surrounding sentences\n","    start_index = max(0, most_similar_index - n_sentences)\n","    end_index = min(len(sentences), most_similar_index + n_sentences + 1)\n","\n","    answer = \" \".join(sentences[start_index:end_index])\n","    return answer\n","\n","# Example usage\n","sentence_transformer_model = SentenceTransformer(\"paraphrase-distilroberta-base-v2\")\n","context = \" \".join([p[\"paragraph\"] for p in relevant_paragraphs])\n","detailed_answer = extract_detailed_answer(query, context, sentence_transformer_model)\n","print(detailed_answer)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHE_W8ZaKNS1","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"error","timestamp":1680881038432,"user_tz":-120,"elapsed":7364,"user":{"displayName":"E.B. Brouwer","userId":"17872242925014382799"}},"outputId":"4a15d5d5-a9ae-4fb8-b1f3-b4a7c91d665a"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-8ce81e3dec9b>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence-transformers/msmarco-distilbert-base-v3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mperformance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-8ce81e3dec9b>\u001b[0m in \u001b[0;36mmy_pipeline\u001b[0;34m(model, questions)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_paragraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_prompt' is not defined"]}],"source":["def my_pipeline(model, questions):\n","    correct_paragraphs = test_data[\"paragraph\"].tolist()\n","    if(questions == None):\n","      queries = test_data[\"question\"].tolist()\n","    else:\n","      queries = questions\n","    count = 0\n","    no_answers = []\n","    answers = []\n","\n","    for idx, query in enumerate(queries):\n","        relevant_paragraphs = retrieve_relevant_paragraphs(query, book_content, model, top_k=5)\n","        gt = correct_paragraphs[idx]\n","\n","        if relevant_paragraphs is None:\n","            print(\"Query is irrelevant.\")\n","            no_answers.append(query)\n","            answers.append(\"QUERY IRRELEVANT\")\n","\n","        elif gt in relevant_paragraphs:\n","            count += 1\n","            prompt = create_prompt(query, relevant_paragraphs)\n","            answer = generate_answer(prompt)\n","            answers.append(answer)\n","\n","        else:\n","            no_answers.append(query)\n","            prompt = create_prompt(query, relevant_paragraphs)\n","            answer = generate_answer(prompt)\n","            answers.append(answer)\n","\n","    \n","    performance = count / len(correct_paragraphs)\n","    return performance, no_answers, answers\n","\n","\n","model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n","performance, no_answers, answers = my_pipeline(model, None)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1680854696198,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"},"user_tz":-120},"id":"e3mEujZXdOLu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b494fbe3-ce20-47fa-f5f8-2616606b60f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Retrieval performance: 0.7966101694915254\n","12\n"]}],"source":["print(f\"Retrieval performance: {performance}\")\n","print(len(no_answers))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTnUYVULiJZe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680854700017,"user_tz":-120,"elapsed":930,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"08f4b1ab-01a6-4ffc-b747-8a20cc0caa89"},"outputs":[{"output_type":"stream","name":"stdout","text":["['What is a language model?'\n"," 'How can we estimate the probability of a word?'\n"," 'What can be done to optimize Naive Bayes when an insufficient amount of labeled data is present?'\n"," 'What is the purpose of logistic regression?'\n"," 'What is the other name of multinomial logistic regression?'\n"," 'What is the idea behind vector semantics?'\n"," \"What is the output of the output layer's softmax in a neural language model?\"\n"," 'What is a Hidden Markov Model?' 'What is a lexical gap?'\n"," 'What is the difference between cross-attention and multi-head self-attention?'\n"," 'How is the chrF evaluation metric for MT computed?'\n"," 'What role does the [CLS] token play in BERT?']\n"]}],"source":["print(np.asarray(no_answers))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzlzpWxHmmZj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680854706435,"user_tz":-120,"elapsed":1054,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"c9fad15a-8a5d-4f34-b6ff-090a924227b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[\"zero or more a's or bs\" '.' 'normalizing word formats'\n"," 'token learner, and token segmenter'\n"," 'to make use of the current and previous output tokens'\n"," 'to learn a vocabulary' 'putting words in a standard format'\n"," 'lemmatization is the task of determining that two words have the same root, '\n"," 'text normalization'\n"," 'the edit distance between two strings is defined as the minimum number of operations needed to change one string'\n"," 'predicting upcoming words from prior word context'\n"," 'by multiplying all the previous words.' 'a hidden Markov model'\n"," 'n-grams' 'bigram and trigram models' 'the better model'\n"," 'the number of possible next words that can follow any word'\n"," 'we can give them the correct distribution t.' 'pruning'\n"," 'when the probability distributions are invariant'\n"," 'naive Bayes classifiers make two simplifying assumptions.'\n"," 'naive Bayes is a probabilistic classifier.'\n"," 'naive Bayes can express any property of the input text.'\n"," 'there are many different types of text classification tasks.'\n"," 'f(x;  ), y' 'to classify an observation into one of two classes' '.' '.'\n"," 'L2 regularization' 'a 2-layer network'\n"," 'affective meanings or connotations'\n"," 'the idea that meaning is related to the distribution of words in context.'\n"," 'each row represents a word in the vocabulary'\n"," 'each row represents a word in the vocabulary'\n"," 'the dot product is a scalar that reflects the degree of similarity' ''\n"," 'd c' 'input units, hidden units, and output units'\n"," 'y i is a weighted sum over the value vectors v.' 'a graph'\n"," 'the process of assigning a part-of-speech label to each of '\n"," 'anything that can be referred to with a named entity proper name'\n"," 'n i = 1' 'limited context'\n"," 'any network that contains a cycle within its network connections'\n"," 'a model that predicts a value at time t based on a linear'\n"," 'removing information no longer needed from the context and adding information likely to be needed for later decision'\n"," 'to delete information from the context that is no longer needed.'\n"," 'the ability to compare an item of interest to a collection of other items in a way'\n"," 'to avoid numerical issues and to an effective loss of gradients'\n"," 'feedforward layers, residual connections, and normalizing layers'\n"," 'a lexical gap is a gap between the source and the target language.'\n"," 'languages that can omit pronouns' 'we use the chrF metric.'\n"," ' head 2  self-attention' 'chrF' '15%' 'to predict the next word'\n"," 'the CLS token is used to compute recall.']\n"]}],"source":["np_answers = np.asarray(answers)\n","#np.savetxt(f\"/content/drive/MyDrive/nlp/answers_msmarco-distilbert-base-v3_top_3.csv\", np_answers, delimiter=\",\", fmt=\"%s\")\n","print(np_answers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SknYotxB-NV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680854711043,"user_tz":-120,"elapsed":383,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"e60fd914-3378-4717-b86c-dadfbf5f072c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(Query, Generated Answer, True Answer)\n","('What is the meaning of the Kleene star in Regex?', \"zero or more a's or bs\", 'The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\"')\n","('What is the usage of the Regex lookahead operator \"?=\"?', '.', 'The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance.')\n","('What are the most common steps in a text normalization process?', 'normalizing word formats', '1. Tokenizing (segmenting) words 2. Normalizing word formats 3. Segmenting sentences')\n","('What are the two most common components of a tokenization scheme?', 'token learner, and token segmenter', 'a token learner, and a token segmenter')\n","('What is the purpose of a token segmenter?', 'to make use of the current and previous output tokens', 'The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary.')\n","('What is the purpose of a token learner in the BPE algorithm?', 'to learn a vocabulary', 'taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.')\n","('What is word normalization?', 'putting words in a standard format', 'Word normalization is the task of putting words/tokens in a standard format')\n","('How is lemmatization performed?', 'lemmatization is the task of determining that two words have the same root, ', 'The most sophisticated methods for lemmatization involve complete morphological parsing of the word.')\n","('What is lemmatization?', 'text normalization', 'Lemmatization is the task of determining that two words have the same root, despite their surface differences.')\n","('How is the minimum edit distance between two strings defined?', 'the edit distance between two strings is defined as the minimum number of operations needed to change one string', 'the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.')\n","('What is a language model?', 'predicting upcoming words from prior word context', 'Models that assign probabilities to sequences of words are called language models')\n","('How can we estimate the probability of a word?', 'by multiplying all the previous words.', 'from relative frequency counts')\n","('What is a Markov model?', 'a hidden Markov model', 'Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past.')\n","('What technique can be used to estimate n-gram probabilities?', 'n-grams', 'maximum likelihood estimation or MLE')\n","('What is the difference between bigram and trigram models?', 'bigram and trigram models', 'condition on the previous two words rather than the previous word')\n","('How can two probabilisting language models be compared on a test set?', 'the better model', 'whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model')\n","('What is the perplexity of a language model?', 'the number of possible next words that can follow any word', 'perplexity of a language model on a test set is the inverse probability of the test set, normalized by the number of words.')\n","('How can language models be prevented from assigning zero probability to unknown words?', 'we can give them the correct distribution t.', 'smoothing or discounting')\n","('What technique can be used to shrink an n-gram language model?', 'pruning', 'pruning')\n","('When is a stochastic process said to be stationary?', 'when the probability distributions are invariant', 'A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index.')\n","('Why are simplifying assumptions needed when using a Naive Bayes Classifier?', 'naive Bayes classifiers make two simplifying assumptions.', 'without some simplifying assumptions, estimating the probability of every possible combination of features (for example, every possible set of words and positions) would require huge numbers of parameters and impossibly large training sets.')\n","('What can be done to optimize Naive Bayes when an insufficient amount of labeled data is present?', 'naive Bayes is a probabilistic classifier.', 'derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment.')\n","('What type of features can be used to train a Naive Bayes classifier?', 'naive Bayes can express any property of the input text.', 'dictionaries, URLs, email addresses, network features, phrases')\n","('Why is accuracy rarely used alone for unbalanced text classification tasks?', 'there are many different types of text classification tasks.', \"because accuracy doesn't work well when the classes are unbalanced\")\n","('What are folds in cross-validation?', 'f(x;  ), y', 'k disjoints subsets')\n","('What is the purpose of logistic regression?', 'to classify an observation into one of two classes', 'The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation.')\n","('What is gradient descent?', '.', \"Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters θ ) the function's slope is rising the most steeply, and moving in the opposite direction.\")\n","('What is stochastic gradient descent?', '.', 'Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example')\n","('Which regularization technique is easier to optimize?', 'L2 regularization', 'L2 regularization is easier to optimize because of its simple derivative')\n","('What is the other name of multinomial logistic regression?', 'a 2-layer network', 'softmax regression')\n","('What are word connotations?', 'affective meanings or connotations', \"the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations\")\n","('What is the idea behind vector semantics?', 'the idea that meaning is related to the distribution of words in context.', \"The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors.\")\n","('What do rows represent in a term-document matrix?', 'each row represents a word in the vocabulary', 'a word in the vocabulary')\n","('What do columns represent in a term-document matrix?', 'each row represents a word in the vocabulary', 'a document from some collection of documents')\n","('Why can dot product be used as a similarity metric?', 'the dot product is a scalar that reflects the degree of similarity', 'The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions.')\n","('What is the intuition behind PPMI?', '', 'PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.')\n","('What is a centroid?', 'd c', 'a multidimensional version of the mean')\n","('What are the three type of nodes in a feedforward neural network?', 'input units, hidden units, and output units', 'input units, hidden units, and output units')\n","(\"What is the output of the output layer's softmax in a neural language model?\", 'y i is a weighted sum over the value vectors v.', 'a probability distribution over words')\n","('What is a computation graph?', 'a graph', 'A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.')\n","('What is part-of-speech tagging?', 'the process of assigning a part-of-speech label to each of ', 'Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.')\n","('What are named entities?', 'anything that can be referred to with a named entity proper name', 'A named entity is, roughly speaking, anything that can be referred to with a proper name: a person, a location, an organization.')\n","('What is a Hidden Markov Model?', 'n i = 1', 'An HMM is a probabilistic sequence model')\n","('Why is limited context a limitation of feedforward neural networks?', 'limited context', 'Anything outside the context window has no impact on the decision being made.')\n","('What is a recurrent neural network?', 'any network that contains a cycle within its network connections', 'any network that contains a cycle within its network connections')\n","('What is an autoregressive language model?', 'a model that predicts a value at time t based on a linear', 'a model that predicts a value at time t based on a linear function of the previous values at times t − 1, t − 2, and so on.')\n","('What are the two subproblems derived from the context management problem by LSTMs?', 'removing information no longer needed from the context and adding information likely to be needed for later decision', 'removing information no longer needed from the context, and adding information likely to be needed for later decision making.')\n","('What is the purpose of a forget gate in the LSTM architecture?', 'to delete information from the context that is no longer needed.', 'delete information from the context that is no longer needed')\n","('What is expressed in the attention-based approach by comparing items in a collection?', 'the ability to compare an item of interest to a collection of other items in a way', 'their relevance in the current context')\n","('Why does the dot product output need to be scaled in the attention computation?', 'to avoid numerical issues and to an effective loss of gradients', 'The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating such large values can lead to numerical issues and to an effective loss of gradients during training.')\n","('What components constitute a transformer block?', 'feedforward layers, residual connections, and normalizing layers', 'in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers')\n","('What is a lexical gap?', 'a lexical gap is a gap between the source and the target language.', 'no word or phrase, short of an explanatory footnote, can express the exact meaning of a word in the other language.')\n","('What are pro-drop languages?', 'languages that can omit pronouns', 'Languages that can omit pronouns')\n","('How does the beam search decoding algorithm operate?', 'we use the chrF metric.', ' In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step.')\n","('What is the difference between cross-attention and multi-head self-attention?', ' head 2  self-attention', 'the keys and values come from the output of the encoder.')\n","('How is the chrF evaluation metric for MT computed?', 'chrF', 'The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common.')\n","('What percentage of tokens sampled for learning are replaced with the [MASK] token during BERT pre-training?', '15%', '80%')\n","('What is the Masked Language Modeling training objective?', 'to predict the next word', 'predict the original inputs for each of the masked tokens')\n","('What role does the [CLS] token play in BERT?', 'the CLS token is used to compute recall.', 'sentence embedding')\n"]}],"source":["str_compare = zip(np.asarray(test_data['question']),np_answers, np.asarray(test_data['answer']))\n","print(\"(Query, Generated Answer, True Answer)\")\n","for item in str_compare:\n","    print(item)"]},{"cell_type":"code","source":["#question generation model with only context as input\n","\n","from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer\n","\n","model_name = \"allenai/t5-small-squad2-question-generation\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","questions_context = []\n","\n","\n","def run_model(**generator_args):\n","    correct_paragraphs = test_data[\"paragraph\"].tolist()\n","    for idx,context in enumerate(correct_paragraphs):\n","        input_ids = tokenizer.encode(context, return_tensors=\"pt\")\n","        res = model.generate(input_ids, **generator_args)\n","        output = tokenizer.batch_decode(res, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","        \n","        for i in output: \n","          questions_context.append(i)\n","\n","\n","run_model()\n","print(len(questions_context))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5uioShAjD4f","executionInfo":{"status":"ok","timestamp":1681082727969,"user_tz":-120,"elapsed":28579,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"97e3a925-a842-4d33-b131-7996673f6ba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59\n"]}]},{"cell_type":"code","source":["#compare questions generated by context only model with the ones from test data set\n","questions = test_data['question'].to_list()\n","for i in range(len(questions_context)):\n","  print(questions_context[i])\n","  print(questions[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4-JpjcQnFAH","executionInfo":{"status":"ok","timestamp":1681082622393,"user_tz":-120,"elapsed":8,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"1cd36729-5291-4fa7-b21f-50691c3e0bf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What is the Kleene * erally pronounced?\n","What is the meaning of the Kleene star in Regex?\n","What is the name of the lookahead assertions that make use of?\n","What is the usage of the Regex lookahead operator \"?=\"?\n","What is the first step in a normalization process?\n","What are the most common steps in a text normalization process?\n","What is the name of the first two tokenization schemes?\n","What are the two most common components of a tokenization scheme?\n","What is the name of the first two tokenization schemes?\n","What is the purpose of a token segmenter?\n","What is the token learner part of the BPE algorithm?\n","What is the purpose of a token learner in the BPE algorithm?\n","What is the task of putting words/tokens in a standard format?\n","What is word normalization?\n","What is the study of the way words are built up from smaller meaning-bearing units\n","How is lemmatization performed?\n","What is the task of Lemmatization?\n","What is lemmatization?\n","What is the minimum edit distance between two strings?\n","How is the minimum edit distance between two strings defined?\n","What is the simplest model that assigns probabilities to sequences of words?\n","What is a language model?\n","What is the probability of a corpus being a factor in the probability of a\n","How can we estimate the probability of a word?\n","What is the general equation for this n-gram approximation to the conditional\n","What is a Markov model?\n","How do we estimate bigram probabilities?\n","What technique can be used to estimate n-gram probabilities?\n","What is the name of the trigram model used for?\n","What is the difference between bigram and trigram models?\n","What does the better model assign to the test set?\n","How can two probabilisting language models be compared on a test set?\n","What is the inverse probability of a test set?\n","What is the perplexity of a language model?\n","What is the name of the modification that is called smoothing or discounting?\n","How can language models be prevented from assigning zero probability to unknown words?\n","What is another option for a n-gram language model?\n","What technique can be used to shrink an n-gram language model?\n","What is the probability distribution for words at time t?\n","When is a stochastic process said to be stationary?\n","What is the probability of every possible combination of features?\n","Why are simplifying assumptions needed when using a Naive Bayes Classifier?\n","What is the opinion lexicon?\n","What can be done to optimize Naive Bayes when an insufficient amount of labeled data is present?\n","What is a naive Bayes model?\n","What type of features can be used to train a Naive Bayes classifier?\n","What percentage of the observations that our system labels correctly?\n","Why is accuracy rarely used alone for unbalanced text classification tasks?\n","What is the name of cross-validation?\n","What are folds in cross-validation?\n","What is the probability that the document has negative sentiment?\n","What is the purpose of logistic regression?\n","What is the method that finds a minimum of a function?\n","What is gradient descent?\n","What is an online algorithm that minimizes the loss function?\n","What is stochastic gradient descent?\n","What is the derivative of | |?\n","Which regularization technique is easier to optimize?\n","What is the term for the word \"choosing from 10, 30, or even 50 different\n","What is the other name of multinomial logistic regression?\n","What is the word sentiment?\n","What are word connotations?\n","What is the term for embeddings?\n","What is the idea behind vector semantics?\n","What is the name of the cell in the matrix?\n","What do rows represent in a term-document matrix?\n","What is the name of the cell in the matrix?\n","What do columns represent in a term-document matrix?\n","What is the dot product?\n","Why can dot product be used as a similarity metric?\n","What is PPMI used for term-term-matrices?\n","What is the intuition behind PPMI?\n","What is the centroid document vector d?\n","What is a centroid?\n","What is the name of a feedforward network?\n","What are the three type of nodes in a feedforward neural network?\n","What is the probability of the next word w t being V 42?\n","What is the output of the output layer's softmax in a neural language model?\n","What is a representation of the process of computing a mathematical expression?\n","What is a computation graph?\n","What is the name of the word that is a part of speech?\n","What is part-of-speech tagging?\n","What is a name for a person?\n","What are named entities?\n","What is an HMM?\n","What is a Hidden Markov Model?\n","What is the main problem of n-gram models of Chapter 3?\n","Why is limited context a limitation of feedforward neural networks?\n","What is the name of a recurrent neural network?\n","What is a recurrent neural network?\n","What is the name of the model that predicts a value at time t?\n","What is an autoregressive language model?\n","What is the most commonly used extension to RNNs?\n","What are the two subproblems derived from the context management problem by LSTMs?\n","What is the first gate we'll consider?\n","What is the purpose of a forget gate in the LSTM architecture?\n","What is the simplest form of comparison between elements in a self-attention layer?\n","What is expressed in the attention-based approach by comparing items in a collection?\n","What is the result of a dot product?\n","Why does the dot product output need to be scaled in the attention computation?\n","What is the core of what transformer block?\n","What components constitute a transformer block?\n","What is the direction of motion marked on the satellite?\n","What is a lexical gap?\n","What is the dimension of referential density?\n","What are pro-drop languages?\n","What is the term for the beam width?\n","How does the beam search decoding algorithm operate?\n","What is the name of the decoder transformer block?\n","What is the difference between cross-attention and multi-head self-attention?\n","What is the chrF metric based on?\n","How is the chrF evaluation metric for MT computed?\n","What percentage of input tokens in a training sequence are sampled for learning?\n","What percentage of tokens sampled for learning are replaced with the [MASK] token during BERT pre-training?\n","What is the training objective of MLM?\n","What is the Masked Language Modeling training objective?\n","What is the term for sentence embedding?\n","What role does the [CLS] token play in BERT?\n"]}]},{"cell_type":"code","source":["print(len(test_data['question'].to_list()))\n","!pip install evaluate\n","import evaluate\n","\n","\n","from nltk.tokenize import word_tokenize\n","bleu = evaluate.load(\"bleu\")\n","results = bleu.compute(predictions=questions_context, references=test_data['question'].to_list(), max_order=1)\n","print(results)\n","results = bleu.compute(predictions=questions_context, references=test_data['question'].to_list(), max_order=2)\n","print(results)\n","results = bleu.compute(predictions=questions_context, references=test_data['question'].to_list(), max_order=3)\n","print(results)\n","results = bleu.compute(predictions=questions_context, references=test_data['question'].to_list(), max_order=4)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaQB09HKOhpH","executionInfo":{"status":"ok","timestamp":1681083148635,"user_tz":-120,"elapsed":12156,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"019e59e8-913a-4dc3-c473-95dbe02dd7b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["59\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (0.4.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.4.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.4)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.11.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.3.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","{'bleu': 0.39473684210526316, 'precisions': [0.39473684210526316], 'brevity_penalty': 1.0, 'length_ratio': 1.0704225352112675, 'translation_length': 608, 'reference_length': 568}\n","{'bleu': 0.2557928231274908, 'precisions': [0.39473684210526316, 0.1657559198542805], 'brevity_penalty': 1.0, 'length_ratio': 1.0704225352112675, 'translation_length': 608, 'reference_length': 568}\n","{'bleu': 0.167192281767045, 'precisions': [0.39473684210526316, 0.1657559198542805, 0.07142857142857142], 'brevity_penalty': 1.0, 'length_ratio': 1.0704225352112675, 'translation_length': 608, 'reference_length': 568}\n","{'bleu': 0.10204526342252244, 'precisions': [0.39473684210526316, 0.1657559198542805, 0.07142857142857142, 0.02320185614849188], 'brevity_penalty': 1.0, 'length_ratio': 1.0704225352112675, 'translation_length': 608, 'reference_length': 568}\n"]}]},{"cell_type":"code","source":["meteor = evaluate.load('meteor')\n","results = meteor.compute(predictions=questions_context, references=test_data['question'].to_list())\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134,"referenced_widgets":["c7f8809ef986456c95f2f4d063094e14","0f39bf93b03f4a1580df480013b99e8d","c90202f59dd3421d9ceb88be273e2528","e94f4c7e69a241579f4e8a772061d098","c432a7022807443eb5970d879cc85907","638b9ab98d1641f29b0e313c993e9ae1","3ae84dc5d39f4aefb39e95dedf6494e1","ed4d3bfd96684e31b98c547535949200","6bd2025fd97c4126b1598b1bda8dce7c","6f67f9b1d22b41e09533e4ad79f67707","faf433962ff84763a4ee8eccc0550069"]},"id":"_LQGDPYdgevw","executionInfo":{"status":"ok","timestamp":1681085664255,"user_tz":-120,"elapsed":5022,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"424171eb-b1d8-4ff2-98f8-65f525d997e7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.81k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f8809ef986456c95f2f4d063094e14"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["{'meteor': 0.37917441773901245}\n"]}]},{"cell_type":"code","source":["#test model question generation with context only\n","model = SentenceTransformer(\"sentence-transformers/msmarco-roberta-base-v2\")\n","performance, no_answers, answers = kg_retrieval_pipeline(model, questions_context)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2k0VXQEmlSm","executionInfo":{"status":"ok","timestamp":1681083589899,"user_tz":-120,"elapsed":422331,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"258474d6-0980-45a2-c51a-9925a67bce28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["print(f\"Retrieval performance: {performance}\")\n","print(len(no_answers))\n","\n","print(np.asarray(no_answers))\n","\n","np_answers = np.asarray(answers)\n","#np.savetxt(f\"/content/drive/MyDrive/nlp/answers_msmarco-distilbert-base-v3_top_3.csv\", np_answers, delimiter=\",\", fmt=\"%s\")\n","print(np_answers)\n","\n","str_compare = zip(questions_context,np_answers, np.asarray(test_data['answer']))\n","print(\"(Query, Generated Answer, True Answer)\")\n","for item in str_compare:\n","    print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgAq2sWroZKt","executionInfo":{"status":"ok","timestamp":1681083786035,"user_tz":-120,"elapsed":962,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"22ca1f7e-b9bd-4afe-a897-e68599cd6d2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Retrieval performance: 0.6610169491525424\n","20\n","['What is the task of putting words/tokens in a standard format?'\n"," 'What is the probability of a corpus being a factor in the probability of a'\n"," 'What is the general equation for this n-gram approximation to the conditional'\n"," 'What is the inverse probability of a test set?'\n"," 'What is the probability distribution for words at time t?'\n"," 'What is the probability that the document has negative sentiment?'\n"," 'What is the method that finds a minimum of a function?'\n"," 'What is an online algorithm that minimizes the loss function?'\n"," 'What is the derivative of | |?'\n"," 'What is the term for the word \"choosing from 10, 30, or even 50 different'\n"," 'What is the name of the cell in the matrix?'\n"," 'What is the name of the cell in the matrix?' 'What is the dot product?'\n"," 'What is the probability of the next word w t being V 42?'\n"," 'What is the name of the word that is a part of speech?'\n"," 'What is the main problem of n-gram models of Chapter 3?'\n"," 'What is the name of the model that predicts a value at time t?'\n"," 'What is the most commonly used extension to RNNs?'\n"," 'What is the dimension of referential density?'\n"," 'What is the term for sentence embedding?']\n","['cleany star' '(?) syntax' 'tokenizing (segmenting) words'\n"," 'token learner and token segmenter' 'token learner and token segmenter'\n"," 'learning a vocabulary by iteratively merging tokens'\n"," 'normalizing word formats' 'morphology'\n"," 'determining that two words have the same root, despite their surface differences'\n"," 'the minimum number of operations it takes to edit one into the other.'\n"," 'n-gram' 'prior probability likelihood = argmax cC likelihood P(d|c)'\n"," 'the general equation is xyzzzzzzzzzzzz' 'maximum likelihood estimation'\n"," 'condition on the previous two words' 'higher probability' '.01'\n"," 'shave off a bit of probability mass from more frequent events and give it to the'\n"," 'Train an n-gram language model on the training corpus, using the current set of'\n"," 'the total number of word tokens N'\n"," 'every possible set of words and positions'\n"," 'the general inquirer, the LIWC (Pennebaker et al'\n"," 'a set of class-specific unigram language models' '100%'\n"," 'a x-ray image of the candidate is generated.'\n"," 'it is more likely that it has negative sentiment than positive ones.'\n"," 'iteratively' 'gradient descent' 'the derivative of the sigmoid' 'random'\n"," 'positive or negative evaluation language' 'vector semantics'\n"," 'cell number' 'cell number' 'a scalar value'\n"," 'positive pointwise mutual information'\n"," 'document vector d = w 1 + w 2 + ... + w '\n"," 'multilayer feedforward network' 'wV count(w, positive) = 0 (4.13)'\n"," 'computation graph' 'noun' 'a location' 'a probabilistic sequence model'\n"," 'they depend on the training corpus'\n"," 'any network that contains a cycle within its network connections'\n"," 'bigram model' 'backpropagation through time (BPTT)' 'the forget gate'\n"," 'a dot product' 'a scalar value' 'self-attention calculation'\n"," 'manner of motion' '1' 'fixed-size memory footprint' 'cross-attention'\n"," 'measuring the exact character n-grams a human reference and candidate machine translation have in'\n"," '15%' 'to predict the inputs for each of the masked tokens.'\n"," 'a vector semantics']\n","(Query, Generated Answer, True Answer)\n","('What is the Kleene * erally pronounced?', 'cleany star', 'The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\"')\n","('What is the name of the lookahead assertions that make use of?', '(?) syntax', 'The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance.')\n","('What is the first step in a normalization process?', 'tokenizing (segmenting) words', '1. Tokenizing (segmenting) words 2. Normalizing word formats 3. Segmenting sentences')\n","('What is the name of the first two tokenization schemes?', 'token learner and token segmenter', 'a token learner, and a token segmenter')\n","('What is the name of the first two tokenization schemes?', 'token learner and token segmenter', 'The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary.')\n","('What is the token learner part of the BPE algorithm?', 'learning a vocabulary by iteratively merging tokens', 'taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.')\n","('What is the task of putting words/tokens in a standard format?', 'normalizing word formats', 'Word normalization is the task of putting words/tokens in a standard format')\n","('What is the study of the way words are built up from smaller meaning-bearing units', 'morphology', 'The most sophisticated methods for lemmatization involve complete morphological parsing of the word.')\n","('What is the task of Lemmatization?', 'determining that two words have the same root, despite their surface differences', 'Lemmatization is the task of determining that two words have the same root, despite their surface differences.')\n","('What is the minimum edit distance between two strings?', 'the minimum number of operations it takes to edit one into the other.', 'the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.')\n","('What is the simplest model that assigns probabilities to sequences of words?', 'n-gram', 'Models that assign probabilities to sequences of words are called language models')\n","('What is the probability of a corpus being a factor in the probability of a', 'prior probability likelihood = argmax cC likelihood P(d|c)', 'from relative frequency counts')\n","('What is the general equation for this n-gram approximation to the conditional', 'the general equation is xyzzzzzzzzzzzz', 'Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past.')\n","('How do we estimate bigram probabilities?', 'maximum likelihood estimation', 'maximum likelihood estimation or MLE')\n","('What is the name of the trigram model used for?', 'condition on the previous two words', 'condition on the previous two words rather than the previous word')\n","('What does the better model assign to the test set?', 'higher probability', 'whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model')\n","('What is the inverse probability of a test set?', '.01', 'perplexity of a language model on a test set is the inverse probability of the test set, normalized by the number of words.')\n","('What is the name of the modification that is called smoothing or discounting?', 'shave off a bit of probability mass from more frequent events and give it to the', 'smoothing or discounting')\n","('What is another option for a n-gram language model?', 'Train an n-gram language model on the training corpus, using the current set of', 'pruning')\n","('What is the probability distribution for words at time t?', 'the total number of word tokens N', 'A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index.')\n","('What is the probability of every possible combination of features?', 'every possible set of words and positions', 'without some simplifying assumptions, estimating the probability of every possible combination of features (for example, every possible set of words and positions) would require huge numbers of parameters and impossibly large training sets.')\n","('What is the opinion lexicon?', 'the general inquirer, the LIWC (Pennebaker et al', 'derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment.')\n","('What is a naive Bayes model?', 'a set of class-specific unigram language models', 'dictionaries, URLs, email addresses, network features, phrases')\n","('What percentage of the observations that our system labels correctly?', '100%', \"because accuracy doesn't work well when the classes are unbalanced\")\n","('What is the name of cross-validation?', 'a x-ray image of the candidate is generated.', 'k disjoints subsets')\n","('What is the probability that the document has negative sentiment?', 'it is more likely that it has negative sentiment than positive ones.', 'The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation.')\n","('What is the method that finds a minimum of a function?', 'iteratively', \"Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters θ ) the function's slope is rising the most steeply, and moving in the opposite direction.\")\n","('What is an online algorithm that minimizes the loss function?', 'gradient descent', 'Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example')\n","('What is the derivative of | |?', 'the derivative of the sigmoid', 'L2 regularization is easier to optimize because of its simple derivative')\n","('What is the term for the word \"choosing from 10, 30, or even 50 different', 'random', 'softmax regression')\n","('What is the word sentiment?', 'positive or negative evaluation language', \"the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations\")\n","('What is the term for embeddings?', 'vector semantics', \"The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors.\")\n","('What is the name of the cell in the matrix?', 'cell number', 'a word in the vocabulary')\n","('What is the name of the cell in the matrix?', 'cell number', 'a document from some collection of documents')\n","('What is the dot product?', 'a scalar value', 'The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions.')\n","('What is PPMI used for term-term-matrices?', 'positive pointwise mutual information', 'PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.')\n","('What is the centroid document vector d?', 'document vector d = w 1 + w 2 + ... + w ', 'a multidimensional version of the mean')\n","('What is the name of a feedforward network?', 'multilayer feedforward network', 'input units, hidden units, and output units')\n","('What is the probability of the next word w t being V 42?', 'wV count(w, positive) = 0 (4.13)', 'a probability distribution over words')\n","('What is a representation of the process of computing a mathematical expression?', 'computation graph', 'A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.')\n","('What is the name of the word that is a part of speech?', 'noun', 'Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.')\n","('What is a name for a person?', 'a location', 'A named entity is, roughly speaking, anything that can be referred to with a proper name: a person, a location, an organization.')\n","('What is an HMM?', 'a probabilistic sequence model', 'An HMM is a probabilistic sequence model')\n","('What is the main problem of n-gram models of Chapter 3?', 'they depend on the training corpus', 'Anything outside the context window has no impact on the decision being made.')\n","('What is the name of a recurrent neural network?', 'any network that contains a cycle within its network connections', 'any network that contains a cycle within its network connections')\n","('What is the name of the model that predicts a value at time t?', 'bigram model', 'a model that predicts a value at time t based on a linear function of the previous values at times t − 1, t − 2, and so on.')\n","('What is the most commonly used extension to RNNs?', 'backpropagation through time (BPTT)', 'removing information no longer needed from the context, and adding information likely to be needed for later decision making.')\n","(\"What is the first gate we'll consider?\", 'the forget gate', 'delete information from the context that is no longer needed')\n","('What is the simplest form of comparison between elements in a self-attention layer?', 'a dot product', 'their relevance in the current context')\n","('What is the result of a dot product?', 'a scalar value', 'The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating such large values can lead to numerical issues and to an effective loss of gradients during training.')\n","('What is the core of what transformer block?', 'self-attention calculation', 'in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers')\n","('What is the direction of motion marked on the satellite?', 'manner of motion', 'no word or phrase, short of an explanatory footnote, can express the exact meaning of a word in the other language.')\n","('What is the dimension of referential density?', '1', 'Languages that can omit pronouns')\n","('What is the term for the beam width?', 'fixed-size memory footprint', ' In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step.')\n","('What is the name of the decoder transformer block?', 'cross-attention', 'the keys and values come from the output of the encoder.')\n","('What is the chrF metric based on?', 'measuring the exact character n-grams a human reference and candidate machine translation have in', 'The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common.')\n","('What percentage of input tokens in a training sequence are sampled for learning?', '15%', '80%')\n","('What is the training objective of MLM?', 'to predict the inputs for each of the masked tokens.', 'predict the original inputs for each of the masked tokens')\n","('What is the term for sentence embedding?', 'a vector semantics', 'sentence embedding')\n"]}]},{"cell_type":"code","source":["model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n","performance, no_answers, answers = kg_retrieval_pipeline(model, questions_context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7TDBdOahop6","executionInfo":{"status":"ok","timestamp":1681084192231,"user_tz":-120,"elapsed":387498,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"e823b09a-ca79-4a1d-da6a-b31b603e893b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Query is irrelevant.\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["print(f\"Retrieval performance: {performance}\")\n","print(len(no_answers))\n","\n","print(np.asarray(no_answers))\n","\n","np_answers = np.asarray(answers)\n","#np.savetxt(f\"/content/drive/MyDrive/nlp/answers_msmarco-distilbert-base-v3_top_3.csv\", np_answers, delimiter=\",\", fmt=\"%s\")\n","print(np_answers)\n","\n","str_compare = zip(questions_context,np_answers, np.asarray(test_data['answer']))\n","print(\"(Query, Generated Answer, True Answer)\")\n","for item in str_compare:\n","    print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_v7Le2CjZ3w","executionInfo":{"status":"ok","timestamp":1681084280703,"user_tz":-120,"elapsed":1353,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"22e7ddb1-e037-4a25-a6fa-fef135a79de8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Retrieval performance: 0.711864406779661\n","17\n","['What is the study of the way words are built up from smaller meaning-bearing units'\n"," 'What is the general equation for this n-gram approximation to the conditional'\n"," 'What is the name of the modification that is called smoothing or discounting?'\n"," 'What is the probability distribution for words at time t?'\n"," 'What is the probability of every possible combination of features?'\n"," 'What is the opinion lexicon?' 'What is a naive Bayes model?'\n"," 'What percentage of the observations that our system labels correctly?'\n"," 'What is the probability that the document has negative sentiment?'\n"," 'What is the derivative of | |?' 'What is the word sentiment?'\n"," 'What is the dot product?'\n"," 'What is the probability of the next word w t being V 42?'\n"," 'What is the name of the word that is a part of speech?'\n"," 'What is the main problem of n-gram models of Chapter 3?'\n"," 'What is the name of the model that predicts a value at time t?'\n"," 'What is the dimension of referential density?']\n","['cleany star' '(?) syntax' 'tokenizing (segmenting) words'\n"," 'token learner and token segmenter' 'token learner and token segmenter'\n"," 'learning a vocabulary by iteratively merging tokens'\n"," 'word normalization' 'lexicon'\n"," 'determining that two words have the same root'\n"," 'the minimum number of operations it takes to edit one into the other.'\n"," 'n-gram' 'it is a factor in the probability of a .'\n"," 'the n-gram model is a simple, fast way to compute bigram probabilities'\n"," 'maximum likelihood estimation'\n"," 'condition on the previous two words rather than the previous word'\n"," 'a higher probability'\n"," 'on what % of the b samples did algorithm A beat expectations? return p-'\n"," 'lowering some non-zero discounting counts' 'shrunk'\n"," 'the correct sequence of tokens w 1:t' '1' 'QUERY IRRELEVANT'\n"," 'a probabilistic classifier' '92%'\n"," 'cross-validation is a simple, non-invasive way to get an average error rate'\n"," '0' 'gradient descent' 'stochastic gradient descent' '|' 'part of speech'\n"," 'negative' 'Embeddings'\n"," 'the number of times the row (target) word appears in a particular document.'\n"," 'the number of times the row (target) word appears in a particular document.'\n"," 'dot product inner product' 'positive pointwise mutual information'\n"," 'w 1 + w 2 + ... + w k k' 'multilayer feedforward network'\n"," 'it is likely that the next word will be the:.' 'computation graph'\n"," 'NOUN' 'a named entity' 'a probabilistic sequence model'\n"," 'they must be constructed without any knowledge of the test set or of the vocabulary of the test set'\n"," 'any network that contains a cycle within its network connections'\n"," 'w which' 'the long short-term memory (LSTM) network' 'the forget gate'\n"," 'a dot product' 'a scalar value' 'self-attention calculation'\n"," '   g # Go the other way instead return' 'd'\n"," 'fixed-size memory footprint' 'cross-attention'\n"," 'the exact character n-grams a human reference and candidate machine translation have in common'\n"," '15%' 'to predict the inputs for each of the masked tokens.'\n"," 'sentence embedding']\n","(Query, Generated Answer, True Answer)\n","('What is the Kleene * erally pronounced?', 'cleany star', 'The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\"')\n","('What is the name of the lookahead assertions that make use of?', '(?) syntax', 'The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance.')\n","('What is the first step in a normalization process?', 'tokenizing (segmenting) words', '1. Tokenizing (segmenting) words 2. Normalizing word formats 3. Segmenting sentences')\n","('What is the name of the first two tokenization schemes?', 'token learner and token segmenter', 'a token learner, and a token segmenter')\n","('What is the name of the first two tokenization schemes?', 'token learner and token segmenter', 'The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary.')\n","('What is the token learner part of the BPE algorithm?', 'learning a vocabulary by iteratively merging tokens', 'taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.')\n","('What is the task of putting words/tokens in a standard format?', 'word normalization', 'Word normalization is the task of putting words/tokens in a standard format')\n","('What is the study of the way words are built up from smaller meaning-bearing units', 'lexicon', 'The most sophisticated methods for lemmatization involve complete morphological parsing of the word.')\n","('What is the task of Lemmatization?', 'determining that two words have the same root', 'Lemmatization is the task of determining that two words have the same root, despite their surface differences.')\n","('What is the minimum edit distance between two strings?', 'the minimum number of operations it takes to edit one into the other.', 'the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.')\n","('What is the simplest model that assigns probabilities to sequences of words?', 'n-gram', 'Models that assign probabilities to sequences of words are called language models')\n","('What is the probability of a corpus being a factor in the probability of a', 'it is a factor in the probability of a .', 'from relative frequency counts')\n","('What is the general equation for this n-gram approximation to the conditional', 'the n-gram model is a simple, fast way to compute bigram probabilities', 'Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past.')\n","('How do we estimate bigram probabilities?', 'maximum likelihood estimation', 'maximum likelihood estimation or MLE')\n","('What is the name of the trigram model used for?', 'condition on the previous two words rather than the previous word', 'condition on the previous two words rather than the previous word')\n","('What does the better model assign to the test set?', 'a higher probability', 'whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model')\n","('What is the inverse probability of a test set?', 'on what % of the b samples did algorithm A beat expectations? return p-', 'perplexity of a language model on a test set is the inverse probability of the test set, normalized by the number of words.')\n","('What is the name of the modification that is called smoothing or discounting?', 'lowering some non-zero discounting counts', 'smoothing or discounting')\n","('What is another option for a n-gram language model?', 'shrunk', 'pruning')\n","('What is the probability distribution for words at time t?', 'the correct sequence of tokens w 1:t', 'A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index.')\n","('What is the probability of every possible combination of features?', '1', 'without some simplifying assumptions, estimating the probability of every possible combination of features (for example, every possible set of words and positions) would require huge numbers of parameters and impossibly large training sets.')\n","('What is the opinion lexicon?', 'QUERY IRRELEVANT', 'derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment.')\n","('What is a naive Bayes model?', 'a probabilistic classifier', 'dictionaries, URLs, email addresses, network features, phrases')\n","('What percentage of the observations that our system labels correctly?', '92%', \"because accuracy doesn't work well when the classes are unbalanced\")\n","('What is the name of cross-validation?', 'cross-validation is a simple, non-invasive way to get an average error rate', 'k disjoints subsets')\n","('What is the probability that the document has negative sentiment?', '0', 'The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation.')\n","('What is the method that finds a minimum of a function?', 'gradient descent', \"Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters θ ) the function's slope is rising the most steeply, and moving in the opposite direction.\")\n","('What is an online algorithm that minimizes the loss function?', 'stochastic gradient descent', 'Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example')\n","('What is the derivative of | |?', '|', 'L2 regularization is easier to optimize because of its simple derivative')\n","('What is the term for the word \"choosing from 10, 30, or even 50 different', 'part of speech', 'softmax regression')\n","('What is the word sentiment?', 'negative', \"the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations\")\n","('What is the term for embeddings?', 'Embeddings', \"The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors.\")\n","('What is the name of the cell in the matrix?', 'the number of times the row (target) word appears in a particular document.', 'a word in the vocabulary')\n","('What is the name of the cell in the matrix?', 'the number of times the row (target) word appears in a particular document.', 'a document from some collection of documents')\n","('What is the dot product?', 'dot product inner product', 'The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions.')\n","('What is PPMI used for term-term-matrices?', 'positive pointwise mutual information', 'PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.')\n","('What is the centroid document vector d?', 'w 1 + w 2 + ... + w k k', 'a multidimensional version of the mean')\n","('What is the name of a feedforward network?', 'multilayer feedforward network', 'input units, hidden units, and output units')\n","('What is the probability of the next word w t being V 42?', 'it is likely that the next word will be the:.', 'a probability distribution over words')\n","('What is a representation of the process of computing a mathematical expression?', 'computation graph', 'A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.')\n","('What is the name of the word that is a part of speech?', 'NOUN', 'Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.')\n","('What is a name for a person?', 'a named entity', 'A named entity is, roughly speaking, anything that can be referred to with a proper name: a person, a location, an organization.')\n","('What is an HMM?', 'a probabilistic sequence model', 'An HMM is a probabilistic sequence model')\n","('What is the main problem of n-gram models of Chapter 3?', 'they must be constructed without any knowledge of the test set or of the vocabulary of the test set', 'Anything outside the context window has no impact on the decision being made.')\n","('What is the name of a recurrent neural network?', 'any network that contains a cycle within its network connections', 'any network that contains a cycle within its network connections')\n","('What is the name of the model that predicts a value at time t?', 'w which', 'a model that predicts a value at time t based on a linear function of the previous values at times t − 1, t − 2, and so on.')\n","('What is the most commonly used extension to RNNs?', 'the long short-term memory (LSTM) network', 'removing information no longer needed from the context, and adding information likely to be needed for later decision making.')\n","(\"What is the first gate we'll consider?\", 'the forget gate', 'delete information from the context that is no longer needed')\n","('What is the simplest form of comparison between elements in a self-attention layer?', 'a dot product', 'their relevance in the current context')\n","('What is the result of a dot product?', 'a scalar value', 'The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating such large values can lead to numerical issues and to an effective loss of gradients during training.')\n","('What is the core of what transformer block?', 'self-attention calculation', 'in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers')\n","('What is the direction of motion marked on the satellite?', '   g # Go the other way instead return', 'no word or phrase, short of an explanatory footnote, can express the exact meaning of a word in the other language.')\n","('What is the dimension of referential density?', 'd', 'Languages that can omit pronouns')\n","('What is the term for the beam width?', 'fixed-size memory footprint', ' In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step.')\n","('What is the name of the decoder transformer block?', 'cross-attention', 'the keys and values come from the output of the encoder.')\n","('What is the chrF metric based on?', 'the exact character n-grams a human reference and candidate machine translation have in common', 'The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common.')\n","('What percentage of input tokens in a training sequence are sampled for learning?', '15%', '80%')\n","('What is the training objective of MLM?', 'to predict the inputs for each of the masked tokens.', 'predict the original inputs for each of the masked tokens')\n","('What is the term for sentence embedding?', 'sentence embedding', 'sentence embedding')\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76BanfGt-T6Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681084373886,"user_tz":-120,"elapsed":82849,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"2e3aa59a-54ac-4fea-81d8-ff08755eb381"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}],"source":["#question generation model with context and answer as input\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","trained_model_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\n","trained_tokenizer_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\n","model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n","tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer_path)\n","questions_answer = []\n","\n","def generate():\n","    correct_paragraphs = test_data[\"paragraph\"].tolist()\n","    answers = test_data[\"answer\"]\n","\n","    for idx,context in enumerate(correct_paragraphs):\n","      input_text = '<answer> %s <context> %s ' % (answers[idx], context)\n","      encoding = tokenizer.encode_plus(\n","            input_text,\n","            return_tensors='pt'\n","      )\n","      input_ids = encoding['input_ids']\n","      attention_mask = encoding['attention_mask']\n","      outputs = model.generate(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","      )\n","      question = tokenizer.decode(\n","            outputs[0],\n","            skip_special_tokens=True,\n","            clean_up_tokenization_spaces=True\n","      )\n","      questions_answer.append(question)\n","\n","generate()\n","#print(test_data)\n","\n","\n","\n"]},{"cell_type":"code","source":["#questions = test_data['question'].to_list()\n","for i in range(len(questions_answer)):\n","  print(questions_answer[i])\n","  print(questions[i])\n","\n","bleu = evaluate.load(\"bleu\")\n","results = bleu.compute(predictions=questions_answer, references=test_data['question'].to_list(), max_order=1)\n","print(results)\n","results = bleu.compute(predictions=questions_answer, references=test_data['question'].to_list(), max_order=2)\n","print(results)\n","results = bleu.compute(predictions=questions_answer, references=test_data['question'].to_list(), max_order=3)\n","print(results)\n","results = bleu.compute(predictions=questions_answer, references=test_data['question'].to_list(), max_order=4)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWbtlZiSm2bP","executionInfo":{"status":"ok","timestamp":1681084483565,"user_tz":-120,"elapsed":3795,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"8f9200c3-06b4-4ce7-caac-4e5d0c09ae4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What does the Kleene star mean?\n","What is the meaning of the Kleene star in Regex?\n","What is the result of the operator?\n","What is the usage of the Regex lookahead operator \"?=\"?\n","What are the three tasks that are commonly applied as part of any normalization process?\n","What are the most common steps in a text normalization process?\n","What are the two parts of most tokenization schemes?\n","What are the two most common components of a tokenization scheme?\n","What is the token segmenter?\n","What is the purpose of a token segmenter?\n","What is the token learner part of the BPE algorithm used for?\n","What is the purpose of a token learner in the BPE algorithm?\n","What is the task of word normalization?\n","What is word normalization?\n","What is the most sophisticated method for lemmatization?\n","How is lemmatization performed?\n","What is the task of determining that two words have the same root?\n","What is lemmatization?\n","What is the minimum edit distance between two strings defined as?\n","How is the minimum edit distance between two strings defined?\n","What are LMs?\n","What is a language model?\n","How can one estimate probability?\n","How can we estimate the probability of a word?\n","What are Markov models?\n","What is a Markov model?\n","What is an intuitive way to estimate probabilities?\n","What technique can be used to estimate n-gram probabilities?\n","What is a trigram model?\n","What is the difference between bigram and trigram models?\n","What is the answer to \"fit the test set\"?\n","How can two probabilisting language models be compared on a test set?\n","What is the perplexity of a language model on a test set?\n","What is the perplexity of a language model?\n","What is the modification of probability mass called?\n","How can language models be prevented from assigning zero probability to unknown words?\n","How can an n-gram language model be shrunk?\n","What technique can be used to shrink an n-gram language model?\n","What is the condition for a stochastic process to be stationary?\n","When is a stochastic process said to be stationary?\n","What is the problem with Eq. 4.6?\n","Why are simplifying assumptions needed when using a Naive Bayes Classifier?\n","What can we do instead of using training data to estimate positive and negative sentiment?\n","What can be done to optimize Naive Bayes when an insufficient amount of labeled data is present?\n","What can naive Bayes classifiers use?\n","What type of features can be used to train a Naive Bayes classifier?\n","Why don't we use accuracy for text classification tasks?\n","Why is accuracy rarely used alone for unbalanced text classification tasks?\n","What are folds?\n","What are folds in cross-validation?\n","What is the goal of binary logistic regression?\n","What is the purpose of logistic regression?\n","What is the method called that finds a minimum of a function?\n","What is gradient descent?\n","What is an online algorithm that minimizes the loss function?\n","What is stochastic gradient descent?\n","Why is L2 regularization easier to optimize?\n","Which regularization technique is easier to optimize?\n","What is another name for multinomial logistic regression?\n","What is the other name of multinomial logistic regression?\n","What does the word connotations mean?\n","What are word connotations?\n","What is the idea of vector semantics?\n","What is the idea behind vector semantics?\n","What does each row represent in a term-document matrix?\n","What do rows represent in a term-document matrix?\n","What does each term-document matrix column represent?\n","What do columns represent in a term-document matrix?\n","What is the dot product used for?\n","Why can dot product be used as a similarity metric?\n","What is the PPMI function?\n","What is the intuition behind PPMI?\n","What is the centroid?\n","What is a centroid?\n","What are the three types of nodes in a feedforward network?\n","What are the three type of nodes in a feedforward neural network?\n","What does the output layer produce?\n","What is the output of the output layer's softmax in a neural language model?\n","What is a computation graph?\n","What is a computation graph?\n","What is part of speech tagging?\n","What is part-of-speech tagging?\n","What is a named entity?\n","What are named entities?\n","What is an HMM?\n","What is a Hidden Markov Model?\n","What is the main weakness of n-gram approaches?\n","Why is limited context a limitation of feedforward neural networks?\n","What is a recurrent neural network?\n","What is a recurrent neural network?\n","What is an autoregressive model?\n","What is an autoregressive language model?\n","What are the two sub-problems of context management?\n","What are the two subproblems derived from the context management problem by LSTMs?\n","What is the forget gate supposed to do?\n","What is the purpose of a forget gate in the LSTM architecture?\n","What does the comparison of an item of interest to a collection of other items reveal?\n","What is expressed in the attention-based approach by comparing items in a collection?\n","What is one of the problems with using a dot product?\n","Why does the dot product output need to be scaled in the attention computation?\n","What is the core of a transformer block?\n","What components constitute a transformer block?\n","What is a lexical gap?\n","What is a lexical gap?\n","What are pro-drop languages?\n","What are pro-drop languages?\n","What is the method called beam search?\n","How does the beam search decoding algorithm operate?\n","Where do the keys and values come from?\n","What is the difference between cross-attention and multi-head self-attention?\n","What is the chrF metric based on?\n","How is the chrF evaluation metric for MT computed?\n","What percentage of input tokens are replaced with [MASK]?\n","What percentage of tokens sampled for learning are replaced with the [MASK] token during BERT pre-training?\n","What is the MLM training objective?\n","What is the Masked Language Modeling training objective?\n","What is the vector that stands for the entire sequence called?\n","What role does the [CLS] token play in BERT?\n","{'bleu': 0.5492190277253026, 'precisions': [0.5973282442748091], 'brevity_penalty': 0.9194593307605706, 'length_ratio': 0.9225352112676056, 'translation_length': 524, 'reference_length': 568}\n","{'bleu': 0.40360654734022355, 'precisions': [0.5973282442748091, 0.3225806451612903], 'brevity_penalty': 0.9194593307605706, 'length_ratio': 0.9225352112676056, 'translation_length': 524, 'reference_length': 568}\n","{'bleu': 0.3090325990674543, 'precisions': [0.5973282442748091, 0.3225806451612903, 0.19704433497536947], 'brevity_penalty': 0.9194593307605706, 'length_ratio': 0.9225352112676056, 'translation_length': 524, 'reference_length': 568}\n","{'bleu': 0.23500122980165988, 'precisions': [0.5973282442748091, 0.3225806451612903, 0.19704433497536947, 0.11239193083573487], 'brevity_penalty': 0.9194593307605706, 'length_ratio': 0.9225352112676056, 'translation_length': 524, 'reference_length': 568}\n"]}]},{"cell_type":"code","source":["meteor = evaluate.load('meteor')\n","results = meteor.compute(predictions=questions_answer, references=test_data['question'].to_list())\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FkE0OhFgTYi","executionInfo":{"status":"ok","timestamp":1681085709513,"user_tz":-120,"elapsed":1535,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"f9ff24e8-d138-4798-92db-fd3566bbf90a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'meteor': 0.5605552780231466}\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["#test model question generation with answer + context\n","model = SentenceTransformer(\"sentence-transformers/msmarco-roberta-base-v2\")\n","performance, no_answers, answers = kg_retrieval_pipeline(model, questions_answer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxFw4yEhryir","executionInfo":{"status":"ok","timestamp":1681084942011,"user_tz":-120,"elapsed":413092,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"4fb10587-ea56-4bc1-c6d2-4d6e37a5a325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (922 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["print(f\"Retrieval performance: {performance}\")\n","print(len(no_answers))\n","\n","print(np.asarray(no_answers))\n","\n","np_answers = np.asarray(answers)\n","#np.savetxt(f\"/content/drive/MyDrive/nlp/answers_msmarco-distilbert-base-v3_top_3.csv\", np_answers, delimiter=\",\", fmt=\"%s\")\n","print(np_answers)\n","\n","str_compare = zip(questions_answer,np_answers, np.asarray(test_data['answer']))\n","print(\"(Query, Generated Answer, True Answer)\")\n","for item in str_compare:\n","    print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA9gm8MVsB3r","executionInfo":{"status":"ok","timestamp":1681084977035,"user_tz":-120,"elapsed":505,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"194f0bde-6b00-4b7c-e5a1-e4ef94694a95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Retrieval performance: 0.7627118644067796\n","14\n","['What is the result of the operator?'\n"," 'What is the task of determining that two words have the same root?'\n"," 'What are LMs?' 'How can one estimate probability?'\n"," 'What are Markov models?'\n"," 'What is the modification of probability mass called?'\n"," 'What is the problem with Eq. 4.6?'\n"," 'What is the method called that finds a minimum of a function?'\n"," 'What is an online algorithm that minimizes the loss function?'\n"," 'What is the idea of vector semantics?'\n"," 'What is the dot product used for?' 'What does the output layer produce?'\n"," 'What is the main weakness of n-gram approaches?'\n"," 'Where do the keys and values come from?']\n","['zero or more occurrences of the immediately previous character or regular expression'\n"," 'the output is 1 for the inputs'\n"," 'normalizing word formats 3. Normalizing sentence formats'\n"," 'token learner, and token segmenter'\n"," 'token segmenter is a set of tokens that are used to tokenize a test'\n"," 'learning a vocabulary' 'putting words/tokens in a standard format'\n"," 'complete morphological parsing of the word' '.'\n"," 'the minimum number of operations it takes to edit one into the other.'\n"," 'feedforward neural LM' 'by using the probability' 'a model markov chain'\n"," 'maximum likelihood estimation'\n"," 'a three-word sequence of words like \"please turn your\" or \"turn your homework'\n"," 'whichever model assigns a higher probability to the test set is the better model'\n"," 'the inverse probability of the test set, normalized by the number of words.'\n"," 'add-k smoothing' 'pruning'\n"," 'the probabilities assigned to a Stationary sequence are invariant with respect to shifts'\n"," 'we will be computing P(d|c)P(c)'\n"," 'we can derive the positive and negative word features from sentiment lexicons.'\n"," 'any sort of feature'\n"," \"because accuracy doesn't work well when the classes are unbalanced\"\n"," 'k disjoint subsets of data'\n"," 'to train a classifier that can make a binary decision about the class of an input'\n"," 'p-value(x)  s + 1 if ' 'gradient descent'\n"," 'because of its simple derivative' 'softmax regression'\n"," \"connotations are the aspects of a word's meaning that are related to a\"\n"," 'the standard way to represent word meaning in NLP'\n"," 'a word in the vocabulary' 'a document from a collection of documents'\n"," 'to compute similarity scores' 'positive pointwise mutual information'\n"," 'a single vector with the minimum sum of squared distances to each of the vectors'\n"," 'input units, hidden units, and output units' 'a final output'\n"," 'a representation of the process of computing a mathematical expression'\n"," 'assigning a part-of-speech label to each of a sequence of'\n"," 'anything that can be referred to with a proper name'\n"," 'a probabilistic sequence model' '.'\n"," 'any network that contains a cycle within its network connections'\n"," 'a model that predicts a value at time t based on a linear'\n"," 'removing information from the context and adding information likely to be needed for later decision making'\n"," 'delete information from the context that is no longer needed'\n"," 'their relevance in the current context' 'it favors long vectors'\n"," 'self-attention calculation'\n"," 'no word or phrase, short of an explanatory footnote, can express the exact meaning'\n"," 'languages that can omit pronouns'\n"," 'a z-axis is generated indicating that the complete candidate output has been found'\n"," 'k'\n"," 'measuring the exact character n-grams a human reference and candidate machine translation have in'\n"," '80%' 'to predict the original inputs for each of the masked tokens.'\n"," 'sentence embedding']\n","(Query, Generated Answer, True Answer)\n","('What does the Kleene star mean?', 'zero or more occurrences of the immediately previous character or regular expression', 'The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\"')\n","('What is the result of the operator?', 'the output is 1 for the inputs', 'The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance.')\n","('What are the three tasks that are commonly applied as part of any normalization process?', 'normalizing word formats 3. Normalizing sentence formats', '1. Tokenizing (segmenting) words 2. Normalizing word formats 3. Segmenting sentences')\n","('What are the two parts of most tokenization schemes?', 'token learner, and token segmenter', 'a token learner, and a token segmenter')\n","('What is the token segmenter?', 'token segmenter is a set of tokens that are used to tokenize a test', 'The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary.')\n","('What is the token learner part of the BPE algorithm used for?', 'learning a vocabulary', 'taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.')\n","('What is the task of word normalization?', 'putting words/tokens in a standard format', 'Word normalization is the task of putting words/tokens in a standard format')\n","('What is the most sophisticated method for lemmatization?', 'complete morphological parsing of the word', 'The most sophisticated methods for lemmatization involve complete morphological parsing of the word.')\n","('What is the task of determining that two words have the same root?', '.', 'Lemmatization is the task of determining that two words have the same root, despite their surface differences.')\n","('What is the minimum edit distance between two strings defined as?', 'the minimum number of operations it takes to edit one into the other.', 'the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.')\n","('What are LMs?', 'feedforward neural LM', 'Models that assign probabilities to sequences of words are called language models')\n","('How can one estimate probability?', 'by using the probability', 'from relative frequency counts')\n","('What are Markov models?', 'a model markov chain', 'Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past.')\n","('What is an intuitive way to estimate probabilities?', 'maximum likelihood estimation', 'maximum likelihood estimation or MLE')\n","('What is a trigram model?', 'a three-word sequence of words like \"please turn your\" or \"turn your homework', 'condition on the previous two words rather than the previous word')\n","('What is the answer to \"fit the test set\"?', 'whichever model assigns a higher probability to the test set is the better model', 'whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model')\n","('What is the perplexity of a language model on a test set?', 'the inverse probability of the test set, normalized by the number of words.', 'perplexity of a language model on a test set is the inverse probability of the test set, normalized by the number of words.')\n","('What is the modification of probability mass called?', 'add-k smoothing', 'smoothing or discounting')\n","('How can an n-gram language model be shrunk?', 'pruning', 'pruning')\n","('What is the condition for a stochastic process to be stationary?', 'the probabilities assigned to a Stationary sequence are invariant with respect to shifts', 'A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index.')\n","('What is the problem with Eq. 4.6?', 'we will be computing P(d|c)P(c)', 'without some simplifying assumptions, estimating the probability of every possible combination of features (for example, every possible set of words and positions) would require huge numbers of parameters and impossibly large training sets.')\n","('What can we do instead of using training data to estimate positive and negative sentiment?', 'we can derive the positive and negative word features from sentiment lexicons.', 'derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment.')\n","('What can naive Bayes classifiers use?', 'any sort of feature', 'dictionaries, URLs, email addresses, network features, phrases')\n","(\"Why don't we use accuracy for text classification tasks?\", \"because accuracy doesn't work well when the classes are unbalanced\", \"because accuracy doesn't work well when the classes are unbalanced\")\n","('What are folds?', 'k disjoint subsets of data', 'k disjoints subsets')\n","('What is the goal of binary logistic regression?', 'to train a classifier that can make a binary decision about the class of an input', 'The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation.')\n","('What is the method called that finds a minimum of a function?', 'p-value(x)  s + 1 if ', \"Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters θ ) the function's slope is rising the most steeply, and moving in the opposite direction.\")\n","('What is an online algorithm that minimizes the loss function?', 'gradient descent', 'Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example')\n","('Why is L2 regularization easier to optimize?', 'because of its simple derivative', 'L2 regularization is easier to optimize because of its simple derivative')\n","('What is another name for multinomial logistic regression?', 'softmax regression', 'softmax regression')\n","('What does the word connotations mean?', \"connotations are the aspects of a word's meaning that are related to a\", \"the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations\")\n","('What is the idea of vector semantics?', 'the standard way to represent word meaning in NLP', \"The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors.\")\n","('What does each row represent in a term-document matrix?', 'a word in the vocabulary', 'a word in the vocabulary')\n","('What does each term-document matrix column represent?', 'a document from a collection of documents', 'a document from some collection of documents')\n","('What is the dot product used for?', 'to compute similarity scores', 'The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions.')\n","('What is the PPMI function?', 'positive pointwise mutual information', 'PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.')\n","('What is the centroid?', 'a single vector with the minimum sum of squared distances to each of the vectors', 'a multidimensional version of the mean')\n","('What are the three types of nodes in a feedforward network?', 'input units, hidden units, and output units', 'input units, hidden units, and output units')\n","('What does the output layer produce?', 'a final output', 'a probability distribution over words')\n","('What is a computation graph?', 'a representation of the process of computing a mathematical expression', 'A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.')\n","('What is part of speech tagging?', 'assigning a part-of-speech label to each of a sequence of', 'Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.')\n","('What is a named entity?', 'anything that can be referred to with a proper name', 'A named entity is, roughly speaking, anything that can be referred to with a proper name: a person, a location, an organization.')\n","('What is an HMM?', 'a probabilistic sequence model', 'An HMM is a probabilistic sequence model')\n","('What is the main weakness of n-gram approaches?', '.', 'Anything outside the context window has no impact on the decision being made.')\n","('What is a recurrent neural network?', 'any network that contains a cycle within its network connections', 'any network that contains a cycle within its network connections')\n","('What is an autoregressive model?', 'a model that predicts a value at time t based on a linear', 'a model that predicts a value at time t based on a linear function of the previous values at times t − 1, t − 2, and so on.')\n","('What are the two sub-problems of context management?', 'removing information from the context and adding information likely to be needed for later decision making', 'removing information no longer needed from the context, and adding information likely to be needed for later decision making.')\n","('What is the forget gate supposed to do?', 'delete information from the context that is no longer needed', 'delete information from the context that is no longer needed')\n","('What does the comparison of an item of interest to a collection of other items reveal?', 'their relevance in the current context', 'their relevance in the current context')\n","('What is one of the problems with using a dot product?', 'it favors long vectors', 'The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating such large values can lead to numerical issues and to an effective loss of gradients during training.')\n","('What is the core of a transformer block?', 'self-attention calculation', 'in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers')\n","('What is a lexical gap?', 'no word or phrase, short of an explanatory footnote, can express the exact meaning', 'no word or phrase, short of an explanatory footnote, can express the exact meaning of a word in the other language.')\n","('What are pro-drop languages?', 'languages that can omit pronouns', 'Languages that can omit pronouns')\n","('What is the method called beam search?', 'a z-axis is generated indicating that the complete candidate output has been found', ' In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step.')\n","('Where do the keys and values come from?', 'k', 'the keys and values come from the output of the encoder.')\n","('What is the chrF metric based on?', 'measuring the exact character n-grams a human reference and candidate machine translation have in', 'The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common.')\n","('What percentage of input tokens are replaced with [MASK]?', '80%', '80%')\n","('What is the MLM training objective?', 'to predict the original inputs for each of the masked tokens.', 'predict the original inputs for each of the masked tokens')\n","('What is the vector that stands for the entire sequence called?', 'sentence embedding', 'sentence embedding')\n"]}]},{"cell_type":"code","source":["model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v3\")\n","performance, no_answers, answers = kg_retrieval_pipeline(model, questions_answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XGbfs0NjvE2","executionInfo":{"status":"ok","timestamp":1681085394200,"user_tz":-120,"elapsed":402732,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"c3de2637-2587-4c12-fc74-c38a9b8b14dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Query is irrelevant.\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["print(f\"Retrieval performance: {performance}\")\n","print(len(no_answers))\n","\n","print(np.asarray(no_answers))\n","\n","np_answers = np.asarray(answers)\n","#np.savetxt(f\"/content/drive/MyDrive/nlp/answers_msmarco-distilbert-base-v3_top_3.csv\", np_answers, delimiter=\",\", fmt=\"%s\")\n","print(np_answers)\n","\n","str_compare = zip(questions_answer,np_answers, np.asarray(test_data['answer']))\n","print(\"(Query, Generated Answer, True Answer)\")\n","for item in str_compare:\n","    print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySa3w6G9lxgU","executionInfo":{"status":"ok","timestamp":1681085436313,"user_tz":-120,"elapsed":9,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"2c75c13f-9875-4163-8b59-c3da2e2a6d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Retrieval performance: 0.7966101694915254\n","12\n","['What is the result of the operator?'\n"," 'What is the most sophisticated method for lemmatization?'\n"," 'What are LMs?' 'How can one estimate probability?'\n"," 'What is the modification of probability mass called?'\n"," 'What is the problem with Eq. 4.6?'\n"," 'What is another name for multinomial logistic regression?'\n"," 'What is the idea of vector semantics?'\n"," 'What is the dot product used for?'\n"," 'What does the comparison of an item of interest to a collection of other items reveal?'\n"," 'What is a lexical gap?' 'Where do the keys and values come from?']\n","['zero or more occurrences of the immediately previous character or regular expression'\n"," 'a score'\n"," 'tokenizing (segmenting) words 2. Normalizing word formats 3. Segment'\n"," 'token learner, and token segmenter'\n"," 'token segmenter is a part of a tokenization scheme that takes a test sentence'\n"," 'learning a vocabulary' 'putting words/tokens in a standard format'\n"," 'symbolics' 'lemmatization'\n"," 'the minimum number of operations it takes to edit one into the other.'\n"," 'QUERY IRRELEVANT' 'by using relative frequencies' 'probabilistic models'\n"," 'maximum likelihood estimation'\n"," 'condition on the previous two words rather than the previous word'\n"," 'whichever model assigns a higher probability to the test set is the better model'\n"," 'the inverse probability of the test set, normalized by the number of words.'\n"," '' 'pruning'\n"," 'the probabilities assigned to a Stationary sequence are invariant with respect to shifts'\n"," 'we will be computing P(d|c)P(c).'\n"," 'we can derive the positive and negative word features from sentiment lexicons.'\n"," 'any sort of feature'\n"," \"because accuracy doesn't work well when the classes are unbalanced\"\n"," 'k disjoint subsets of data'\n"," 'to train a classifier to make a binary decision about the class of a new'\n"," 'gradient descent' 'stochastic gradient descent' 'its simple derivative'\n"," 'logistic regression'\n"," \"connotations means the aspects of a word's meaning that are related to a\"\n"," 'the standard way to represent word meaning in NLP'\n"," 'a word in the vocabulary' 'a document from a collection of documents'\n"," 'to measure how similar the decoder hidden state is to an encoder hidden state'\n"," 'P(w)P  (c) , 0'\n"," 'a single vector that has the minimum sum of squared distances to each of the vector'\n"," 'input units, hidden units, and output units' 'a final output'\n"," 'a representation of the process of computing a mathematical expression'\n"," 'assigning a part-of-speech label to each of a sequence of'\n"," 'anything that can be referred to with a named entity proper name'\n"," 'a probabilistic sequence model' 'limited context'\n"," 'any network that contains a cycle within its network connections'\n"," 'a model that predicts a value at time t based on a linear'\n"," 'removing information from the context and adding information likely to be needed for later decision making'\n"," 'delete information from the context that is no longer needed'\n"," 'that the item of interest is larger than a single word.'\n"," 'it favors long vectors' 'self-attention calculation'\n"," 'a lexical gap is a gap between the system output and the gold output.'\n"," 'languages that can omit pronouns' 'decoding' 'from the input vectors'\n"," 'the exact character n-grams a human reference and candidate machine translation have in common'\n"," '80%' 'to predict the original inputs for each of the masked tokens.'\n"," 'sentence embedding']\n","(Query, Generated Answer, True Answer)\n","('What does the Kleene star mean?', 'zero or more occurrences of the immediately previous character or regular expression', 'The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\"')\n","('What is the result of the operator?', 'a score', 'The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance.')\n","('What are the three tasks that are commonly applied as part of any normalization process?', 'tokenizing (segmenting) words 2. Normalizing word formats 3. Segment', '1. Tokenizing (segmenting) words 2. Normalizing word formats 3. Segmenting sentences')\n","('What are the two parts of most tokenization schemes?', 'token learner, and token segmenter', 'a token learner, and a token segmenter')\n","('What is the token segmenter?', 'token segmenter is a part of a tokenization scheme that takes a test sentence', 'The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary.')\n","('What is the token learner part of the BPE algorithm used for?', 'learning a vocabulary', 'taking a corpus broken up into individual characters or bytes, and learning a vocabulary by iteratively merging tokens.')\n","('What is the task of word normalization?', 'putting words/tokens in a standard format', 'Word normalization is the task of putting words/tokens in a standard format')\n","('What is the most sophisticated method for lemmatization?', 'symbolics', 'The most sophisticated methods for lemmatization involve complete morphological parsing of the word.')\n","('What is the task of determining that two words have the same root?', 'lemmatization', 'Lemmatization is the task of determining that two words have the same root, despite their surface differences.')\n","('What is the minimum edit distance between two strings defined as?', 'the minimum number of operations it takes to edit one into the other.', 'the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.')\n","('What are LMs?', 'QUERY IRRELEVANT', 'Models that assign probabilities to sequences of words are called language models')\n","('How can one estimate probability?', 'by using relative frequencies', 'from relative frequency counts')\n","('What are Markov models?', 'probabilistic models', 'Markov models are the class of probabilistic models Markov that assume we can predict the probability of some future unit without looking too far into the past.')\n","('What is an intuitive way to estimate probabilities?', 'maximum likelihood estimation', 'maximum likelihood estimation or MLE')\n","('What is a trigram model?', 'condition on the previous two words rather than the previous word', 'condition on the previous two words rather than the previous word')\n","('What is the answer to \"fit the test set\"?', 'whichever model assigns a higher probability to the test set is the better model', 'whichever model assigns a higher probability to the test set-meaning it more accurately predicts the test set-is a better model')\n","('What is the perplexity of a language model on a test set?', 'the inverse probability of the test set, normalized by the number of words.', 'perplexity of a language model on a test set is the inverse probability of the test set, normalized by the number of words.')\n","('What is the modification of probability mass called?', '', 'smoothing or discounting')\n","('How can an n-gram language model be shrunk?', 'pruning', 'pruning')\n","('What is the condition for a stochastic process to be stationary?', 'the probabilities assigned to a Stationary sequence are invariant with respect to shifts', 'A stochastic process is said to be stationary if the probabilities it assigns to a Stationary sequence are invariant with respect to shifts in the time index.')\n","('What is the problem with Eq. 4.6?', 'we will be computing P(d|c)P(c).', 'without some simplifying assumptions, estimating the probability of every possible combination of features (for example, every possible set of words and positions) would require huge numbers of parameters and impossibly large training sets.')\n","('What can we do instead of using training data to estimate positive and negative sentiment?', 'we can derive the positive and negative word features from sentiment lexicons.', 'derive the positive and negative word features from sentiment lexicons, lists of words that are pre-sentiment lexicons annotated with positive or negative sentiment.')\n","('What can naive Bayes classifiers use?', 'any sort of feature', 'dictionaries, URLs, email addresses, network features, phrases')\n","(\"Why don't we use accuracy for text classification tasks?\", \"because accuracy doesn't work well when the classes are unbalanced\", \"because accuracy doesn't work well when the classes are unbalanced\")\n","('What are folds?', 'k disjoint subsets of data', 'k disjoints subsets')\n","('What is the goal of binary logistic regression?', 'to train a classifier to make a binary decision about the class of a new', 'The goal of binary logistic regression is to train a classifier that can make a binary decision about the class of a new input observation.')\n","('What is the method called that finds a minimum of a function?', 'gradient descent', \"Gradient descent is a method that finds a minimum of a function by figuring out in which direction (in the space of the parameters θ ) the function's slope is rising the most steeply, and moving in the opposite direction.\")\n","('What is an online algorithm that minimizes the loss function?', 'stochastic gradient descent', 'Stochastic gradient descent is an online algorithm that minimizes the loss function by computing its gradient after each training example')\n","('Why is L2 regularization easier to optimize?', 'its simple derivative', 'L2 regularization is easier to optimize because of its simple derivative')\n","('What is another name for multinomial logistic regression?', 'logistic regression', 'softmax regression')\n","('What does the word connotations mean?', \"connotations means the aspects of a word's meaning that are related to a\", \"the aspects of a word's meaning that are related to a writer or reader's emotions, sentiment, opinions, or evaluations\")\n","('What is the idea of vector semantics?', 'the standard way to represent word meaning in NLP', \"The idea of vector semantics is to represent a word as a point in a multidimensional semantic space that is derived (in ways we'll see) from the distributions of word neighbors.\")\n","('What does each row represent in a term-document matrix?', 'a word in the vocabulary', 'a word in the vocabulary')\n","('What does each term-document matrix column represent?', 'a document from a collection of documents', 'a document from some collection of documents')\n","('What is the dot product used for?', 'to measure how similar the decoder hidden state is to an encoder hidden state', 'The dot product acts as a similarity metric because it will tend to be high just when the two vectors have large values in the same dimensions.')\n","('What is the PPMI function?', 'P(w)P  (c) , 0', 'PPMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.')\n","('What is the centroid?', 'a single vector that has the minimum sum of squared distances to each of the vector', 'a multidimensional version of the mean')\n","('What are the three types of nodes in a feedforward network?', 'input units, hidden units, and output units', 'input units, hidden units, and output units')\n","('What does the output layer produce?', 'a final output', 'a probability distribution over words')\n","('What is a computation graph?', 'a representation of the process of computing a mathematical expression', 'A computation graph is a representation of the process of computing a mathematical expression, in which the computation is broken down into separate operations, each of which is modeled as a node in a graph.')\n","('What is part of speech tagging?', 'assigning a part-of-speech label to each of a sequence of', 'Part-of-speech tagging is the process of assigning a part-of-speech to each word in a text.')\n","('What is a named entity?', 'anything that can be referred to with a named entity proper name', 'A named entity is, roughly speaking, anything that can be referred to with a proper name: a person, a location, an organization.')\n","('What is an HMM?', 'a probabilistic sequence model', 'An HMM is a probabilistic sequence model')\n","('What is the main weakness of n-gram approaches?', 'limited context', 'Anything outside the context window has no impact on the decision being made.')\n","('What is a recurrent neural network?', 'any network that contains a cycle within its network connections', 'any network that contains a cycle within its network connections')\n","('What is an autoregressive model?', 'a model that predicts a value at time t based on a linear', 'a model that predicts a value at time t based on a linear function of the previous values at times t − 1, t − 2, and so on.')\n","('What are the two sub-problems of context management?', 'removing information from the context and adding information likely to be needed for later decision making', 'removing information no longer needed from the context, and adding information likely to be needed for later decision making.')\n","('What is the forget gate supposed to do?', 'delete information from the context that is no longer needed', 'delete information from the context that is no longer needed')\n","('What does the comparison of an item of interest to a collection of other items reveal?', 'that the item of interest is larger than a single word.', 'their relevance in the current context')\n","('What is one of the problems with using a dot product?', 'it favors long vectors', 'The result of a dot product can be an arbitrarily large (positive or negative) value. Exponentiating such large values can lead to numerical issues and to an effective loss of gradients during training.')\n","('What is the core of a transformer block?', 'self-attention calculation', 'in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers')\n","('What is a lexical gap?', 'a lexical gap is a gap between the system output and the gold output.', 'no word or phrase, short of an explanatory footnote, can express the exact meaning of a word in the other language.')\n","('What are pro-drop languages?', 'languages that can omit pronouns', 'Languages that can omit pronouns')\n","('What is the method called beam search?', 'decoding', ' In beam search, instead of choosing the best token beam search to generate at each timestep, we keep k possible tokens at each step.')\n","('Where do the keys and values come from?', 'from the input vectors', 'the keys and values come from the output of the encoder.')\n","('What is the chrF metric based on?', 'the exact character n-grams a human reference and candidate machine translation have in common', 'The chrF metric is based on measuring the exact character n-grams a human reference and candidate machine translation have in common.')\n","('What percentage of input tokens are replaced with [MASK]?', '80%', '80%')\n","('What is the MLM training objective?', 'to predict the original inputs for each of the masked tokens.', 'predict the original inputs for each of the masked tokens')\n","('What is the vector that stands for the entire sequence called?', 'sentence embedding', 'sentence embedding')\n"]}]},{"cell_type":"code","source":["#Analyse the contexts \n","\n","print(test_data['paragraph'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Thk5GWgiZXI","executionInfo":{"status":"ok","timestamp":1681086364069,"user_tz":-120,"elapsed":518,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"69a076e3-1f74-42df-f17c-64cd90fdc7e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This language consists of strings with a b, followed by at least two a's, followed by an exclamation point. The set of operators that allows us to say things like \"some number of as\" are based on the asterisk or *, commonly called the Kleene * (gen-Kleene * erally pronounced \"cleany star\"). The Kleene star means \"zero or more occurrences of the immediately previous character or regular expression\". So /a*/ means \"any string of zero or more as\". This will match a or aaaaaa, but it will also match Off Minor since the string Off Minor has zero a's. So the regular expression for matching one or more a is /aa*/, meaning one a followed by zero or more as. More complex patterns can also be repeated. So /[ab]*/ means \"zero or more a's or b's\" (not \"zero or more right square braces\"). This will match strings like aaaa or ababab or bbbb.\n"]}]},{"cell_type":"code","source":["print(test_data['paragraph'][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCcF1QFdjz6y","executionInfo":{"status":"ok","timestamp":1681086438965,"user_tz":-120,"elapsed":858,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"90a734e4-3667-4166-d693-708fb9eb82d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["These lookahead assertions make use of the (? syntax that we saw in the previous section for non-capture groups. The operator (?= pattern) is true if pattern occurs, but is zero-width, i.e. the match pointer doesn’t advance. The operator (?! pattern) only returns true if a pattern does not match, but again is zero-width and doesn’t advance the cursor. Negative lookahead is commonly used when we are parsing some complex pattern but want to rule out a special case. For example suppose we want to match, at the beginning of a line, any single word that doesn’t start with “Volcano”. We can use negative lookahead to do this: /ˆ(?!Volcano)[A-Za-z]+/\n"]}]},{"cell_type":"code","source":["print(test_data['paragraph'][3])\n","print(test_data['question'][3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Npl5KC8j-On","executionInfo":{"status":"ok","timestamp":1681086898336,"user_tz":-120,"elapsed":9,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"5e7f3dbd-f674-4d1e-ec64-4132704fbcb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Most tokenization schemes have two parts: a token learner, and a token segmenter. The token learner takes a raw training corpus (sometimes roughly preseparated into words, for example by whitespace) and induces a vocabulary, a set of tokens. The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary. Three algorithms are widely used: byte-pair encoding (Sennrich et al., 2016) , unigram language modeling (Kudo, 2018) , and WordPiece (Schuster and Nakajima, 2012) ; there is also a SentencePiece library that includes implementations of the first two of the three (Kudo and Richardson, 2018) .\n","What are the two most common components of a tokenization scheme?\n"]}]},{"cell_type":"code","source":["print(test_data['paragraph'][4])\n","print(test_data['question'][4])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJZvrXFzkzSv","executionInfo":{"status":"ok","timestamp":1681086903119,"user_tz":-120,"elapsed":9,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"fb514b43-b310-4a64-e3f4-8d9e12f91c56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Most tokenization schemes have two parts: a token learner, and a token segmenter. The token learner takes a raw training corpus (sometimes roughly preseparated into words, for example by whitespace) and induces a vocabulary, a set of tokens. The token segmenter takes a raw test sentence and segments it into the tokens in the vocabulary. Three algorithms are widely used: byte-pair encoding (Sennrich et al., 2016) , unigram language modeling (Kudo, 2018) , and WordPiece (Schuster and Nakajima, 2012) ; there is also a SentencePiece library that includes implementations of the first two of the three (Kudo and Richardson, 2018) .\n","What is the purpose of a token segmenter?\n"]}]},{"cell_type":"code","source":["print(test_data['paragraph'][50])\n","print(test_data['answer'][50])\n","print(test_data['question'][50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ii8aRn77qq5d","executionInfo":{"status":"ok","timestamp":1681090148324,"user_tz":-120,"elapsed":8,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"3044b5e7-7dcc-4c42-890c-473cbecd7948"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The self-attention calculation lies at the core of what's called a transformer block, which, in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers. The input and output dimensions of these blocks are matched so they can be stacked just as was the case for stacked RNNs. Fig. 9 .18 illustrates a standard transformer block consisting of a single attention layer followed by a fully-connected feedforward layer with residual connections and layer normalizations following each. We've already seen feedforward layers in Chapter 7, but what are residual connections and layer norm? In deep networks, residual connections are connections that pass information from a lower layer to a higher layer without going through the intermediate layer. Allowing information from the activation going forward and the gradient going backwards to skip a layer improves learning and gives higher level layers direct access to information from lower layers (He et al., 2016) . Residual connections in transformers are implemented by added a layer's input vector to its output vector before passing it forward . In the transformer block shown in Fig. 9 .18, residual connections are used with both the attention and feedforward sublayers. These summed vectors are then normalized using layer normalization (Ba et al., 2016 ). If we think of a layer as one long vector of units, the resulting function computed in a transformer block can be expressed as:\n","in addition to the self-attention layer, includes additional feedforward layers, residual connections, and normalizing layers\n","What components constitute a transformer block?\n"]}]},{"cell_type":"code","source":["print(test_data['paragraph'][42])\n","print(test_data['answer'][42])\n","print(test_data['question'][42])\n","\n","print(test_data['paragraph'][57])\n","print(test_data['answer'][57])\n","print(test_data['question'][57])\n","\n","print(test_data['paragraph'][9])\n","print(test_data['answer'][9])\n","print(test_data['question'][9])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aj8da2Fds4RG","executionInfo":{"status":"ok","timestamp":1681090047387,"user_tz":-120,"elapsed":8,"user":{"displayName":"Puja Fadte","userId":"01381488140609442867"}},"outputId":"56a0168d-b662-4102-cf66-dd389c055c01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["An HMM is a probabilistic sequence model: given a sequence of units (words, letters, morphemes, sentences, whatever), it computes a probability distribution over possible sequences of labels and chooses the best label sequence.\n","An HMM is a probabilistic sequence model\n","What is a Hidden Markov Model?\n","The MLM training objective is to predict the original inputs for each of the masked tokens using a bidirectional encoder of the kind described in the last section. The cross-entropy loss from these predictions drives the training process for all the parameters in the model. Note that all of the input tokens play a role in the selfattention process, but only the sampled tokens are used for learning.\n","predict the original inputs for each of the masked tokens\n","What is the Masked Language Modeling training objective?\n","Again, the fact that these two strings are very similar (differing by only one word) seems like useful evidence for deciding that they might be coreferent. Edit distance gives us a way to quantify both of these intuitions about string similarity. More formally, the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.\n","the minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another.\n","How is the minimum edit distance between two strings defined?\n"]}]},{"cell_type":"code","source":["\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","model_name = \"allenai/t5-small-squad2-question-generation\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","print(model.config.num_hidden_layers)\n","print(model.config.hidden_size)\n","print(model.config.num_attention_heads)\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))"],"metadata":{"id":"S7vR9JeVOtnW","colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["7d751095064e4b0daa948e3ba0102f40","266b178bfd7445ecad7f02ba9a90f46b","149646ffa21c4dba9411ba688b34bfb1","8a8fd9a010534408a0607b897d332cb2","e31181e4ed1846719f76eb49e9b266fe","e53d30690d4a479c8fb74852460de10b","ab7b6cebf393445e800ba15f87ded150","917ce720e83446119595b4f7691b6b13","171cabff16cc4f1e9b02b209e8d93399","d8531da1f2c343f381f5816ea5e0763b","f175378522d74aabbb5df08c6a0cb744","38c56a7c43ab412d84ab97baedd89ebf","bbcc10a45fb14904b1c59f1a8c2cc85d","842ac6e6795c41cba5bc4089d4e8ca7c","a3331b5ac58943ac8b21effc5120b11d","0d38a98b329c4d11a24b80ebf159c982","95993245ce53427aa0431c2e9e1e9d25","e3e0fadb4484430db62296a7fd4f010c","6236a7b77b24477089541db95c28a90b","7a50aa51cb3b493bbb9fefe86641a9d5","735a62d9c79847fe898e316667e763aa","2fdd042e2a384a5eb1cb559ee61f7e63","ccce0dc76eaf4afe8002926a1e3f7465","793a7baa779b4ac7b406762ad5d574e7","a532ad1ce11944d79e6ffe449da2712b","362a0abc1b5b418083ef2057ccbf0852","7e947ef0aba84141b1975ba060e799ca","fdd771790bd7424b86cd7ba27774bb22","c9749d8f93b547f8bb685f1fd6accce3","7bcd4a67cdda42499c38f86f2dd7e823","0001c80c19d64d9e89f9a67453d025d7","5b42d7072c57433b8000a586574ce9be","58a98c67f5b743e4b67d35eb5bb0cfe2","6f66b39319e5477bb6c65ea05be7fea4","aebcd1cb25c841088ac3304fdc5b8469","d9fae00f17e34c8b84ad2b45fc8dfa01","8314c75a824543e7826348e6619f2ca3","eb3f8e0c8ebb4957a35e6245ca5b6b14","3355bbaf6ae64e54a7b7274e57f50c2e","ff2acb2338d2476db8ef62aa2cfdcceb","7aec471e74c64dd997a173b87b16c69c","9406834f052240b7bfa67bae917a377b","ababdf339cdd4c148da9c4916043b3fe","ee06f41b71c34dbbb893e7cde93a985e","5d4bd09b10f8444fbe2122aa2bce1c75","f97a63eea8794ec38fa905bd0fca5ab4","43dad83b61ea40a7830786d170ad3983","1697e9cbd1fc46718382efe0fd214d0d","e5b2cf62098f4ff0adb7e10f5f652eeb","d7798616b76d4791bb5ce347288eaeac","a0c5fad6de874899af05b7acd72958cb","4826bb89923d435dab1844ea9ed82720","a3b1ca0eef9941d1a62aae73dc840c94","f39c56f984ff4124b38d8f0bc054c157","da6fb661bd4d4bdbb79f6a707dca82e4","85026f3432ba450dbcbf99cba6faadf9","81d769ec9863483db4d5c8d14c525b64","e9e39d8032b042c9a87a9976f88fc3fc","4f39f86419c34517bd33f3171069cf08","163e5c88fa954495991ff223435de745","fcfd41f8bdfc4901bd6a1f1505b789b7","7c89ea17be274dd5b82a101ad357ce3b","665ea039d04343e8ad27a929dcbfd2e3","73a3e5aa4bf44c1d88c7197ac008cb5a","e01dcd4ada7647b8acbcbc888e6a507c","4a077702efe149ea90921e2330981a53"]},"executionInfo":{"status":"ok","timestamp":1681131495273,"user_tz":-120,"elapsed":17934,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"}},"outputId":"4e901bee-92e6-405a-f80e-a46130507acc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d751095064e4b0daa948e3ba0102f40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c56a7c43ab412d84ab97baedd89ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccce0dc76eaf4afe8002926a1e3f7465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f66b39319e5477bb6c65ea05be7fea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d4bd09b10f8444fbe2122aa2bce1c75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85026f3432ba450dbcbf99cba6faadf9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["6\n","512\n","8\n","60506624\n"]}]},{"cell_type":"code","source":["model_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\n","tokenizer_path = 'ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation'\n","model = T5ForConditionalGeneration.from_pretrained(model_path)\n","\n","print(model.config.num_hidden_layers)\n","print(model.config.hidden_size)\n","print(model.config.num_attention_heads)\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["32a36dd9a27d455d9b4a160c71469e76","21b3c75c8fb74f438d4518e29cb5580d","c01666394c0246bb8f84151fb58dc53d","ba08b2f6c6f242d680820da6bc255a52","f2b324a2b4bd453bb53c103c4f0113ea","614f299e60cb4328bafbb658207fcad5","bea9bde6464e483eb9a1982d3e24f598","e5a3946491f54d23b03a1aa0c3d81f9d","a13463bc3a9543be81be9a5db0878a54","6916941c16844f45a510dc3da07614ba","b1ae13a6028946eb819b9a8739d572f1","c80339e68bf74b7584b18d209fa6f42f","22f1c7f1a3cc4c128d74350e06f1d50a","d5cefe027a8f423cb91bbb183a24a135","99ae0b12b4b94af498806cb9ce432194","aa14835cbd0a434f8b908af0b76c89c5","3227b0938aef401db6783c6e3e8d4319","fd86f35dda144186afde06541e570d1d","7fa18abf0824453dad2b2b5b515cd704","620d2667f7a041d4a84451cfa6c0745a","da461bd6de4f40a49125a80ecb07e4a1","5329b38c1cd34fd198c8ab466c9f4221"]},"id":"wDC7wHUqPvjH","executionInfo":{"status":"ok","timestamp":1681131624621,"user_tz":-120,"elapsed":21304,"user":{"displayName":"P.R. Fadte","userId":"13531061216412575175"}},"outputId":"e361710b-1af9-411e-8d22-fa2ef2de5e70"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32a36dd9a27d455d9b4a160c71469e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c80339e68bf74b7584b18d209fa6f42f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["12\n","768\n","12\n","222903552\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1VQho1GzshwYZcjkhcIXRz-dS1QxZ6gEa","timestamp":1680772620447}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e22ecf124e2545e4b931f58fda243242":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08eb70b750424599a0312a81c92b704b","IPY_MODEL_9d3fb8b9688b49ee9fb5e9f0235a6a50","IPY_MODEL_93b26a7d8f2647d5b4a8c9e5cf4ba493"],"layout":"IPY_MODEL_8e002ed1dc0544fda1257b22e2b3d759"}},"08eb70b750424599a0312a81c92b704b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_762cc44b89354e3989d5c10949b0d53b","placeholder":"​","style":"IPY_MODEL_0b864ae086fc4edcac68f1aee361e44a","value":"Downloading (…)2b9e5/.gitattributes: 100%"}},"9d3fb8b9688b49ee9fb5e9f0235a6a50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_addc7246c7e6482b922915f7aebed3b0","max":736,"min":0,"orientation":"horizontal","style":"IPY_MODEL_485f36fdddf5403287f76fbb0205842f","value":736}},"93b26a7d8f2647d5b4a8c9e5cf4ba493":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50459bbbcc8f459583e059110ca8a5a5","placeholder":"​","style":"IPY_MODEL_a84e374baf1b4c5d9563165de4524c9c","value":" 736/736 [00:00&lt;00:00, 10.2kB/s]"}},"8e002ed1dc0544fda1257b22e2b3d759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"762cc44b89354e3989d5c10949b0d53b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b864ae086fc4edcac68f1aee361e44a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"addc7246c7e6482b922915f7aebed3b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"485f36fdddf5403287f76fbb0205842f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50459bbbcc8f459583e059110ca8a5a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84e374baf1b4c5d9563165de4524c9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eebf5064e77d40eaa960457d86e76a5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38dac4b1fe0c4c69b629e4df743f51dc","IPY_MODEL_7f12647a925b4c4cb0a43f4471f9cb55","IPY_MODEL_530c45454a6f492cbfcf7056cebf2d06"],"layout":"IPY_MODEL_4417d3dbbc3d4333804a9fa08b5c821a"}},"38dac4b1fe0c4c69b629e4df743f51dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13a39e8bb23c41c79737a5f0c3c3be35","placeholder":"​","style":"IPY_MODEL_e6d8993d676a4790bb6bccdc90558cc8","value":"Downloading (…)_Pooling/config.json: 100%"}},"7f12647a925b4c4cb0a43f4471f9cb55":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af69613b2ceb46dc9d959b73154d9a61","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bde0c56a60b34c72b60c8e92ae83592c","value":190}},"530c45454a6f492cbfcf7056cebf2d06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cc8ff632a5a4510a9cfea0abfab9524","placeholder":"​","style":"IPY_MODEL_5964bfdc804d45c0acbd41a310fd02ca","value":" 190/190 [00:00&lt;00:00, 3.12kB/s]"}},"4417d3dbbc3d4333804a9fa08b5c821a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13a39e8bb23c41c79737a5f0c3c3be35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d8993d676a4790bb6bccdc90558cc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af69613b2ceb46dc9d959b73154d9a61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde0c56a60b34c72b60c8e92ae83592c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cc8ff632a5a4510a9cfea0abfab9524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5964bfdc804d45c0acbd41a310fd02ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19e849364e164250a88917caacbc3b6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7647707e5cd490b92433c3db44a96e5","IPY_MODEL_25312b89f58b4c42ac4b84d99d66da28","IPY_MODEL_d89f2b46004a4ea78254117c9f20647d"],"layout":"IPY_MODEL_d02fd260b3cc4ebebc2009109e214ac5"}},"e7647707e5cd490b92433c3db44a96e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5105e1e440d64a72931fd87213bd6c39","placeholder":"​","style":"IPY_MODEL_0582c630550446ddb281cd63e914dad8","value":"Downloading (…)3c1ed2b9e5/README.md: 100%"}},"25312b89f58b4c42ac4b84d99d66da28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_370523f402234011a559be11389bdbcb","max":3741,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cfd7897c2764afcbb9e2ac6b2e2cc5a","value":3741}},"d89f2b46004a4ea78254117c9f20647d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b440ef0aa884c899c604153ef885c85","placeholder":"​","style":"IPY_MODEL_45fccbf46d8f4b61bc1f6b55802b50f8","value":" 3.74k/3.74k [00:00&lt;00:00, 52.9kB/s]"}},"d02fd260b3cc4ebebc2009109e214ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5105e1e440d64a72931fd87213bd6c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0582c630550446ddb281cd63e914dad8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"370523f402234011a559be11389bdbcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfd7897c2764afcbb9e2ac6b2e2cc5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b440ef0aa884c899c604153ef885c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45fccbf46d8f4b61bc1f6b55802b50f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9dfb4d58a3c427caa607d0a97f562c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00b47e006d874fa3b6c997bd56006547","IPY_MODEL_d98eca76321e4a188dfbd5f8bcfcb48c","IPY_MODEL_55994ac10c7d4fcaaf51bc269197a493"],"layout":"IPY_MODEL_8975ef622be946c2abd708e1852d190d"}},"00b47e006d874fa3b6c997bd56006547":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0c7e2782a14460b3853ab8deab4d07","placeholder":"​","style":"IPY_MODEL_ef251ede424544c2ab044df62119ab77","value":"Downloading (…)1ed2b9e5/config.json: 100%"}},"d98eca76321e4a188dfbd5f8bcfcb48c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e8cc4aa7344acc922dc127d67472e6","max":686,"min":0,"orientation":"horizontal","style":"IPY_MODEL_816030fb79eb40058dae4517f95eecf5","value":686}},"55994ac10c7d4fcaaf51bc269197a493":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb0c1b34c22543c5a80151fc14d4c8f1","placeholder":"​","style":"IPY_MODEL_162e2bb118bf48cbb0a635a37512ee2c","value":" 686/686 [00:00&lt;00:00, 16.7kB/s]"}},"8975ef622be946c2abd708e1852d190d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e0c7e2782a14460b3853ab8deab4d07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef251ede424544c2ab044df62119ab77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38e8cc4aa7344acc922dc127d67472e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816030fb79eb40058dae4517f95eecf5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb0c1b34c22543c5a80151fc14d4c8f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"162e2bb118bf48cbb0a635a37512ee2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13688f65eebd4935a7cfdecc58840ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91025bd1da3c4cb79b6a96b27232eafc","IPY_MODEL_387a051eb06c4a4f975eab4c324db718","IPY_MODEL_28e4d03c6a874c9789e6f7b9fc3875e5"],"layout":"IPY_MODEL_efe9d7ccb1eb4d1dba64cafe43d01e4a"}},"91025bd1da3c4cb79b6a96b27232eafc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_625d37cb5d114afdbf9571ce07ed43e8","placeholder":"​","style":"IPY_MODEL_529f05ffd16d462f9b92dd542421e0ea","value":"Downloading (…)ce_transformers.json: 100%"}},"387a051eb06c4a4f975eab4c324db718":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a25cb071ccb42a890129746d53c3505","max":122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77965214fc1248eba84e7b66ee8ff2b8","value":122}},"28e4d03c6a874c9789e6f7b9fc3875e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebb3355217ce4675b2c19a7b125f86ca","placeholder":"​","style":"IPY_MODEL_748a161fa9eb467195545071487c4489","value":" 122/122 [00:00&lt;00:00, 4.82kB/s]"}},"efe9d7ccb1eb4d1dba64cafe43d01e4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625d37cb5d114afdbf9571ce07ed43e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"529f05ffd16d462f9b92dd542421e0ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a25cb071ccb42a890129746d53c3505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77965214fc1248eba84e7b66ee8ff2b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebb3355217ce4675b2c19a7b125f86ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748a161fa9eb467195545071487c4489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20de1fd7d0d141b4ac25a787e6953432":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56322b48de2847bc9171b3fdf1797689","IPY_MODEL_37d6144b01d44b31a8de6ae58ede20c2","IPY_MODEL_1f15daba850e41db9b78c3f9e243cfdf"],"layout":"IPY_MODEL_3e3f76c6156e4dc7aaf78dead73a95d6"}},"56322b48de2847bc9171b3fdf1797689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_236f2c7623b3495d98628d262238746c","placeholder":"​","style":"IPY_MODEL_e826e74b9c3e4086bd38eda4c57b190b","value":"Downloading (…)c1ed2b9e5/merges.txt: 100%"}},"37d6144b01d44b31a8de6ae58ede20c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5e85136f0b477ea5862c6e1388fbd6","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b574558023745a980f92c8386dd1caf","value":456356}},"1f15daba850e41db9b78c3f9e243cfdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ed03e9d0106484892585711e1c9fb22","placeholder":"​","style":"IPY_MODEL_926ce28199f2445aa59bb81c9b3b9ac4","value":" 456k/456k [00:00&lt;00:00, 11.1MB/s]"}},"3e3f76c6156e4dc7aaf78dead73a95d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"236f2c7623b3495d98628d262238746c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e826e74b9c3e4086bd38eda4c57b190b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc5e85136f0b477ea5862c6e1388fbd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b574558023745a980f92c8386dd1caf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ed03e9d0106484892585711e1c9fb22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926ce28199f2445aa59bb81c9b3b9ac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0f1cf2a68b0403c9b880c99029aa6a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33d50d5d63eb492a807ed96c9d519639","IPY_MODEL_0e58e3c9edb042cc85818e4cbfa7e9c6","IPY_MODEL_acd745b3deac4dd8ace5b7616a7e56bd"],"layout":"IPY_MODEL_d159afe80246413796d9bec5cfa64c54"}},"33d50d5d63eb492a807ed96c9d519639":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f3fee1706ac4015aae69735f28f48e3","placeholder":"​","style":"IPY_MODEL_cdef964a39cb4fb5b292f5fc05d90fc2","value":"Downloading pytorch_model.bin: 100%"}},"0e58e3c9edb042cc85818e4cbfa7e9c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08d8e9fbb3c495cba1eda25bda56433","max":328515953,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99f62bc1034f4cd4a61a058311e455bb","value":328515953}},"acd745b3deac4dd8ace5b7616a7e56bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ce38b151e94a76ad2d2e02a33fc5d3","placeholder":"​","style":"IPY_MODEL_47df19ec1e67493b982a3c9129e12de3","value":" 329M/329M [00:09&lt;00:00, 39.1MB/s]"}},"d159afe80246413796d9bec5cfa64c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3fee1706ac4015aae69735f28f48e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdef964a39cb4fb5b292f5fc05d90fc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a08d8e9fbb3c495cba1eda25bda56433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f62bc1034f4cd4a61a058311e455bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4ce38b151e94a76ad2d2e02a33fc5d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47df19ec1e67493b982a3c9129e12de3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be86f8f5382c4202bb226d8b3c06b518":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99c9b769fe1540749ccd3bc94c667b67","IPY_MODEL_13fe1876764b4acbb52c210b00f5d766","IPY_MODEL_8784e2a05ef64da193c361ddf9efd662"],"layout":"IPY_MODEL_813590552a4a4064bab0ee229679aac1"}},"99c9b769fe1540749ccd3bc94c667b67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f1cecfb69c74479a7ad49f9fd8e5773","placeholder":"​","style":"IPY_MODEL_e8194e09b72b4c5b8669ac65a0c6e2c2","value":"Downloading (…)nce_bert_config.json: 100%"}},"13fe1876764b4acbb52c210b00f5d766":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e8b96edd8d74729bded82aa522b5dbb","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b48fd675fc746349e0fad7ffd6440a0","value":53}},"8784e2a05ef64da193c361ddf9efd662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2b2790dc984486952dc35b16e8c56e","placeholder":"​","style":"IPY_MODEL_50b74077ec674d6f978149c9bf8308f0","value":" 53.0/53.0 [00:00&lt;00:00, 2.92kB/s]"}},"813590552a4a4064bab0ee229679aac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f1cecfb69c74479a7ad49f9fd8e5773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8194e09b72b4c5b8669ac65a0c6e2c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e8b96edd8d74729bded82aa522b5dbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b48fd675fc746349e0fad7ffd6440a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f2b2790dc984486952dc35b16e8c56e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50b74077ec674d6f978149c9bf8308f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"759a28d94ff94280ba8dba47ee323850":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57b008177b154b2eb236e47b0e20c653","IPY_MODEL_d81c468e1ef349d690ee8c98279a9456","IPY_MODEL_04bbd2f594a444ff87cca6629e2126c6"],"layout":"IPY_MODEL_f63a51b2034a45f58093793ee759ce65"}},"57b008177b154b2eb236e47b0e20c653":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34755868accb408f80df03f12dd8c09a","placeholder":"​","style":"IPY_MODEL_1895df10227a492d8feebdd04defdaac","value":"Downloading (…)cial_tokens_map.json: 100%"}},"d81c468e1ef349d690ee8c98279a9456":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0353fcb826fa4fc989a9d317ce08a245","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a1ea502d864401fb4354326494c4169","value":239}},"04bbd2f594a444ff87cca6629e2126c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2c8902938834713a644292a5681af91","placeholder":"​","style":"IPY_MODEL_c72091b33e3244d191c76275e7478f0d","value":" 239/239 [00:00&lt;00:00, 5.17kB/s]"}},"f63a51b2034a45f58093793ee759ce65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34755868accb408f80df03f12dd8c09a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1895df10227a492d8feebdd04defdaac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0353fcb826fa4fc989a9d317ce08a245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a1ea502d864401fb4354326494c4169":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2c8902938834713a644292a5681af91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c72091b33e3244d191c76275e7478f0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"685a85ac1c2c46aca7c40947f5bed5ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f2c0e6244e84008a2ebff0c6bbd6582","IPY_MODEL_67052362b31e4def92e08801ed682e1f","IPY_MODEL_5b65aa41db384fb6b2811415bb142f12"],"layout":"IPY_MODEL_d3c6e52ccb164fd9b9572b7f9293463a"}},"8f2c0e6244e84008a2ebff0c6bbd6582":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b70b621d6154d84828919f4b7495520","placeholder":"​","style":"IPY_MODEL_4cd2bbab9f8a439b84be960a8f683acb","value":"Downloading (…)2b9e5/tokenizer.json: 100%"}},"67052362b31e4def92e08801ed682e1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d040c7b1b64c9bb9694e1d8f394760","max":1355881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16d01f7f4ee14d13a47cc9e164e3e86b","value":1355881}},"5b65aa41db384fb6b2811415bb142f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9e07ca763b44ad8b4c6dfb26c08c399","placeholder":"​","style":"IPY_MODEL_f8bfb06ae97345849468c1c6938a88e8","value":" 1.36M/1.36M [00:00&lt;00:00, 2.50MB/s]"}},"d3c6e52ccb164fd9b9572b7f9293463a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b70b621d6154d84828919f4b7495520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cd2bbab9f8a439b84be960a8f683acb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04d040c7b1b64c9bb9694e1d8f394760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16d01f7f4ee14d13a47cc9e164e3e86b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9e07ca763b44ad8b4c6dfb26c08c399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8bfb06ae97345849468c1c6938a88e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc9a6d40dc8448f3ac1301b7b8aee3af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_564ab30bf6cf4bd0b0036dcac70d9c96","IPY_MODEL_c8cc02ee922a47138d8e7e771dc97340","IPY_MODEL_550f027303bb477a94a2aaf49c36c500"],"layout":"IPY_MODEL_9d62590bb57f4542856e742f2877d067"}},"564ab30bf6cf4bd0b0036dcac70d9c96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7188c1ac04934827ad6b16ce7556af40","placeholder":"​","style":"IPY_MODEL_3a641abf33d44bd7978b9d1c6ddf9d90","value":"Downloading (…)okenizer_config.json: 100%"}},"c8cc02ee922a47138d8e7e771dc97340":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eb698256ab249f1b6c92c67b82a9464","max":1123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed66b06211474fcd97f39cbcb03bcc69","value":1123}},"550f027303bb477a94a2aaf49c36c500":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ba30ae08c814a52977b32d6018d863b","placeholder":"​","style":"IPY_MODEL_7910526e062240368cca81311406335f","value":" 1.12k/1.12k [00:00&lt;00:00, 18.1kB/s]"}},"9d62590bb57f4542856e742f2877d067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7188c1ac04934827ad6b16ce7556af40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a641abf33d44bd7978b9d1c6ddf9d90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eb698256ab249f1b6c92c67b82a9464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed66b06211474fcd97f39cbcb03bcc69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ba30ae08c814a52977b32d6018d863b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7910526e062240368cca81311406335f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2209efb0d5c94f3091a05acaf36b21bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8caf5c76ae3a43689eb21d082d959a25","IPY_MODEL_d2561a7e3b9d4eb6a726a0d68ecfd867","IPY_MODEL_954ddbb51dac41af9554dd4faf16816a"],"layout":"IPY_MODEL_a3e693042d4c4fd6a606f2b61feeba62"}},"8caf5c76ae3a43689eb21d082d959a25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6277ef7fceb2488686992291dc7eaa1d","placeholder":"​","style":"IPY_MODEL_4ccab469a532443eb52f95f14248a3ac","value":"Downloading (…)c1ed2b9e5/vocab.json: 100%"}},"d2561a7e3b9d4eb6a726a0d68ecfd867":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a10a411d3934282a8a34b82081669c9","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e76b61dab6a48598e1db09f111c7a69","value":798293}},"954ddbb51dac41af9554dd4faf16816a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90633305502b4eae9a2636708c2763d1","placeholder":"​","style":"IPY_MODEL_503498dc5ae94b4fb6188ac06e48b879","value":" 798k/798k [00:00&lt;00:00, 1.74MB/s]"}},"a3e693042d4c4fd6a606f2b61feeba62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6277ef7fceb2488686992291dc7eaa1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ccab469a532443eb52f95f14248a3ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a10a411d3934282a8a34b82081669c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e76b61dab6a48598e1db09f111c7a69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90633305502b4eae9a2636708c2763d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"503498dc5ae94b4fb6188ac06e48b879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71d8ed1f9a6342dcb3ca03668b9cfd63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8aab362fc4a4ec38247766ce26c25e0","IPY_MODEL_a9fc9124e6864383818ceca27dc09c47","IPY_MODEL_f280bc14db264adea07e3c453196bd48"],"layout":"IPY_MODEL_ed6bd57012c94f1f881bbe9f77c58615"}},"e8aab362fc4a4ec38247766ce26c25e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4331ba2fa20b49cab1ca4e217af25917","placeholder":"​","style":"IPY_MODEL_09c5f544f7bd470483a74e734ee826b6","value":"Downloading (…)ed2b9e5/modules.json: 100%"}},"a9fc9124e6864383818ceca27dc09c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6c0780b278d4cfaba5e885f1f13d71d","max":229,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0c47ff4dc934e14b0566dd1086cf2e5","value":229}},"f280bc14db264adea07e3c453196bd48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16bfafe4cc1241d9bfcaab255d3ee3d9","placeholder":"​","style":"IPY_MODEL_7ac43ac71bca445987bd0211bdd8cd9f","value":" 229/229 [00:00&lt;00:00, 8.03kB/s]"}},"ed6bd57012c94f1f881bbe9f77c58615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4331ba2fa20b49cab1ca4e217af25917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c5f544f7bd470483a74e734ee826b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6c0780b278d4cfaba5e885f1f13d71d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0c47ff4dc934e14b0566dd1086cf2e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16bfafe4cc1241d9bfcaab255d3ee3d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac43ac71bca445987bd0211bdd8cd9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a3bab006f27495e940f69d789ceed62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8619779699bd4d8c86f6ad30c28ded0c","IPY_MODEL_acd945fe45b4472ba5118404c4bb4134","IPY_MODEL_09d6e6e10e9a4aabb038bceb632dcadf"],"layout":"IPY_MODEL_8d1e271d905c43a3ba5c46648483bedc"}},"8619779699bd4d8c86f6ad30c28ded0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d633203a054563a334bac4999dae03","placeholder":"​","style":"IPY_MODEL_b98a667da5f84667a0b09fc36df4f2f0","value":"Downloading (…)okenizer_config.json: 100%"}},"acd945fe45b4472ba5118404c4bb4134":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc7fda7f8b74c20a0a9f277fa7da5c6","max":39,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fdf76b6bcdf4c12b6409ca9ed5e80a6","value":39}},"09d6e6e10e9a4aabb038bceb632dcadf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167ccb692bf047f6b84f78eba2a85b49","placeholder":"​","style":"IPY_MODEL_21bd0f606ac04e73be3340d77e42e8f5","value":" 39.0/39.0 [00:00&lt;00:00, 629B/s]"}},"8d1e271d905c43a3ba5c46648483bedc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d633203a054563a334bac4999dae03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b98a667da5f84667a0b09fc36df4f2f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc7fda7f8b74c20a0a9f277fa7da5c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fdf76b6bcdf4c12b6409ca9ed5e80a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167ccb692bf047f6b84f78eba2a85b49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21bd0f606ac04e73be3340d77e42e8f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c37fb5237254c3a858a9fadbdaafa1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f7c36bb1d2b4d81a6d677972d03b52e","IPY_MODEL_49892775520e46c6aceb309f370f7ec6","IPY_MODEL_84d60330641c4e22874b01a0cf25ea1c"],"layout":"IPY_MODEL_52f1faca49ef4f508a4393953e2ea599"}},"1f7c36bb1d2b4d81a6d677972d03b52e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_734b93d89fb7452cba3dba554285c3c1","placeholder":"​","style":"IPY_MODEL_e481be4cdfce4c1cbaf0ccab1d8e6d45","value":"Downloading (…)lve/main/config.json: 100%"}},"49892775520e46c6aceb309f370f7ec6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ed341a31f043858530ecc180a3a6bb","max":465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5649de593e34688a8e053cf27462cea","value":465}},"84d60330641c4e22874b01a0cf25ea1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a3523b4031a4082940843e258b3dcc7","placeholder":"​","style":"IPY_MODEL_0eb0a11d7c1b455ca6984240ac741f48","value":" 465/465 [00:00&lt;00:00, 14.8kB/s]"}},"52f1faca49ef4f508a4393953e2ea599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"734b93d89fb7452cba3dba554285c3c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e481be4cdfce4c1cbaf0ccab1d8e6d45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ed341a31f043858530ecc180a3a6bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5649de593e34688a8e053cf27462cea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a3523b4031a4082940843e258b3dcc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb0a11d7c1b455ca6984240ac741f48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e8490e43e494608bfbb368934d58791":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ceb8a71617134f2492941858a75efc2f","IPY_MODEL_2707dc89b4d04606a3d89448aee56dba","IPY_MODEL_8496eb8f590248e196c0b2a0eab0dba1"],"layout":"IPY_MODEL_3ffac43531c3447097491993bb87db39"}},"ceb8a71617134f2492941858a75efc2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b03cae2890c40098463a020311c1a07","placeholder":"​","style":"IPY_MODEL_56af9eaae8ea47079a64f810350c3dc4","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"2707dc89b4d04606a3d89448aee56dba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_618568ad6c6640d78f1041d9064838d4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cec44f5d23841e2aca99938c4cdebd9","value":231508}},"8496eb8f590248e196c0b2a0eab0dba1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1acec211ee9409d8b879c04c0a44972","placeholder":"​","style":"IPY_MODEL_4d8abdbd63614bfe8f1763c4e7275e7d","value":" 232k/232k [00:00&lt;00:00, 3.59MB/s]"}},"3ffac43531c3447097491993bb87db39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b03cae2890c40098463a020311c1a07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56af9eaae8ea47079a64f810350c3dc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"618568ad6c6640d78f1041d9064838d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cec44f5d23841e2aca99938c4cdebd9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1acec211ee9409d8b879c04c0a44972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8abdbd63614bfe8f1763c4e7275e7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bf5e635715e41fc99306de21de85e7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5633f91282054436837c8fc7f277714f","IPY_MODEL_6cec0e3a6f834995a54e95be087d1f02","IPY_MODEL_b31ff19cdce84a6996ed7fc8d2d7d590"],"layout":"IPY_MODEL_1513a2f724874698971909904a5e4fe3"}},"5633f91282054436837c8fc7f277714f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb25da54d63a4f79b149491a59453229","placeholder":"​","style":"IPY_MODEL_181b0c6ab1244c0ba6889776f8971976","value":"Downloading (…)cial_tokens_map.json: 100%"}},"6cec0e3a6f834995a54e95be087d1f02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5abefdba23bb4ce3a52a904b0fed7bbd","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_486f2fbe37f745b0a3b3d62173bc1908","value":112}},"b31ff19cdce84a6996ed7fc8d2d7d590":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ee41752250f466dadd9cf21f95b6492","placeholder":"​","style":"IPY_MODEL_2c3c81cf671145dba62bf582bd614427","value":" 112/112 [00:00&lt;00:00, 2.69kB/s]"}},"1513a2f724874698971909904a5e4fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb25da54d63a4f79b149491a59453229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"181b0c6ab1244c0ba6889776f8971976":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5abefdba23bb4ce3a52a904b0fed7bbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"486f2fbe37f745b0a3b3d62173bc1908":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ee41752250f466dadd9cf21f95b6492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c3c81cf671145dba62bf582bd614427":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1294dd153d0244b0836d885f8a9693a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e21e62d2f3d44bb5af88cb7cdcf7680e","IPY_MODEL_21eddaeb30e9429c815deb39ef089f0d","IPY_MODEL_eedb2298866c45cd81440320b939915f"],"layout":"IPY_MODEL_7147034b3f0b44b2902b32c1414e93be"}},"e21e62d2f3d44bb5af88cb7cdcf7680e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b3c86ca10d6475b9edec1bb841202d7","placeholder":"​","style":"IPY_MODEL_b5a5a29f8bbf40c687314e0ad70b5d1b","value":"Downloading pytorch_model.bin: 100%"}},"21eddaeb30e9429c815deb39ef089f0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d88b5de3bff949559e836254733d72d2","max":437985356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f5f3127de9a4bccbe924fddee58c609","value":437985356}},"eedb2298866c45cd81440320b939915f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b19fcdfefbb546da993990e77595444e","placeholder":"​","style":"IPY_MODEL_e4342d0f3a944f8f80913a436561cd3e","value":" 438M/438M [00:17&lt;00:00, 7.35MB/s]"}},"7147034b3f0b44b2902b32c1414e93be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b3c86ca10d6475b9edec1bb841202d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5a5a29f8bbf40c687314e0ad70b5d1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d88b5de3bff949559e836254733d72d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f5f3127de9a4bccbe924fddee58c609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b19fcdfefbb546da993990e77595444e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4342d0f3a944f8f80913a436561cd3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59aa5514b1554bceb859b3096c75ce4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c01935542b1941a5838966ad6c3ad7d0","IPY_MODEL_e94b6e6c4e5345fc8b0f58e5a709edc3","IPY_MODEL_8d067cc153f44005882161bb7099452a"],"layout":"IPY_MODEL_eb0ecb1291504631b9cc894fd84d2014"}},"c01935542b1941a5838966ad6c3ad7d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e7bc012ea6743d790e521735fc3c164","placeholder":"​","style":"IPY_MODEL_28889ca26de44e8a8b1dd08de9ac7901","value":"Downloading (…)lve/main/config.json: 100%"}},"e94b6e6c4e5345fc8b0f58e5a709edc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_785ace4ce7ed45c5b887bd4f02229f14","max":545,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c5409a74f3e49948d2c0dee232e0ba6","value":545}},"8d067cc153f44005882161bb7099452a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e1ac5bc7a8245ce9a2b3c923ba0e50b","placeholder":"​","style":"IPY_MODEL_a8dbde65f2f24eb4a48a5dfed420a577","value":" 545/545 [00:00&lt;00:00, 18.1kB/s]"}},"eb0ecb1291504631b9cc894fd84d2014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e7bc012ea6743d790e521735fc3c164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28889ca26de44e8a8b1dd08de9ac7901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"785ace4ce7ed45c5b887bd4f02229f14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c5409a74f3e49948d2c0dee232e0ba6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e1ac5bc7a8245ce9a2b3c923ba0e50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8dbde65f2f24eb4a48a5dfed420a577":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41043b3ad8844cc1b76085690da205e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a113a2b03cd40dfb955e060775baf29","IPY_MODEL_c6955f503c844f7faebbc7eba191d3bf","IPY_MODEL_e8793dbe76de4ac2a2e63e9ef3dcb4f7"],"layout":"IPY_MODEL_8c814d523a7c42729931696a2dae002c"}},"0a113a2b03cd40dfb955e060775baf29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0656ee2bc6dc4405b86b0c568e688542","placeholder":"​","style":"IPY_MODEL_53bc4b1ccf0e4e748429298a2df2fcf6","value":"Downloading pytorch_model.bin: 100%"}},"c6955f503c844f7faebbc7eba191d3bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_826b01232b274e66b87163af3a259461","max":265486777,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11b8bf6d9f0d4c9190ea01092cab96cc","value":265486777}},"e8793dbe76de4ac2a2e63e9ef3dcb4f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36f805e9c60049499e752195791d03a6","placeholder":"​","style":"IPY_MODEL_4411284d626541f280f7786154576f8a","value":" 265M/265M [00:18&lt;00:00, 12.9MB/s]"}},"8c814d523a7c42729931696a2dae002c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0656ee2bc6dc4405b86b0c568e688542":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53bc4b1ccf0e4e748429298a2df2fcf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"826b01232b274e66b87163af3a259461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11b8bf6d9f0d4c9190ea01092cab96cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36f805e9c60049499e752195791d03a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4411284d626541f280f7786154576f8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fc94fd6b4a049dc8e179f0f23f9885c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61520ae541974c4d9d606ee65efd884a","IPY_MODEL_6d9fb932015b4a2e947cbda0bc4ee45a","IPY_MODEL_3237d2ffb53a4bfa9098969821c7ede8"],"layout":"IPY_MODEL_073d7c4f112e43ffaeff914ad86b44ed"}},"61520ae541974c4d9d606ee65efd884a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8601fc67337f441c9a4dd3305f55c0fa","placeholder":"​","style":"IPY_MODEL_8a62d55cb6c84a158d46d15e1ccce19e","value":"Downloading builder script: 100%"}},"6d9fb932015b4a2e947cbda0bc4ee45a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71c44c19dc6d49b8a923129494554611","max":3454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f28afce0ce2a497d86baeec6aa570492","value":3454}},"3237d2ffb53a4bfa9098969821c7ede8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e833c645dd4343039ce8f99e633d856c","placeholder":"​","style":"IPY_MODEL_b56387a85db544fdb8d80968cf949946","value":" 3.45k/3.45k [00:00&lt;00:00, 216kB/s]"}},"073d7c4f112e43ffaeff914ad86b44ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8601fc67337f441c9a4dd3305f55c0fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a62d55cb6c84a158d46d15e1ccce19e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71c44c19dc6d49b8a923129494554611":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f28afce0ce2a497d86baeec6aa570492":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e833c645dd4343039ce8f99e633d856c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b56387a85db544fdb8d80968cf949946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07296998180f4dc6a077112617c53e72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fe69bb06283444386e09ab5da26143c","IPY_MODEL_794e9182a47c4f60a70a1dc272419652","IPY_MODEL_00977cfbefce4af1881bf90f1a12b9bd"],"layout":"IPY_MODEL_8a859a77915745a78f303c60016778d1"}},"8fe69bb06283444386e09ab5da26143c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5287a7c25fc4311927d7fa3399567eb","placeholder":"​","style":"IPY_MODEL_b353b570b3834b89a43daf73a430da97","value":"Downloading readme: 100%"}},"794e9182a47c4f60a70a1dc272419652":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee672c122ec45c09e2363de4cd34ca0","max":6967,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95724b8899914346b882d8017021a410","value":6967}},"00977cfbefce4af1881bf90f1a12b9bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7240cce7c9c940ca9c73765249a1019b","placeholder":"​","style":"IPY_MODEL_64636fe30eb84da9977be097ce7300a7","value":" 6.97k/6.97k [00:00&lt;00:00, 467kB/s]"}},"8a859a77915745a78f303c60016778d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5287a7c25fc4311927d7fa3399567eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b353b570b3834b89a43daf73a430da97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ee672c122ec45c09e2363de4cd34ca0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95724b8899914346b882d8017021a410":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7240cce7c9c940ca9c73765249a1019b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64636fe30eb84da9977be097ce7300a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa21476a360a41ebb513bc764849c4d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82ebb781e3df4ee0bd2fcd7ebf66dba6","IPY_MODEL_c72e12144d474c419d1541401333ea83","IPY_MODEL_605d5739aaee411e9dae5e7246cfbbbf"],"layout":"IPY_MODEL_f40175aaaad14f679a5e6fc4dec3b0d6"}},"82ebb781e3df4ee0bd2fcd7ebf66dba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95bda14616a54fbf9c11385c7b3f54e8","placeholder":"​","style":"IPY_MODEL_8373446b3a274241ad7735e1b4414445","value":"Downloading data: 100%"}},"c72e12144d474c419d1541401333ea83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff2f999f8c85485eb11e6ca812466b7f","max":741123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f73d3fbe404c47aba4f758e38e3ed4f0","value":741123}},"605d5739aaee411e9dae5e7246cfbbbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17d86de4adc64bbaa23a7903302f615d","placeholder":"​","style":"IPY_MODEL_0280949d703f4e7d8790d212969c6565","value":" 741k/741k [00:00&lt;00:00, 822kB/s]"}},"f40175aaaad14f679a5e6fc4dec3b0d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95bda14616a54fbf9c11385c7b3f54e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8373446b3a274241ad7735e1b4414445":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff2f999f8c85485eb11e6ca812466b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73d3fbe404c47aba4f758e38e3ed4f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17d86de4adc64bbaa23a7903302f615d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0280949d703f4e7d8790d212969c6565":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beca19f7eee34aadbbcee5c05c944943":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e88c858047244ff2afb010951df88a5f","IPY_MODEL_9e5ee027b7644e909bf2022cd910aee1","IPY_MODEL_588a66120e364c94867f73127d7cc2f9"],"layout":"IPY_MODEL_be231b68a0ea43be9d7fbb063fa10c6c"}},"e88c858047244ff2afb010951df88a5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5e46e979407484599450c7943624ed1","placeholder":"​","style":"IPY_MODEL_1e8639a9279a4b7d9a43e8c62fd0845b","value":"Generating train split: "}},"9e5ee027b7644e909bf2022cd910aee1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_52fe5839c93e4d75bd87745f33264451","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a731ccdebfc478a9486ba18d61e8f12","value":1}},"588a66120e364c94867f73127d7cc2f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_320ff484422a46f3839a6f45f6ab1a39","placeholder":"​","style":"IPY_MODEL_597537e66cac4dcaa820e4dee5b55c31","value":" 1697/0 [00:16&lt;00:00, 5675.40 examples/s]"}},"be231b68a0ea43be9d7fbb063fa10c6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f5e46e979407484599450c7943624ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e8639a9279a4b7d9a43e8c62fd0845b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52fe5839c93e4d75bd87745f33264451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7a731ccdebfc478a9486ba18d61e8f12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"320ff484422a46f3839a6f45f6ab1a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"597537e66cac4dcaa820e4dee5b55c31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91611badadf742f6982644d7876d5ac3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f848bb27595246b9ae2542e8c5a52d62","IPY_MODEL_f525f668af9549a6961cc2afc778d237","IPY_MODEL_e41fcde1b44b4c95b37991f8cf9452dd"],"layout":"IPY_MODEL_bc3ccbaf13db4bf98e2934671ea9daed"}},"f848bb27595246b9ae2542e8c5a52d62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccafe35fe9544af28fa7c11a8a910c6c","placeholder":"​","style":"IPY_MODEL_7cb9b59a67014df69509c1d87e8cbce9","value":"100%"}},"f525f668af9549a6961cc2afc778d237":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71b34d2804da461c94c73e97e556ac83","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cec436c36e9470aa2a06442d1d4cfd7","value":1}},"e41fcde1b44b4c95b37991f8cf9452dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6034d2a920de4e10b0fbe193668c209d","placeholder":"​","style":"IPY_MODEL_333cb4d908e843e38739d2cf3229bdf9","value":" 1/1 [00:00&lt;00:00, 41.31it/s]"}},"bc3ccbaf13db4bf98e2934671ea9daed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccafe35fe9544af28fa7c11a8a910c6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb9b59a67014df69509c1d87e8cbce9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b34d2804da461c94c73e97e556ac83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cec436c36e9470aa2a06442d1d4cfd7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6034d2a920de4e10b0fbe193668c209d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"333cb4d908e843e38739d2cf3229bdf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3533b91d1d7c4e1a89efc56f5c29ec1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2483bac646ba4e18b9a5358018e2d209","IPY_MODEL_5cc707cbec854ced9d8639067723081f","IPY_MODEL_399b46afe4fc477aa1e6869a0c30250f"],"layout":"IPY_MODEL_60786abb5b894f00b40971d620f3c097"}},"2483bac646ba4e18b9a5358018e2d209":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_329c077df1a04fed92a33980db49e39a","placeholder":"​","style":"IPY_MODEL_a485e45daa6548b18188766ba9ba9c02","value":"Downloading (…)da7dc/.gitattributes: 100%"}},"5cc707cbec854ced9d8639067723081f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_687115eaf5f04e6391a86641cb7367cf","max":690,"min":0,"orientation":"horizontal","style":"IPY_MODEL_748604d6fc8a4d0c9ca0461d47796f82","value":690}},"399b46afe4fc477aa1e6869a0c30250f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d866aa497f4e29b2d7590eb4fc6c1c","placeholder":"​","style":"IPY_MODEL_6d371e59d4214433960eae92f1feafc9","value":" 690/690 [00:00&lt;00:00, 35.4kB/s]"}},"60786abb5b894f00b40971d620f3c097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329c077df1a04fed92a33980db49e39a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a485e45daa6548b18188766ba9ba9c02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"687115eaf5f04e6391a86641cb7367cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748604d6fc8a4d0c9ca0461d47796f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54d866aa497f4e29b2d7590eb4fc6c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d371e59d4214433960eae92f1feafc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daea622a7e824d8b9d62ab68628031c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6408fcb1864345279ca61ac9efabb26f","IPY_MODEL_80eface5421244a8bf93e814c8d43722","IPY_MODEL_ccc9fa1f7714424880c17e6d981739f4"],"layout":"IPY_MODEL_3c6a922f338b4c49b774ce3afce28605"}},"6408fcb1864345279ca61ac9efabb26f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e880fc1aafec4de3aeb1aa3082e4b159","placeholder":"​","style":"IPY_MODEL_cf02caa0f01644fdbd42efc892daac29","value":"Downloading (…)_Pooling/config.json: 100%"}},"80eface5421244a8bf93e814c8d43722":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c8e8f9b4d204a739a4069527718fc34","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bbe67671bd63406ea676b75d96119f4c","value":190}},"ccc9fa1f7714424880c17e6d981739f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d51deb7c7c341cea2e3b692d2afd7e6","placeholder":"​","style":"IPY_MODEL_eae042e195584b3792c2a37e82d82e2d","value":" 190/190 [00:00&lt;00:00, 8.66kB/s]"}},"3c6a922f338b4c49b774ce3afce28605":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e880fc1aafec4de3aeb1aa3082e4b159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf02caa0f01644fdbd42efc892daac29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c8e8f9b4d204a739a4069527718fc34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe67671bd63406ea676b75d96119f4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d51deb7c7c341cea2e3b692d2afd7e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae042e195584b3792c2a37e82d82e2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"767af6ed427e42afb4b12512d64bd452":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55fedab7bbef470a81474d3180fc7b9f","IPY_MODEL_7c5a7153d1c84c178f73a34a301e8d66","IPY_MODEL_1a724673bba941d0b9026848bbf2207e"],"layout":"IPY_MODEL_b9ae46a521924caabbe7b157bab1fabc"}},"55fedab7bbef470a81474d3180fc7b9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_784a06ee3fda41d5a0f9d1cafd9e3ba2","placeholder":"​","style":"IPY_MODEL_97cce910749f4a7ca0fc11bcacae0a19","value":"Downloading (…)3fc4bda7dc/README.md: 100%"}},"7c5a7153d1c84c178f73a34a301e8d66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf56808fa8b948769419f31548059b5e","max":3714,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f445af40516c4d7aa34d34bbc9a0daef","value":3714}},"1a724673bba941d0b9026848bbf2207e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90183f8d01d941d49036a3237843fcd5","placeholder":"​","style":"IPY_MODEL_02d816954f21435185c4d3d9712c82d8","value":" 3.71k/3.71k [00:00&lt;00:00, 201kB/s]"}},"b9ae46a521924caabbe7b157bab1fabc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"784a06ee3fda41d5a0f9d1cafd9e3ba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97cce910749f4a7ca0fc11bcacae0a19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf56808fa8b948769419f31548059b5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f445af40516c4d7aa34d34bbc9a0daef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90183f8d01d941d49036a3237843fcd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d816954f21435185c4d3d9712c82d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22ddca84aa4e43a180e9cc945a3a61c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_388a148566b34b6c906c8c557f5f1a12","IPY_MODEL_202fbeb821cb40e79c73b780efa88442","IPY_MODEL_eb1de45aa7cc4e20afc79d0fe2d6663f"],"layout":"IPY_MODEL_5b696266d03c4e78b54fdbb5a2840e70"}},"388a148566b34b6c906c8c557f5f1a12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc201c523e934f939d2019d3af83d5bf","placeholder":"​","style":"IPY_MODEL_e31c24820c184241979a67f0ea6d3d8a","value":"Downloading (…)c4bda7dc/config.json: 100%"}},"202fbeb821cb40e79c73b780efa88442":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3479c78403bf4c5f9843a8b6dc4baf26","max":545,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3d59cd0aff346bc9718ca9569b1beaa","value":545}},"eb1de45aa7cc4e20afc79d0fe2d6663f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3feeaa7172f14fe28b563a1acd76ecad","placeholder":"​","style":"IPY_MODEL_a922bc3c959449c6b20c40f93455bd14","value":" 545/545 [00:00&lt;00:00, 27.9kB/s]"}},"5b696266d03c4e78b54fdbb5a2840e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc201c523e934f939d2019d3af83d5bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e31c24820c184241979a67f0ea6d3d8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3479c78403bf4c5f9843a8b6dc4baf26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3d59cd0aff346bc9718ca9569b1beaa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3feeaa7172f14fe28b563a1acd76ecad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a922bc3c959449c6b20c40f93455bd14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aba4f6e144a42f6aca272bc04ce6108":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97d234aff1ea4efa89d2021455e8f5f7","IPY_MODEL_90fb3ed6b45848368e4ddd0730fd7eb0","IPY_MODEL_e9687234508e473885fd4f8dd3481048"],"layout":"IPY_MODEL_d5dd0f9e202147db85b77f4c456d241e"}},"97d234aff1ea4efa89d2021455e8f5f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_841078076b0a4ee4b0134fca40e435d0","placeholder":"​","style":"IPY_MODEL_5a34f40b32254ac89686909c9f14a79f","value":"Downloading (…)ce_transformers.json: 100%"}},"90fb3ed6b45848368e4ddd0730fd7eb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a7152fb01cf4cd0934c18268c9e8bd1","max":122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec001f213a574defb84991a8b71625c2","value":122}},"e9687234508e473885fd4f8dd3481048":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe2541878e3740238c1838c369477a7c","placeholder":"​","style":"IPY_MODEL_beb2dfda22264c5b9fcd1ebe1078f660","value":" 122/122 [00:00&lt;00:00, 6.71kB/s]"}},"d5dd0f9e202147db85b77f4c456d241e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"841078076b0a4ee4b0134fca40e435d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a34f40b32254ac89686909c9f14a79f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a7152fb01cf4cd0934c18268c9e8bd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec001f213a574defb84991a8b71625c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe2541878e3740238c1838c369477a7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb2dfda22264c5b9fcd1ebe1078f660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34fae80772534398a0f47f50a983e0f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2933294f0804203bf0ae90fb4b4ce45","IPY_MODEL_615fbca8878941dfb119d097ee502ddd","IPY_MODEL_03b1fedfe0334bbfaffb2fec9e11c5e5"],"layout":"IPY_MODEL_f327812f60b94a2dbcdf9133b60549ff"}},"b2933294f0804203bf0ae90fb4b4ce45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcff5243346344f39455295ac053b2eb","placeholder":"​","style":"IPY_MODEL_fb69315335b54c8ba147e567753a1f39","value":"Downloading pytorch_model.bin: 100%"}},"615fbca8878941dfb119d097ee502ddd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed3a4cf3926c401a9c3c9b93bfddf852","max":265486777,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b769c2e6a2d476281d1b70fceacf4ec","value":265486777}},"03b1fedfe0334bbfaffb2fec9e11c5e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05c28b29d5af49f08ed22087c4904064","placeholder":"​","style":"IPY_MODEL_773ef3037ad64aa0b452e2e632460913","value":" 265M/265M [00:00&lt;00:00, 330MB/s]"}},"f327812f60b94a2dbcdf9133b60549ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcff5243346344f39455295ac053b2eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb69315335b54c8ba147e567753a1f39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed3a4cf3926c401a9c3c9b93bfddf852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b769c2e6a2d476281d1b70fceacf4ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05c28b29d5af49f08ed22087c4904064":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"773ef3037ad64aa0b452e2e632460913":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82f74f9568c04574a4808dfd464ca691":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7069429b683341b39c34fdb5b84c0669","IPY_MODEL_d254c7dd745d4cdcb3644a9955748476","IPY_MODEL_0f58f05a1db14567960b632e94369dfb"],"layout":"IPY_MODEL_ece83e8406c84ddda8baae2b045771e7"}},"7069429b683341b39c34fdb5b84c0669":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1732b6708c924e949ad0e6f54e9db380","placeholder":"​","style":"IPY_MODEL_59c6e075f662445b8508a7d935948d4f","value":"Downloading (…)nce_bert_config.json: 100%"}},"d254c7dd745d4cdcb3644a9955748476":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad1e98be6d348dd902782a33d4fbfa8","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_055cb6baa5fa4edc96d59b07c59cc2f2","value":53}},"0f58f05a1db14567960b632e94369dfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fda530753be47a4aa444e50b7339840","placeholder":"​","style":"IPY_MODEL_48ef537cc7d74475abd690c7ceabb277","value":" 53.0/53.0 [00:00&lt;00:00, 2.36kB/s]"}},"ece83e8406c84ddda8baae2b045771e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1732b6708c924e949ad0e6f54e9db380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c6e075f662445b8508a7d935948d4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad1e98be6d348dd902782a33d4fbfa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"055cb6baa5fa4edc96d59b07c59cc2f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fda530753be47a4aa444e50b7339840":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48ef537cc7d74475abd690c7ceabb277":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c34b6dfb5de34b0cbd8ffd346151e60f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a32accb02747441c89a981dc622b4af2","IPY_MODEL_e2489cb018784cf799247bffea93ffcb","IPY_MODEL_d96cca4878fc4398bba47038a531ba7f"],"layout":"IPY_MODEL_8f22a1bf68334b41853e616f50b25a7b"}},"a32accb02747441c89a981dc622b4af2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d119288b931a43b093d62b9fa46248cf","placeholder":"​","style":"IPY_MODEL_2fac0c1ee901458db21f4c4a3a8ab273","value":"Downloading (…)cial_tokens_map.json: 100%"}},"e2489cb018784cf799247bffea93ffcb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f30d04d933d54ad093b6009198cbcb48","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8e12c5126c04f21a1ea1f7f34ad398a","value":112}},"d96cca4878fc4398bba47038a531ba7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cebed3333cb4fe3953bb53a6ce5937f","placeholder":"​","style":"IPY_MODEL_0b39ef015ac946fa8110dcea2bd2cfdb","value":" 112/112 [00:00&lt;00:00, 5.20kB/s]"}},"8f22a1bf68334b41853e616f50b25a7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d119288b931a43b093d62b9fa46248cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fac0c1ee901458db21f4c4a3a8ab273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f30d04d933d54ad093b6009198cbcb48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e12c5126c04f21a1ea1f7f34ad398a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cebed3333cb4fe3953bb53a6ce5937f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b39ef015ac946fa8110dcea2bd2cfdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db63b3aef3ed49079d17abd981f4f777":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10f4b7d8f50a4673a36b64affedbfd53","IPY_MODEL_3f229d4711d54cbeb87208728f4779ac","IPY_MODEL_4b8cf1a8b3cb4b679d85aea0f2eb22d7"],"layout":"IPY_MODEL_834c27f6a5734e0eb8fa3a3494ae6ebb"}},"10f4b7d8f50a4673a36b64affedbfd53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_509c31f2cebb45f6bb65e33892efdc92","placeholder":"​","style":"IPY_MODEL_0efdabe7850d4441b98143e4af185d6a","value":"Downloading (…)da7dc/tokenizer.json: 100%"}},"3f229d4711d54cbeb87208728f4779ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0044126db9a2442d98525ff0b1261ee4","max":466081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73ac199984684f9aace5217ed98e2e6b","value":466081}},"4b8cf1a8b3cb4b679d85aea0f2eb22d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d07877dd16e4018b611ab7f6a8bc246","placeholder":"​","style":"IPY_MODEL_83161e30eea44eb28b58a8fac9dfe362","value":" 466k/466k [00:00&lt;00:00, 736kB/s]"}},"834c27f6a5734e0eb8fa3a3494ae6ebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509c31f2cebb45f6bb65e33892efdc92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efdabe7850d4441b98143e4af185d6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0044126db9a2442d98525ff0b1261ee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ac199984684f9aace5217ed98e2e6b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d07877dd16e4018b611ab7f6a8bc246":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83161e30eea44eb28b58a8fac9dfe362":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b239ba5c0f743218a42a54e6bb691f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b4453b371a0430682206e01fb07ffe6","IPY_MODEL_1b44062c01cb4201a5d9b424a47c9db9","IPY_MODEL_69361d20ecac4b5dbce1a7eff4ba8ea8"],"layout":"IPY_MODEL_216a804cc2934c8a9ba3bb4e72abc59e"}},"7b4453b371a0430682206e01fb07ffe6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48cdb4b943cc4bb0a4c5e1e9ab78b9f6","placeholder":"​","style":"IPY_MODEL_7ef8ed4dbacd4aad9581af70e71221f4","value":"Downloading (…)okenizer_config.json: 100%"}},"1b44062c01cb4201a5d9b424a47c9db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f97904701e7b4a508de7215198efbcbb","max":499,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25ef9d715a3046bbaccd647ecd1694ab","value":499}},"69361d20ecac4b5dbce1a7eff4ba8ea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4dd2a0f5f6d450f9d21995fe38010f0","placeholder":"​","style":"IPY_MODEL_0ac14a677f0b48fd867110f56997649b","value":" 499/499 [00:00&lt;00:00, 25.8kB/s]"}},"216a804cc2934c8a9ba3bb4e72abc59e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48cdb4b943cc4bb0a4c5e1e9ab78b9f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ef8ed4dbacd4aad9581af70e71221f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f97904701e7b4a508de7215198efbcbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ef9d715a3046bbaccd647ecd1694ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4dd2a0f5f6d450f9d21995fe38010f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac14a677f0b48fd867110f56997649b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"394b19b93d6648009030723fea0b5765":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18519fcf6c1e42a6b18849eaad8346c7","IPY_MODEL_0a8cf7cea0b9493fa2f0bc97d5660689","IPY_MODEL_e1b5341d229b4567843c7942c80f32fa"],"layout":"IPY_MODEL_501d86ff0dec470cbcd59ec908ecdb20"}},"18519fcf6c1e42a6b18849eaad8346c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82b9da5e61044fc9c3589be59282870","placeholder":"​","style":"IPY_MODEL_4bb65b37aa634e139ff76206c97c5f20","value":"Downloading (…)3fc4bda7dc/vocab.txt: 100%"}},"0a8cf7cea0b9493fa2f0bc97d5660689":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbb8105f2160497aac370dd7b3fc0330","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c884b9008ac4e31931dccc516403fc5","value":231508}},"e1b5341d229b4567843c7942c80f32fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e48b6b3c0ab84a879a641880db088a70","placeholder":"​","style":"IPY_MODEL_251dd039ba354930b9a7186b8f6f40b7","value":" 232k/232k [00:00&lt;00:00, 8.54MB/s]"}},"501d86ff0dec470cbcd59ec908ecdb20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82b9da5e61044fc9c3589be59282870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bb65b37aa634e139ff76206c97c5f20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbb8105f2160497aac370dd7b3fc0330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c884b9008ac4e31931dccc516403fc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e48b6b3c0ab84a879a641880db088a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"251dd039ba354930b9a7186b8f6f40b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc9765314c8c423cb879eb9c5cbc570b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcb92750ffcf44369d943419a918488d","IPY_MODEL_53340f4062ee4178b6362b08a7ccde0f","IPY_MODEL_816222e6b8ff415ebe84f9244e4aa661"],"layout":"IPY_MODEL_7a0404158eb245c99d8fb562d2074ca2"}},"fcb92750ffcf44369d943419a918488d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7fddbb9b31943b2ad3f3880ce2a881d","placeholder":"​","style":"IPY_MODEL_6f57e93eeb644efbb78a8140b3cd19f8","value":"Downloading (…)4bda7dc/modules.json: 100%"}},"53340f4062ee4178b6362b08a7ccde0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72f114843b3e4c45b13c9258fccc7084","max":229,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ee54a7a21ce4e5e9b542226342b0c24","value":229}},"816222e6b8ff415ebe84f9244e4aa661":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e9b39d2bc3d49e7a45a5e48c5ea816e","placeholder":"​","style":"IPY_MODEL_a984ca239d10456c8e5036898bdfd80e","value":" 229/229 [00:00&lt;00:00, 12.0kB/s]"}},"7a0404158eb245c99d8fb562d2074ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7fddbb9b31943b2ad3f3880ce2a881d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f57e93eeb644efbb78a8140b3cd19f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72f114843b3e4c45b13c9258fccc7084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee54a7a21ce4e5e9b542226342b0c24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e9b39d2bc3d49e7a45a5e48c5ea816e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a984ca239d10456c8e5036898bdfd80e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"606011312509457eb0fdece7c4d18d77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4e523ee180a464d8081323a4d280b69","IPY_MODEL_59f01a54eaed48a1a4304e6d593336dc","IPY_MODEL_e9ceacaec5f34017b61aa4d530c02eb2"],"layout":"IPY_MODEL_f2af735e02a54271a9761552c1e0690e"}},"d4e523ee180a464d8081323a4d280b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f1169dd8f3f449eb199f202236dec8e","placeholder":"​","style":"IPY_MODEL_e1278e906bf5422ab2a03b884bdaa1c2","value":"Downloading (…)lve/main/config.json: 100%"}},"59f01a54eaed48a1a4304e6d593336dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba5e056c7c154c359561ed26e12466f2","max":1236,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b99f6feae37e4f9898777874b6e0e109","value":1236}},"e9ceacaec5f34017b61aa4d530c02eb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27a20dfebf6443ee9b26837ee36ccf63","placeholder":"​","style":"IPY_MODEL_8a749f32ec9349f4b1ff99b8758c85f9","value":" 1.24k/1.24k [00:00&lt;00:00, 67.1kB/s]"}},"f2af735e02a54271a9761552c1e0690e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f1169dd8f3f449eb199f202236dec8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1278e906bf5422ab2a03b884bdaa1c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba5e056c7c154c359561ed26e12466f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99f6feae37e4f9898777874b6e0e109":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27a20dfebf6443ee9b26837ee36ccf63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a749f32ec9349f4b1ff99b8758c85f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fdcafae93c04932879f8d7afbe7c239":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_340e829ff8e0443a85e0b2bcb2d12e73","IPY_MODEL_892d8f036bfb405d94fc4ce7926cb24c","IPY_MODEL_1d298db1df974f5b9a73d097a4281609"],"layout":"IPY_MODEL_537c9d5671744ddf89178a4002be3f43"}},"340e829ff8e0443a85e0b2bcb2d12e73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3b19a29f69430590cc9df7f6e4a9c8","placeholder":"​","style":"IPY_MODEL_b3a176fe5b024bc6a1bc751115cf7daf","value":"Downloading pytorch_model.bin: 100%"}},"892d8f036bfb405d94fc4ce7926cb24c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52453c417ab646558d9677650454f687","max":891736323,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6139ad5fc0b341b38f937f9febf15dd6","value":891736323}},"1d298db1df974f5b9a73d097a4281609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_830a59420faf401aa9f9a01419790d7b","placeholder":"​","style":"IPY_MODEL_b96a91ca1d1e46a983f0109ea0af0a3e","value":" 892M/892M [00:09&lt;00:00, 100MB/s]"}},"537c9d5671744ddf89178a4002be3f43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c3b19a29f69430590cc9df7f6e4a9c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3a176fe5b024bc6a1bc751115cf7daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52453c417ab646558d9677650454f687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6139ad5fc0b341b38f937f9febf15dd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"830a59420faf401aa9f9a01419790d7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b96a91ca1d1e46a983f0109ea0af0a3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"800d3d85d33b47fd93ba3391a03a4ad0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cabd4b3930fa46b1bc627b5f63967d9a","IPY_MODEL_dda8aa1da86849ce9800a8d687b5b481","IPY_MODEL_65980751c87e40268c8d872244de7d5c"],"layout":"IPY_MODEL_f24725d472984213acb179e6ac9a6aef"}},"cabd4b3930fa46b1bc627b5f63967d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e0dc34679d640219c3ac72edadcc32a","placeholder":"​","style":"IPY_MODEL_3ca6f172b148449b843f7faa69105280","value":"Downloading (…)neration_config.json: 100%"}},"dda8aa1da86849ce9800a8d687b5b481":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62d7dc1ec54b449d9cd2bdea3384b83d","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4a2bd4e500740e7b4567382bda9f4d2","value":147}},"65980751c87e40268c8d872244de7d5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02bf613806c441fab241105f2e9002a7","placeholder":"​","style":"IPY_MODEL_2947a5678c8a4e4492769fe6c7ade019","value":" 147/147 [00:00&lt;00:00, 4.92kB/s]"}},"f24725d472984213acb179e6ac9a6aef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e0dc34679d640219c3ac72edadcc32a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ca6f172b148449b843f7faa69105280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62d7dc1ec54b449d9cd2bdea3384b83d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4a2bd4e500740e7b4567382bda9f4d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02bf613806c441fab241105f2e9002a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2947a5678c8a4e4492769fe6c7ade019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b98a32698b654f5fac156dec47d4385c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb44d00842bf4465a6080c39bc84ef02","IPY_MODEL_302ee0991bbc453eaa7fe83d88f4ae32","IPY_MODEL_d64052601a914a85a9b7dc97479be734"],"layout":"IPY_MODEL_14921323156941a092a2e05c89ecde26"}},"cb44d00842bf4465a6080c39bc84ef02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f6c152c8d5246d0b1f06d58f9410002","placeholder":"​","style":"IPY_MODEL_358809e3b90842ce9f0de606a17e3622","value":"Downloading (…)okenizer_config.json: 100%"}},"302ee0991bbc453eaa7fe83d88f4ae32":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b2bb7224f7647f8b1af598117cecaf9","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a28cf58ed84a45e880eca7cd63ce9aaa","value":25}},"d64052601a914a85a9b7dc97479be734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9acb41eb3e24a8a8d3d4e9e592ca4ad","placeholder":"​","style":"IPY_MODEL_1f07f009840b46d8889c7ac32725d837","value":" 25.0/25.0 [00:00&lt;00:00, 1.31kB/s]"}},"14921323156941a092a2e05c89ecde26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6c152c8d5246d0b1f06d58f9410002":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"358809e3b90842ce9f0de606a17e3622":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2bb7224f7647f8b1af598117cecaf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a28cf58ed84a45e880eca7cd63ce9aaa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9acb41eb3e24a8a8d3d4e9e592ca4ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f07f009840b46d8889c7ac32725d837":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb3a84b6ec374960b3554adb96d12210":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a51a3d9f235445395cf7a961fb38139","IPY_MODEL_8c4af0c188804a7291e14ce959c004ea","IPY_MODEL_954602fbf9934bd9854e872109ffcd7e"],"layout":"IPY_MODEL_e56210d4de174445892ae664e5ba2ec4"}},"0a51a3d9f235445395cf7a961fb38139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2ea9c6cddd42dc905efe870877a6d6","placeholder":"​","style":"IPY_MODEL_1da5f7b8e84046b8b7f471ccf82784cb","value":"Downloading (…)ve/main/spiece.model: 100%"}},"8c4af0c188804a7291e14ce959c004ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a386560b67dc4f2fb03e51722d7da36f","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8578090d7f3147dbbd9852e23bb49fc6","value":791656}},"954602fbf9934bd9854e872109ffcd7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42752549cabb48b08d549f0192be8d95","placeholder":"​","style":"IPY_MODEL_1bfcf57062634e1db9286e486292702b","value":" 792k/792k [00:00&lt;00:00, 942kB/s]"}},"e56210d4de174445892ae664e5ba2ec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2ea9c6cddd42dc905efe870877a6d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da5f7b8e84046b8b7f471ccf82784cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a386560b67dc4f2fb03e51722d7da36f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8578090d7f3147dbbd9852e23bb49fc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42752549cabb48b08d549f0192be8d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bfcf57062634e1db9286e486292702b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6b3f554107f4b7590abd1d233b03cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac3835bf4d10474e94cb494954d53855","IPY_MODEL_bf5634a06005453188ec0107f8f0b263","IPY_MODEL_6743bb63b58648c9bad1bc5214fc929b"],"layout":"IPY_MODEL_0893deee9df14a22bd393a0063fd4bc3"}},"ac3835bf4d10474e94cb494954d53855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe3d47e1de54a2399f2780fd9da2396","placeholder":"​","style":"IPY_MODEL_b06b818dd9fa423288beba83c2662e55","value":"Downloading (…)cial_tokens_map.json: 100%"}},"bf5634a06005453188ec0107f8f0b263":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d0f55530b824008a484b1d32ca31669","max":1786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e73866eefa0438894c6d2fbfd22eb97","value":1786}},"6743bb63b58648c9bad1bc5214fc929b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_711e9b8ececd49b99f8fcb003be4c961","placeholder":"​","style":"IPY_MODEL_c85b78107cdc48e393dae33208c8aae2","value":" 1.79k/1.79k [00:00&lt;00:00, 64.1kB/s]"}},"0893deee9df14a22bd393a0063fd4bc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abe3d47e1de54a2399f2780fd9da2396":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b06b818dd9fa423288beba83c2662e55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d0f55530b824008a484b1d32ca31669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e73866eefa0438894c6d2fbfd22eb97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"711e9b8ececd49b99f8fcb003be4c961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c85b78107cdc48e393dae33208c8aae2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7f8809ef986456c95f2f4d063094e14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f39bf93b03f4a1580df480013b99e8d","IPY_MODEL_c90202f59dd3421d9ceb88be273e2528","IPY_MODEL_e94f4c7e69a241579f4e8a772061d098"],"layout":"IPY_MODEL_c432a7022807443eb5970d879cc85907"}},"0f39bf93b03f4a1580df480013b99e8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_638b9ab98d1641f29b0e313c993e9ae1","placeholder":"​","style":"IPY_MODEL_3ae84dc5d39f4aefb39e95dedf6494e1","value":"Downloading builder script: 100%"}},"c90202f59dd3421d9ceb88be273e2528":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed4d3bfd96684e31b98c547535949200","max":6809,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bd2025fd97c4126b1598b1bda8dce7c","value":6809}},"e94f4c7e69a241579f4e8a772061d098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f67f9b1d22b41e09533e4ad79f67707","placeholder":"​","style":"IPY_MODEL_faf433962ff84763a4ee8eccc0550069","value":" 6.81k/6.81k [00:00&lt;00:00, 359kB/s]"}},"c432a7022807443eb5970d879cc85907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"638b9ab98d1641f29b0e313c993e9ae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae84dc5d39f4aefb39e95dedf6494e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed4d3bfd96684e31b98c547535949200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bd2025fd97c4126b1598b1bda8dce7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f67f9b1d22b41e09533e4ad79f67707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faf433962ff84763a4ee8eccc0550069":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d751095064e4b0daa948e3ba0102f40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_266b178bfd7445ecad7f02ba9a90f46b","IPY_MODEL_149646ffa21c4dba9411ba688b34bfb1","IPY_MODEL_8a8fd9a010534408a0607b897d332cb2"],"layout":"IPY_MODEL_e31181e4ed1846719f76eb49e9b266fe"}},"266b178bfd7445ecad7f02ba9a90f46b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e53d30690d4a479c8fb74852460de10b","placeholder":"​","style":"IPY_MODEL_ab7b6cebf393445e800ba15f87ded150","value":"Downloading spiece.model: 100%"}},"149646ffa21c4dba9411ba688b34bfb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_917ce720e83446119595b4f7691b6b13","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_171cabff16cc4f1e9b02b209e8d93399","value":791656}},"8a8fd9a010534408a0607b897d332cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8531da1f2c343f381f5816ea5e0763b","placeholder":"​","style":"IPY_MODEL_f175378522d74aabbb5df08c6a0cb744","value":" 792k/792k [00:00&lt;00:00, 2.46MB/s]"}},"e31181e4ed1846719f76eb49e9b266fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53d30690d4a479c8fb74852460de10b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab7b6cebf393445e800ba15f87ded150":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"917ce720e83446119595b4f7691b6b13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171cabff16cc4f1e9b02b209e8d93399":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8531da1f2c343f381f5816ea5e0763b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f175378522d74aabbb5df08c6a0cb744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c56a7c43ab412d84ab97baedd89ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbcc10a45fb14904b1c59f1a8c2cc85d","IPY_MODEL_842ac6e6795c41cba5bc4089d4e8ca7c","IPY_MODEL_a3331b5ac58943ac8b21effc5120b11d"],"layout":"IPY_MODEL_0d38a98b329c4d11a24b80ebf159c982"}},"bbcc10a45fb14904b1c59f1a8c2cc85d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95993245ce53427aa0431c2e9e1e9d25","placeholder":"​","style":"IPY_MODEL_e3e0fadb4484430db62296a7fd4f010c","value":"Downloading (…)cial_tokens_map.json: 100%"}},"842ac6e6795c41cba5bc4089d4e8ca7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6236a7b77b24477089541db95c28a90b","max":1786,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a50aa51cb3b493bbb9fefe86641a9d5","value":1786}},"a3331b5ac58943ac8b21effc5120b11d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_735a62d9c79847fe898e316667e763aa","placeholder":"​","style":"IPY_MODEL_2fdd042e2a384a5eb1cb559ee61f7e63","value":" 1.79k/1.79k [00:00&lt;00:00, 36.3kB/s]"}},"0d38a98b329c4d11a24b80ebf159c982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95993245ce53427aa0431c2e9e1e9d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3e0fadb4484430db62296a7fd4f010c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6236a7b77b24477089541db95c28a90b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a50aa51cb3b493bbb9fefe86641a9d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"735a62d9c79847fe898e316667e763aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fdd042e2a384a5eb1cb559ee61f7e63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccce0dc76eaf4afe8002926a1e3f7465":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_793a7baa779b4ac7b406762ad5d574e7","IPY_MODEL_a532ad1ce11944d79e6ffe449da2712b","IPY_MODEL_362a0abc1b5b418083ef2057ccbf0852"],"layout":"IPY_MODEL_7e947ef0aba84141b1975ba060e799ca"}},"793a7baa779b4ac7b406762ad5d574e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdd771790bd7424b86cd7ba27774bb22","placeholder":"​","style":"IPY_MODEL_c9749d8f93b547f8bb685f1fd6accce3","value":"Downloading (…)okenizer_config.json: 100%"}},"a532ad1ce11944d79e6ffe449da2712b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bcd4a67cdda42499c38f86f2dd7e823","max":1857,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0001c80c19d64d9e89f9a67453d025d7","value":1857}},"362a0abc1b5b418083ef2057ccbf0852":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b42d7072c57433b8000a586574ce9be","placeholder":"​","style":"IPY_MODEL_58a98c67f5b743e4b67d35eb5bb0cfe2","value":" 1.86k/1.86k [00:00&lt;00:00, 21.3kB/s]"}},"7e947ef0aba84141b1975ba060e799ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd771790bd7424b86cd7ba27774bb22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9749d8f93b547f8bb685f1fd6accce3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bcd4a67cdda42499c38f86f2dd7e823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0001c80c19d64d9e89f9a67453d025d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b42d7072c57433b8000a586574ce9be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58a98c67f5b743e4b67d35eb5bb0cfe2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f66b39319e5477bb6c65ea05be7fea4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aebcd1cb25c841088ac3304fdc5b8469","IPY_MODEL_d9fae00f17e34c8b84ad2b45fc8dfa01","IPY_MODEL_8314c75a824543e7826348e6619f2ca3"],"layout":"IPY_MODEL_eb3f8e0c8ebb4957a35e6245ca5b6b14"}},"aebcd1cb25c841088ac3304fdc5b8469":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3355bbaf6ae64e54a7b7274e57f50c2e","placeholder":"​","style":"IPY_MODEL_ff2acb2338d2476db8ef62aa2cfdcceb","value":"Downloading (…)lve/main/config.json: 100%"}},"d9fae00f17e34c8b84ad2b45fc8dfa01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aec471e74c64dd997a173b87b16c69c","max":1320,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9406834f052240b7bfa67bae917a377b","value":1320}},"8314c75a824543e7826348e6619f2ca3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ababdf339cdd4c148da9c4916043b3fe","placeholder":"​","style":"IPY_MODEL_ee06f41b71c34dbbb893e7cde93a985e","value":" 1.32k/1.32k [00:00&lt;00:00, 31.1kB/s]"}},"eb3f8e0c8ebb4957a35e6245ca5b6b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3355bbaf6ae64e54a7b7274e57f50c2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff2acb2338d2476db8ef62aa2cfdcceb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aec471e74c64dd997a173b87b16c69c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9406834f052240b7bfa67bae917a377b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ababdf339cdd4c148da9c4916043b3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee06f41b71c34dbbb893e7cde93a985e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d4bd09b10f8444fbe2122aa2bce1c75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f97a63eea8794ec38fa905bd0fca5ab4","IPY_MODEL_43dad83b61ea40a7830786d170ad3983","IPY_MODEL_1697e9cbd1fc46718382efe0fd214d0d"],"layout":"IPY_MODEL_e5b2cf62098f4ff0adb7e10f5f652eeb"}},"f97a63eea8794ec38fa905bd0fca5ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7798616b76d4791bb5ce347288eaeac","placeholder":"​","style":"IPY_MODEL_a0c5fad6de874899af05b7acd72958cb","value":"Downloading pytorch_model.bin: 100%"}},"43dad83b61ea40a7830786d170ad3983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4826bb89923d435dab1844ea9ed82720","max":242087757,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3b1ca0eef9941d1a62aae73dc840c94","value":242087757}},"1697e9cbd1fc46718382efe0fd214d0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f39c56f984ff4124b38d8f0bc054c157","placeholder":"​","style":"IPY_MODEL_da6fb661bd4d4bdbb79f6a707dca82e4","value":" 242M/242M [00:05&lt;00:00, 50.3MB/s]"}},"e5b2cf62098f4ff0adb7e10f5f652eeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7798616b76d4791bb5ce347288eaeac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0c5fad6de874899af05b7acd72958cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4826bb89923d435dab1844ea9ed82720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b1ca0eef9941d1a62aae73dc840c94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f39c56f984ff4124b38d8f0bc054c157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da6fb661bd4d4bdbb79f6a707dca82e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85026f3432ba450dbcbf99cba6faadf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81d769ec9863483db4d5c8d14c525b64","IPY_MODEL_e9e39d8032b042c9a87a9976f88fc3fc","IPY_MODEL_4f39f86419c34517bd33f3171069cf08"],"layout":"IPY_MODEL_163e5c88fa954495991ff223435de745"}},"81d769ec9863483db4d5c8d14c525b64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcfd41f8bdfc4901bd6a1f1505b789b7","placeholder":"​","style":"IPY_MODEL_7c89ea17be274dd5b82a101ad357ce3b","value":"Downloading (…)neration_config.json: 100%"}},"e9e39d8032b042c9a87a9976f88fc3fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_665ea039d04343e8ad27a929dcbfd2e3","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73a3e5aa4bf44c1d88c7197ac008cb5a","value":147}},"4f39f86419c34517bd33f3171069cf08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e01dcd4ada7647b8acbcbc888e6a507c","placeholder":"​","style":"IPY_MODEL_4a077702efe149ea90921e2330981a53","value":" 147/147 [00:00&lt;00:00, 7.06kB/s]"}},"163e5c88fa954495991ff223435de745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcfd41f8bdfc4901bd6a1f1505b789b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c89ea17be274dd5b82a101ad357ce3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"665ea039d04343e8ad27a929dcbfd2e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a3e5aa4bf44c1d88c7197ac008cb5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e01dcd4ada7647b8acbcbc888e6a507c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a077702efe149ea90921e2330981a53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32a36dd9a27d455d9b4a160c71469e76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21b3c75c8fb74f438d4518e29cb5580d","IPY_MODEL_c01666394c0246bb8f84151fb58dc53d","IPY_MODEL_ba08b2f6c6f242d680820da6bc255a52"],"layout":"IPY_MODEL_f2b324a2b4bd453bb53c103c4f0113ea"}},"21b3c75c8fb74f438d4518e29cb5580d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_614f299e60cb4328bafbb658207fcad5","placeholder":"​","style":"IPY_MODEL_bea9bde6464e483eb9a1982d3e24f598","value":"Downloading (…)lve/main/config.json: 100%"}},"c01666394c0246bb8f84151fb58dc53d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5a3946491f54d23b03a1aa0c3d81f9d","max":1382,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a13463bc3a9543be81be9a5db0878a54","value":1382}},"ba08b2f6c6f242d680820da6bc255a52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6916941c16844f45a510dc3da07614ba","placeholder":"​","style":"IPY_MODEL_b1ae13a6028946eb819b9a8739d572f1","value":" 1.38k/1.38k [00:00&lt;00:00, 27.0kB/s]"}},"f2b324a2b4bd453bb53c103c4f0113ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614f299e60cb4328bafbb658207fcad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bea9bde6464e483eb9a1982d3e24f598":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5a3946491f54d23b03a1aa0c3d81f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a13463bc3a9543be81be9a5db0878a54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6916941c16844f45a510dc3da07614ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ae13a6028946eb819b9a8739d572f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80339e68bf74b7584b18d209fa6f42f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22f1c7f1a3cc4c128d74350e06f1d50a","IPY_MODEL_d5cefe027a8f423cb91bbb183a24a135","IPY_MODEL_99ae0b12b4b94af498806cb9ce432194"],"layout":"IPY_MODEL_aa14835cbd0a434f8b908af0b76c89c5"}},"22f1c7f1a3cc4c128d74350e06f1d50a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3227b0938aef401db6783c6e3e8d4319","placeholder":"​","style":"IPY_MODEL_fd86f35dda144186afde06541e570d1d","value":"Downloading pytorch_model.bin: 100%"}},"d5cefe027a8f423cb91bbb183a24a135":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa18abf0824453dad2b2b5b515cd704","max":891727295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_620d2667f7a041d4a84451cfa6c0745a","value":891727295}},"99ae0b12b4b94af498806cb9ce432194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da461bd6de4f40a49125a80ecb07e4a1","placeholder":"​","style":"IPY_MODEL_5329b38c1cd34fd198c8ab466c9f4221","value":" 892M/892M [00:15&lt;00:00, 63.3MB/s]"}},"aa14835cbd0a434f8b908af0b76c89c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3227b0938aef401db6783c6e3e8d4319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd86f35dda144186afde06541e570d1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fa18abf0824453dad2b2b5b515cd704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"620d2667f7a041d4a84451cfa6c0745a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da461bd6de4f40a49125a80ecb07e4a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5329b38c1cd34fd198c8ab466c9f4221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}